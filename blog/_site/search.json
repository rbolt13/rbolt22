[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Randi Bolt",
    "section": "",
    "text": "About\nI am a data analyst / scientist based out of Portland, Oregon.\nI have been writing about mathematics, statistics, and data science in my blog since 2021.\nI am constantly exploring new topics, and ways to improve upon past and current work.\nI graduated magna cum laude with a Bachelors of Science in Mathematics from Portland State University in 2022."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "R\n\n\nSQL\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2023\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nPackage Building\n\n\nR\n\n\nNBA\n\n\nSportsObserveR\n\n\n\n\n\n\n\n\n\n\n\nJan 2, 2023\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nWeb-Scraping\n\n\nNBA\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nStatistics\n\n\nLinear Regression\n\n\n\n\n\n\n\n\n\n\n\nDec 5, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nPython\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\nNov 28, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nQuarto\n\n\n\n\n\n\n\n\n\n\n\nNov 21, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nNBA\n\n\nWeb-Scraping\n\n\nR\n\n\nSportsObserveR\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nMath\n\n\nProof\n\n\n\n\n\n\n\n\n\n\n\nOct 31, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nBayes\n\n\n\n\n\n\n\n\n\n\n\nAug 22, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJul 25, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nNBA\n\n\nWeb-Scraping\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\n\nJul 18, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nStatistics\n\n\n\n\n\n\n\n\n\n\n\nJun 20, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nGeometry\n\n\n\n\n\n\n\n\n\n\n\nMay 30, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nMath\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\n\nApr 25, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nNLP\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\nApr 18, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nMath\n\n\n\n\n\n\n\n\n\n\n\nMar 28, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nGeometry\n\n\n\n\n\n\n\n\n\n\n\nMar 21, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\nFeb 21, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nGeometry\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nMath\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nLinear Regression\n\n\n\n\n\n\n\n\n\n\n\nDec 20, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nProof\n\n\nStatistics\n\n\nLinear Regression\n\n\n\n\n\n\n\n\n\n\n\nNov 29, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nStatistics\n\n\n\n\n\n\n\n\n\n\n\nNov 22, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nMath\n\n\n\n\n\n\n\n\n\n\n\nOct 25, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nConditional Probabilty\n\n\nTree Diagrams\n\n\nStatistics\n\n\n\n\n\n\n\n\n\n\n\nOct 18, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nGenerative Art\n\n\n\n\n\n\n\n\n\n\n\nSep 27, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\ntidycensus\n\n\nAPI\n\n\n\n\n\n\n\n\n\n\n\nSep 20, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\nAug 30, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nQuarto\n\n\n\n\n\n\n\n\n\n\n\nAug 23, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nGeometry\n\n\nMath\n\n\nProof\n\n\n\n\n\n\n\n\n\n\n\nJul 26, 2021\n\n\nRandi Bolt\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nGeometry\n\n\nMath\n\n\nProof\n\n\n\n\n\n\n\n\n\n\n\nJul 19, 2021\n\n\nRandi Bolt\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nStatistics\n\n\n\n\n\n\n\n\n\n\n\nJun 28, 2021\n\n\nRandi Bolt\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Randi Bolt",
    "section": "",
    "text": "I post bimonthly about a range of topics that are related to data science, statistics, mathematics, or machine learning. Check out my journey, and feel free to leave my posts comments. Iâ€™d love to hear from you!\nThanks for stopping by, and please enjoy!\nðŸ˜˜âœ¨"
  },
  {
    "objectID": "01_blog/2022_11_21_Quartro/index.html",
    "href": "01_blog/2022_11_21_Quartro/index.html",
    "title": "Quarto Links",
    "section": "",
    "text": "Quarto LinksAccessibilityQuarto BlogsOther Blogs\n\n\nA Quarto tip a day\nCreating a blog with Quarto in 10 steps - Bea Milz\nFrom R Markdown to Quarto\nInstalling and Configuring Python with RStudio\nManaging Execution\nQuarto: Creating a Blog (Documentation)\nQuarto/RMarkdown - Whatâ€™s Different: Slides Repo\nquarto-trio (Using Python, R, and Apache Arrow)\n\n\na11Y - digital accessibility\nWAVE - Web Accessibility Evaluation Tool\n\n\nAbhirup Moitra\nBea Milz: Repo\nDaniel Tran: Repo\nDanielle Navarro - Notes from a data witch: Repo\nRober Mitchell: Repo\nSam Csik: Repo\nTed Landeras, PhD: repo\n\n\nAlicia Johnson (Made with blogdown))\nAllison Hill, PhD\nGreg Wilson\nJenny Bryan (Made with Blogdown and Hugo): Repo\nJulia Silge (Made with Blogdown and Hugo): Repo\nMachine Learning Mastery!\nNan Xiao: Repo\nTanner Heffner (Made with Svelte): Repo\nYanina Bellini Saibene\nYihui Xie"
  },
  {
    "objectID": "01_blog/2022_12_19_NBA-Salaries-Part-1-Web-Scraping/index.html",
    "href": "01_blog/2022_12_19_NBA-Salaries-Part-1-Web-Scraping/index.html",
    "title": "NBA Salaries - Part 1: Web-Scraping",
    "section": "",
    "text": "This post exhibits mainly a scraping function that saves and cleans data from ESPN - NBA Players Salaries, with some simple statistic and data visuals."
  },
  {
    "objectID": "01_blog/2022_12_19_NBA-Salaries-Part-1-Web-Scraping/index.html#change-salaray-from-character-to-numeric",
    "href": "01_blog/2022_12_19_NBA-Salaries-Part-1-Web-Scraping/index.html#change-salaray-from-character-to-numeric",
    "title": "NBA Salaries - Part 1: Web-Scraping",
    "section": "4.1 Change Salaray from Character to Numeric",
    "text": "4.1 Change Salaray from Character to Numeric\nNotice that the SALARY column is a character value. This will not be helpful when trying to do math, or make graphs with this numerical data. To change this 3 things must be addressed:\n\nRemoving the dollar sign.\nRemoving the commas.\nChange character type to numeric.\n\n\nnba_salaries_2023$SALARY <- str_remove_all(nba_salaries_2023$SALARY,\n                    \"\\\\$\")\nnba_salaries_2023$SALARY <- str_remove_all(nba_salaries_2023$SALARY,\n                    \",\")\nnba_salaries_2023$SALARY <- as.numeric(nba_salaries_2023$SALARY)\n\nNow we are able to do math, make graphs, and arrange the data by salary."
  },
  {
    "objectID": "01_blog/2022_12_19_NBA-Salaries-Part-1-Web-Scraping/index.html#basic-statistics",
    "href": "01_blog/2022_12_19_NBA-Salaries-Part-1-Web-Scraping/index.html#basic-statistics",
    "title": "NBA Salaries - Part 1: Web-Scraping",
    "section": "4.2 Basic Statistics",
    "text": "4.2 Basic Statistics\n\n\n\n\nHighest paid value : 48,070,014\nLowest paid value : 5,318\nMedian : 4,043,639\nMean : 8,599,110\nStandard Deviation : 10,152,995"
  },
  {
    "objectID": "01_blog/2022_12_19_NBA-Salaries-Part-1-Web-Scraping/index.html#box-plots",
    "href": "01_blog/2022_12_19_NBA-Salaries-Part-1-Web-Scraping/index.html#box-plots",
    "title": "NBA Salaries - Part 1: Web-Scraping",
    "section": "4.3 Box Plots",
    "text": "4.3 Box Plots\n\n4.3.1 2022 - 2023 Yearly Salary by Postion\n\nggplot2::ggplot(data = nba_salaries_2023,\n                mapping = ggplot2::aes(x = SALARY,\n                                       y = POSITION)) + \n  ggplot2::geom_boxplot()\n\n\n\n\nFrom this visual we can see that Point Guards (PG) appear to be paid the most, while Guards (G) and Forwards (F) on average are paid the least.\n\n\n4.4 2022-2023 Yearly Salary by Team\n\nggplot2::ggplot(data = nba_salaries_2023,\n                mapping = ggplot2::aes(x = SALARY,\n                                       y = TEAM)) + \n  ggplot2::geom_boxplot()\n\n\n\n\nThis plot is not the easiest to read, and might be worth sub-setting the information further. However eye-balling this visual we can see most teams pay between $2,000,000 and $15,000,000 per player with a few outliers. These outliers of course being superstar players."
  },
  {
    "objectID": "01_blog/2023_01_09_Decision-Tree/index.html",
    "href": "01_blog/2023_01_09_Decision-Tree/index.html",
    "title": "Decision Trees - Shipwreak Data",
    "section": "",
    "text": "This is â€¦.\n[picture]"
  },
  {
    "objectID": "01_blog/2023_01_09_Decision-Tree/index.html#load-packages",
    "href": "01_blog/2023_01_09_Decision-Tree/index.html#load-packages",
    "title": "Decision Trees - Shipwreak Data",
    "section": "Load Packages",
    "text": "Load Packages\n\nimport numpy as np\nimport pandas as pd\nimport regex\nimport xgboost as xgb\nimport seaborn as sns\nfrom IPython import get_ipython\nget_ipython().run_line_magic('matplotlib', 'inline')\n\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\n\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom IPython.display import Image as PImage\nfrom subprocess import check_call\nfrom PIL import Image, ImageDraw, ImageFont"
  },
  {
    "objectID": "01_blog/2023_01_09_Decision-Tree/index.html#data",
    "href": "01_blog/2023_01_09_Decision-Tree/index.html#data",
    "title": "Decision Trees - Shipwreak Data",
    "section": "Data",
    "text": "Data\n\nimport numpy as np\nimport pandas as pd\n\nfrom pandas import Series, DataFrame\n\n\ntitanic = pd.read_csv(\"../../00_data/titanic_data.csv\")\ntitanic.head()\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Pclass\n      Name\n      Sex\n      Age\n      SibSp\n      Parch\n      Ticket\n      Fare\n      Cabin\n      Embarked\n    \n  \n  \n    \n      0\n      1\n      0\n      3\n      Braund, Mr. Owen Harris\n      male\n      22.0\n      1\n      0\n      A/5 21171\n      7.2500\n      NaN\n      S\n    \n    \n      1\n      2\n      1\n      1\n      Cumings, Mrs. John Bradley (Florence Briggs Th...\n      female\n      38.0\n      1\n      0\n      PC 17599\n      71.2833\n      C85\n      C\n    \n    \n      2\n      3\n      1\n      3\n      Heikkinen, Miss. Laina\n      female\n      26.0\n      0\n      0\n      STON/O2. 3101282\n      7.9250\n      NaN\n      S\n    \n    \n      3\n      4\n      1\n      1\n      Futrelle, Mrs. Jacques Heath (Lily May Peel)\n      female\n      35.0\n      1\n      0\n      113803\n      53.1000\n      C123\n      S\n    \n    \n      4\n      5\n      0\n      3\n      Allen, Mr. William Henry\n      male\n      35.0\n      0\n      0\n      373450\n      8.0500\n      NaN\n      S\n    \n  \n\n\n\n\n\ntitanic.head()\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Pclass\n      Name\n      Sex\n      Age\n      SibSp\n      Parch\n      Ticket\n      Fare\n      Cabin\n      Embarked\n    \n  \n  \n    \n      0\n      1\n      0\n      3\n      Braund, Mr. Owen Harris\n      male\n      22.0\n      1\n      0\n      A/5 21171\n      7.2500\n      NaN\n      S\n    \n    \n      1\n      2\n      1\n      1\n      Cumings, Mrs. John Bradley (Florence Briggs Th...\n      female\n      38.0\n      1\n      0\n      PC 17599\n      71.2833\n      C85\n      C\n    \n    \n      2\n      3\n      1\n      3\n      Heikkinen, Miss. Laina\n      female\n      26.0\n      0\n      0\n      STON/O2. 3101282\n      7.9250\n      NaN\n      S\n    \n    \n      3\n      4\n      1\n      1\n      Futrelle, Mrs. Jacques Heath (Lily May Peel)\n      female\n      35.0\n      1\n      0\n      113803\n      53.1000\n      C123\n      S\n    \n    \n      4\n      5\n      0\n      3\n      Allen, Mr. William Henry\n      male\n      35.0\n      0\n      0\n      373450\n      8.0500\n      NaN\n      S"
  },
  {
    "objectID": "01_blog/2023_01_09_Decision-Tree/index.html#split-data",
    "href": "01_blog/2023_01_09_Decision-Tree/index.html#split-data",
    "title": "Decision Trees - Shipwreak Data",
    "section": "split data",
    "text": "split data\n\ny=titanic.Survived\nx=titanic.drop('Survived', axis=1)\n\n\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\nx_train.head\n\n<bound method NDFrame.head of      PassengerId  Pclass                                  Name     Sex   Age  \\\n95            96       3           Shorney, Mr. Charles Joseph    male   NaN   \n123          124       2                   Webber, Miss. Susan  female  32.5   \n151          152       1     Pears, Mrs. Thomas (Edith Wearne)  female  22.0   \n162          163       3            Bengtsson, Mr. John Viktor    male  26.0   \n870          871       3                     Balkic, Mr. Cerin    male  26.0   \n..           ...     ...                                   ...     ...   ...   \n249          250       2         Carter, Rev. Ernest Courtenay    male  54.0   \n890          891       3                   Dooley, Mr. Patrick    male  32.0   \n490          491       3  Hagland, Mr. Konrad Mathias Reiersen    male   NaN   \n110          111       1        Porter, Mr. Walter Chamberlain    male  47.0   \n36            37       3                      Mamee, Mr. Hanna    male   NaN   \n\n     SibSp  Parch  Ticket     Fare Cabin Embarked  \n95       0      0  374910   8.0500   NaN        S  \n123      0      0   27267  13.0000  E101        S  \n151      1      0  113776  66.6000    C2        S  \n162      0      0  347068   7.7750   NaN        S  \n870      0      0  349248   7.8958   NaN        S  \n..     ...    ...     ...      ...   ...      ...  \n249      1      0  244252  26.0000   NaN        S  \n890      0      0  370376   7.7500   NaN        Q  \n490      1      0   65304  19.9667   NaN        S  \n110      0      0  110465  52.0000  C110        S  \n36       0      0    2677   7.2292   NaN        C  \n\n[712 rows x 11 columns]>"
  },
  {
    "objectID": "about.html#books-im-currently-reading",
    "href": "about.html#books-im-currently-reading",
    "title": "Randi Bolt",
    "section": "Books Iâ€™m Currently Reading",
    "text": "Books Iâ€™m Currently Reading"
  },
  {
    "objectID": "about.html#music-im-listening-to",
    "href": "about.html#music-im-listening-to",
    "title": "Randi Bolt",
    "section": "Music Iâ€™m Listening To",
    "text": "Music Iâ€™m Listening To\nFace Your Fears - Crazy Ex Girlfriend\nHer Morning Elegance\nNever Thought - Mel Bryant\nPudgy - Smino"
  },
  {
    "objectID": "about.html#movies-ive-watched-recently",
    "href": "about.html#movies-ive-watched-recently",
    "title": "About Randi",
    "section": "Movies Iâ€™ve Watched Recently",
    "text": "Movies Iâ€™ve Watched Recently\nThe Terminator (1,2,3)\nPearl\nX\nThe Father"
  },
  {
    "objectID": "about.html#movies-ive-recently-watched",
    "href": "about.html#movies-ive-recently-watched",
    "title": "Randi Bolt",
    "section": "Movies Iâ€™ve Recently Watched",
    "text": "Movies Iâ€™ve Recently Watched\nThe Terminator (1,2,3)\nPearl\nX\nThe Father"
  },
  {
    "objectID": "01_blog/2021_06_28_Stat-451-Hw1/index.html",
    "href": "01_blog/2021_06_28_Stat-451-Hw1/index.html",
    "title": "Statistics 451: Applied Statistics for Engineers and Scientists - Homework 1",
    "section": "",
    "text": "The problems on this page are from Probability & Statistics for Engineering & Sciences 9th Edition by Jay L. Devore - Duxbury Publisher, and the work is mine."
  },
  {
    "objectID": "01_blog/2021_06_28_Stat-451-Hw1/index.html#consider-the-strength-data-for-beams-given-in-example-1.2.",
    "href": "01_blog/2021_06_28_Stat-451-Hw1/index.html#consider-the-strength-data-for-beams-given-in-example-1.2.",
    "title": "Statistics 451: Applied Statistics for Engineers and Scientists - Homework 1",
    "section": "1.10 : Consider the strength data for beams given in Example 1.2.",
    "text": "1.10 : Consider the strength data for beams given in Example 1.2.\n\na. Construct a stem-and leaf display of the data. What appears to be a representative strength value? Do the observations appear to be highly concentrated about the representative value or rather spread out?\n\nbeam <- c(5.9, 7.2, 7.3, 6.3, 8.1, 6.8, 7.0, 7.6, 6.8, 6.5, 7.0, 6.3, 7.9, 9.0,\n         8.2, 8.7, 7.8, 9.7, 7.4, 7.7, 9.7, 7.8, 7.7, 11.6, 11.3, 11.8, 10.7)\nstem(beam)\n\n\n  The decimal point is at the |\n\n   5 | 9\n   6 | 33588\n   7 | 00234677889\n   8 | 127\n   9 | 077\n  10 | 7\n  11 | 368\n\n\nA representative strength value would be 7.7, as more observations are concentrated around this value than any other.\n\nDoes the display appear to be reasonably symmetric about a representative value, or would you describe its shape in some other way?\n\n\n\n\n\n\nNo, I would argue that the data has a slight positive skewed to the right. I say this because the higher frequency values (in blues) seem to be to the left of the representative value (indicated by the red line), which is to the left of the mean (indicated by the orange line).\n\nDo there appear to be any outlying strength values?\n\nYes there seems to be a small density of values outlying around 11.\n\nWhat proportion of strength observations in this sample exceed 10 MPa?\n\n\n\n[1] \"14.81 %\"\n\n\nAn unlikely 14.81% of values exceed 10 MPa."
  },
  {
    "objectID": "01_blog/2021_06_28_Stat-451-Hw1/index.html#consider-the-strength-data-for-beams-given-below.",
    "href": "01_blog/2021_06_28_Stat-451-Hw1/index.html#consider-the-strength-data-for-beams-given-below.",
    "title": "Statistics 451: Applied Statistics for Engineers and Scientists - Homework 1",
    "section": "1.10 : Consider the strength data for beams given below.",
    "text": "1.10 : Consider the strength data for beams given below.\n\na. Construct a stem-and leaf display of the data. What appears to be a representative strength value? Do the observations appear to be highly concentrated about the representative value or rather spread out?\n\nbeam <- c(5.9, 7.2, 7.3, 6.3, 8.1, 6.8, 7.0, 7.6, 6.8, 6.5, 7.0, 6.3, 7.9, 9.0,\n         8.2, 8.7, 7.8, 9.7, 7.4, 7.7, 9.7, 7.8, 7.7, 11.6, 11.3, 11.8, 10.7)\nstem(beam)\n\n\n  The decimal point is at the |\n\n   5 | 9\n   6 | 33588\n   7 | 00234677889\n   8 | 127\n   9 | 077\n  10 | 7\n  11 | 368\n\n\nA representative strength value would be 7.7, as more observations are concentrated around this value than any other.\n\nDoes the display appear to be reasonably symmetric about a representative value, or would you describe its shape in some other way?\n\n\n\n\n\n\nNo, I would argue that the data has a slight positive skewed to the right. I say this because the higher frequency values (in blues) seem to be to the left of the representative value (indicated by the red line), which is to the left of the mean (indicated by the orange line).\n\nDo there appear to be any outlying strength values?\n\nYes there seems to be a small density of values outlying around 11.\n\nWhat proportion of strength observations in this sample exceed 10 MPa?\n\n\n\n[1] \"14.81 %\"\n\n\nAn unlikely 14.81% of values exceed 10 MPa."
  },
  {
    "objectID": "01_blog/2021_06_28_Stat-451-Hw1/index.html#consider-the-strength-data-for-beams.",
    "href": "01_blog/2021_06_28_Stat-451-Hw1/index.html#consider-the-strength-data-for-beams.",
    "title": "Statistics 451: Applied Statistics for Engineers and Scientists - Homework 1",
    "section": "1.10 Consider the strength data for beams.",
    "text": "1.10 Consider the strength data for beams.\n\na. Construct a stem-and leaf display of the data. What appears to be a representative strength value? Do the observations appear to be highly concentrated about the representative value or rather spread out?\n\nbeam <- c(5.9, 7.2, 7.3, 6.3, 8.1, 6.8, 7.0, 7.6, 6.8, 6.5, 7.0, 6.3, 7.9, 9.0,\n         8.2, 8.7, 7.8, 9.7, 7.4, 7.7, 9.7, 7.8, 7.7, 11.6, 11.3, 11.8, 10.7)\nstem(beam)\n\n\n  The decimal point is at the |\n\n   5 | 9\n   6 | 33588\n   7 | 00234677889\n   8 | 127\n   9 | 077\n  10 | 7\n  11 | 368\n\n\nA representative strength value would be 7.7, as more observations are concentrated around this value than any other.\n\n\nb. Does the display appear to be reasonably symmetric about a representative value, or would you describe its shape in some other way?\n\n\n\n\n\nNo, I would argue that the data has a slight positive skewed to the right. I say this because the higher frequency values (in blues) seem to be to the left of the representative value (indicated by the red line), which is to the left of the mean (indicated by the orange line).\n\n\nc. Do there appear to be any outlying strength values?\nYes there seems to be a small density of values outlying around 11.\n\n\nd. What proportion of strength observations in this sample exceed 10 MPa?\n\n\n[1] \"14.81 %\"\n\n\nAn unlikely 14.81% of values exceed 10 MPa."
  },
  {
    "objectID": "01_blog/2021_06_28_Stat-451-Hw1/index.html#the-accompanying-specific-gravity-values-for-various-wood-types-used-in-construction-appeared-in-the-article-bolted-connection-design-values-based-on-european-yield-model-j.-of-structural-engr.-1993-2169-2186",
    "href": "01_blog/2021_06_28_Stat-451-Hw1/index.html#the-accompanying-specific-gravity-values-for-various-wood-types-used-in-construction-appeared-in-the-article-bolted-connection-design-values-based-on-european-yield-model-j.-of-structural-engr.-1993-2169-2186",
    "title": "Statistics 451: Applied Statistics for Engineers and Scientists - Homework 1",
    "section": "1.12 The accompanying specific gravity values for various wood types used in construction appeared in the article â€œBolted Connection Design Values Based on European Yield Modelâ€ (J. of Structural Engr., 1993: 2169-2186):",
    "text": "1.12 The accompanying specific gravity values for various wood types used in construction appeared in the article â€œBolted Connection Design Values Based on European Yield Modelâ€ (J. of Structural Engr., 1993: 2169-2186):\n\nwood.g <- c(.31, .35, .36, .36, .37, .38, .40, .40, .40,\n            .41, .41, .42, .42, .42, .42, .42, .43, .44,\n            .45, .46, .46, .47, .48, .48, .48, .51, .54,\n            .54, .55, .58, .62, .66, .66, .67, .68, .75)\n\n\nConstruct a stem-and-leaf display using repeated stems (see the previous exercise), and comment on any interesting features of the display.\n\n\n\n  The decimal point is at the |\n\n  0 | 344444444444444444\n  0 | 555555555566677778\n\n\n\n  The decimal point is 1 digit(s) to the left of the |\n\n  3 | 156678\n  4 | 0001122222345667888\n  5 | 14458\n  6 | 26678\n  7 | 5\n\n\n\n  The decimal point is 1 digit(s) to the left of the |\n\n  3 | 1\n  3 | 56678\n  4 | 000112222234\n  4 | 5667888\n  5 | 144\n  5 | 58\n  6 | 2\n  6 | 6678\n  7 | \n  7 | 5\n\n\nLooking at the three stem-and-leaf displays there are a few interesting features about the gravity for various wood types used in construction data that stands out. Dropping the last digit in the data, the first stem-and-leaf display shows us that thereâ€™s an even number of values that are >0.5 and 0.5that appear most dense around 0.4. The second and third stem-and-leaf displays show us that these values are most dense about 0.42, with a small blip around 6.6 and obvious outlier for value 0.75."
  },
  {
    "objectID": "01_blog/2021_06_28_Stat-451-Hw1/index.html#the-article-cited-in-example-1.2-also-gave-the-accompanying-strengths-observations-for-cylinders",
    "href": "01_blog/2021_06_28_Stat-451-Hw1/index.html#the-article-cited-in-example-1.2-also-gave-the-accompanying-strengths-observations-for-cylinders",
    "title": "Statistics 451: Applied Statistics for Engineers and Scientists - Homework 1",
    "section": "1.16 The article cited in Example 1.2 also gave the accompanying strengths observations for cylinders:",
    "text": "1.16 The article cited in Example 1.2 also gave the accompanying strengths observations for cylinders:\n\ncylinders <- c(6.1, 5.8, 7.8, 7.1, 7.2, 9.2, 6.6, 8.3, 7.0, 8.3,\n           7.8, 8.1, 7.4, 8.5, 8.9, 9.8, 9.7, 14.1, 12.6, 11.2)\n\n\na. Construct a comparative stem-and-leaf display (see the previous exercise) of the beam and cylinder data and then answer the questions in parts (b)-(d) of Exercise 10 for the observations on cylinders.\n\n\n\n  The decimal point is at the |\n\n   5 | 8\n   6 | 16\n   7 | 012488\n   8 | 13359\n   9 | 278\n  10 | \n  11 | 2\n  12 | 6\n  13 | \n  14 | 1\n\n\n\nDoes the display appear to be reasonably symmetric about a representative value, or would you describe its shape in some other way?\n\n\n\ncylinders\n 5.8  6.1  6.6    7  7.1  7.2  7.4  8.1  8.5  8.9  9.2  9.7  9.8 11.2 12.6 14.1 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 7.8  8.3 \n   2    2 \n\n\n[1] 8.575\n\n\n[1] 8.2\n\n\nThis data of cylinders also appears to have a slight positive skew, shown by mean (orange line) to the right of the median (red line) and mode (yellow line). However the mean is a lot closer to the median and mode in this than in the previous graph because there appear to bee less extreme observations.\n\nDo there appear to be any outlying strength values?\n\n14.1 appears to be an outlying strength value, as well as 11.2 and 12.6. Without these three values the mean and median are almost identical, shown below in cylinders.clean.\n\n\n [1] 6.1 5.8 7.8 7.1 7.2 9.2 6.6 8.3 7.0 8.3 7.8 8.1 7.4 8.5 8.9 9.8 9.7\n\n\n[1] 7.858824\n\n\n[1] 7.8\n\n\n\nWhat proportion of strength observations in this sample exceed 10 MPa?\n\n\n\n[1] \"15 %\"\n\n\nAbout 15% of the data observations exceed 10 Mpa.\n\n\nb. In what ways are the two sides of the display similar? Are there any obvious differences between the beam observations and the cylinder observations?\nBoth displays show relatively normal distributions with slight skews to the right. Similarly both the beam and cylinders have approximately 15% of the data outside the normal distribution. An obvious difference between the two is that the beam data was more skewed than the cylinder. A reason for this may be that the range of values for the beam is smaller than the range of values for cylinders, so the beam mean is more sensitive to outlying data."
  },
  {
    "objectID": "01_blog/2021_06_28_Stat-451-Hw1/index.html#exposure-to-microbial-products-especially-endotoxin-may-have-an-impact-on-vulnerability-to-allergic-diseases.-the-article-dust-sampling-methods-for-endotoxin-an-essential-but-underestimated-issue-indoor-air-2006-20-27-considered-various-issues-associated-with-determining-endotoxin-concentration.-the-following-data-on-concentration-eumg-in-settled-dust-for-one-sample-of-urban-homes-and-another-of-farm-homes-was-kindly-supplied-by-the-authors-of-the-cited-article.",
    "href": "01_blog/2021_06_28_Stat-451-Hw1/index.html#exposure-to-microbial-products-especially-endotoxin-may-have-an-impact-on-vulnerability-to-allergic-diseases.-the-article-dust-sampling-methods-for-endotoxin-an-essential-but-underestimated-issue-indoor-air-2006-20-27-considered-various-issues-associated-with-determining-endotoxin-concentration.-the-following-data-on-concentration-eumg-in-settled-dust-for-one-sample-of-urban-homes-and-another-of-farm-homes-was-kindly-supplied-by-the-authors-of-the-cited-article.",
    "title": "Statistics 451: Applied Statistics for Engineers and Scientists - Homework 1",
    "section": "1.34 Exposure to microbial products, especially endotoxin, may have an impact on vulnerability to allergic diseases. The article â€œDust Sampling Methods for Endotoxin â€“ An Essential, But Underestimated Issueâ€ (Indoor Air, 2006: 20-27) considered various issues associated with determining endotoxin concentration. The following data on concentration (EU/mg) in settled dust for one sample of urban homes and another of farm homes was kindly supplied by the authors of the cited article.",
    "text": "1.34 Exposure to microbial products, especially endotoxin, may have an impact on vulnerability to allergic diseases. The article â€œDust Sampling Methods for Endotoxin â€“ An Essential, But Underestimated Issueâ€ (Indoor Air, 2006: 20-27) considered various issues associated with determining endotoxin concentration. The following data on concentration (EU/mg) in settled dust for one sample of urban homes and another of farm homes was kindly supplied by the authors of the cited article.\n\nurban <- c(6.0, 5.0, 11.0, 33.0, 4.0, 5.0, 80.0, 18.0, 35.0, 17.0, 23.0)\nfarm <- c(4.0, 14.0, 11.0, 9.0, 9.0, 8.0, 4.0, 20.0, 5.0, 8.9, 21.0, 9.2, 3.0, 2.0, 0.3 )\n\n\na. Determine the sample mean for each sample. How do they compare?\n\nmean(urban)\n\n[1] 21.54545\n\nmean(farm)\n\n[1] 8.56\n\n\nThe mean endotoxin concentration is greater in urban homes than farm homes.\n\n\nb. Determine the sample median for each sample. How do they compare? Why is the median for the urban sample so different from the mean for that sample?\n\nmedian(urban)\n\n[1] 17\n\nmedian(farm)\n\n[1] 8.9\n\n\nThe median endotoxin concentration is greater in urban homes than farm homes.\nThe urban sampleâ€™s median is so different from the mean, because the mean is more sensitive to outliers in the data (such as 80 EU/mg) than the median is.\n\n\nc. Calculate the trimmed mean for each sample by deleting the smallest and largest observation. What are the corresponding trimming percentages? How do the values of these trimmed means compare to the corresponding means and medians?\nTo start I will sort the data to see what are the largest and smallest observations for both.\n\nsort(urban)\n\n [1]  4  5  5  6 11 17 18 23 33 35 80\n\nsort(farm)\n\n [1]  0.3  2.0  3.0  4.0  4.0  5.0  8.0  8.9  9.0  9.0  9.2 11.0 14.0 20.0 21.0\n\n\nFrom the sorted data I can see the lowest and highest values for urban are c(4,80), and for farm they are c(0.3,21). These values are removed from the urban.trim and farm.trim shown below.\n\nurban.trim <- c(6.0, 5.0, 11.0, 33.0, 5.0, 18.0, 35.0, 17.0, 23.0)\nfarm.trim <- c(4.0, 14.0, 11.0, 9.0, 9.0, 8.0, 4.0, 20.0, 5.0, 8.9, 9.2, 3.0, 2.0)\n\nTo find the corresponding trimming percentages I subtracted the sum of the subtracted values from the sums of the urban and farm data sets respectively, and then divide each by the length of each data set respectively.\n\n(sum(urban)-84)/length(urban)\n\n[1] 13.90909\n\n(sum(farm)-21.3)/length(farm)\n\n[1] 7.14\n\n\nThe two values removed from the urban dataset is about 14% of the data, slightly more then the 7.14% variation of the farm data set.\nNow to look at the trimmed means.\n\nmean(urban.trim)\n\n[1] 17\n\nmean(farm.trim)\n\n[1] 8.238462\n\n\nThe trimmed mean of the urban data is closer to the median of the urban data, whereas the trimmed mean for the farm data is farther away from the mean and median of the untrimmed data. After this analysis it would seem that trimming the first data set may be appropriate, whereas trimming the second may lead to misleading data. Looking at the stem-and-leaf displays are helpful in visualizing distributions and outliers.\n\nstem(urban, scale = 2)\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  0 | 4556\n  1 | 178\n  2 | 3\n  3 | 35\n  4 | \n  5 | \n  6 | \n  7 | \n  8 | 0\n\nstem(farm, scale = .5)\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  0 | 02344589999\n  1 | 14\n  2 | 01"
  },
  {
    "objectID": "01_blog/2021_06_28_Stat-451-Hw1/index.html#exercise-34-presented-the-following-data-on-endotoxin-concentration-in-settled-dust-both-for-a-sample-of-urban-homes-and-for-a-sample-of-farm-homes",
    "href": "01_blog/2021_06_28_Stat-451-Hw1/index.html#exercise-34-presented-the-following-data-on-endotoxin-concentration-in-settled-dust-both-for-a-sample-of-urban-homes-and-for-a-sample-of-farm-homes",
    "title": "Statistics 451: Applied Statistics for Engineers and Scientists - Homework 1",
    "section": "1.48 Exercise 34 presented the following data on endotoxin concentration in settled dust both for a sample of urban homes and for a sample of farm homes:",
    "text": "1.48 Exercise 34 presented the following data on endotoxin concentration in settled dust both for a sample of urban homes and for a sample of farm homes:\n\nurban\n\n [1]  6  5 11 33  4  5 80 18 35 17 23\n\nfarm\n\n [1]  4.0 14.0 11.0  9.0  9.0  8.0  4.0 20.0  5.0  8.9 21.0  9.2  3.0  2.0  0.3\n\n\n\na. Determine the value of the sample standard deviation for each sample, interpret these values, and then contrast variability in the two samples.\n\nsd(urban)\n\n[1] 22.29961\n\nsd(farm)\n\n[1] 6.087669\n\n\nAnother way we could find the standard deviation given the hint and the following equation given in class :\n[s^2=_{i=1}^{n}(x_i - x)^2] [=[_{i=1}{n}x_i2 - ]]\n\n# hint\nsigma_x_i.u <- 237.0\nsigma_x_i.f <- 128.4\nsigma_x_i_2.u <- 10079\nsigma_x_i_2.f <- 1617.94\nn.u <- length(urban)\nn.f <- length(farm)\nconstant.u <- 1/(n.u-1)\nconstant.f <- 1/(n.f-1)\nsv.u <- constant.u*(sigma_x_i_2.u - (sigma_x_i.u)^2/n.u)\nsv.f <- constant.f*(sigma_x_i_2.f - (sigma_x_i.f)^2/n.f)\nsqrt(sv.u)\n\n[1] 22.29961\n\nsqrt(sv.f)\n\n[1] 6.087669\n\n\n\n\nb. Compute the fourth spread for each sample and compare. Do the fourth spreads convey the same message about variability that the standard deviations do? Explain.\nThe quickest way to do this in r is with quantile().\n\nquantile(urban)\n\n  0%  25%  50%  75% 100% \n 4.0  5.5 17.0 28.0 80.0 \n\nquantile(farm)\n\n  0%  25%  50%  75% 100% \n 0.3  4.0  8.9 10.1 21.0 \n\n\nExplanation : coming soon\nAnother way to find the forth spread is by first computing the upper fourth and lower fourth . To do that I first sorted the data, and then split it in half. Notice that because n for both data sets is odd, I figure out the middle value that is included in both, before I create the new data sets.\n\n# sort \nsorted.u <- sort(urban)\nsorted.f <- sort(farm)\nsorted.u\n\n [1]  4  5  5  6 11 17 18 23 33 35 80\n\nsorted.f\n\n [1]  0.3  2.0  3.0  4.0  4.0  5.0  8.0  8.9  9.0  9.0  9.2 11.0 14.0 20.0 21.0\n\n# find included value \ninclude.u <- as.integer(n.u/2)+1\ninclude.f <- as.integer(n.f/2)+1\nsorted.u[include.u]\n\n[1] 17\n\nsorted.f[include.f]\n\n[1] 8.9\n\n# upper and lower forth \nurban.lower <- c(4,  5,  5,  6, 11, 17)\nurban.upper <- c(17, 18, 23, 33, 35, 80)\nfarm.lower <- c(0.3,  2.0,  3.0,  4.0,  4.0,  5.0,  8.0,  8.9)\nfarm.upper <- c(8.9,  9.0,  9.0,  9.2, 11.0, 14.0, 20.0, 21.0)\n\nNow that the data is sorted, the middle values of 17 and 8.9 have been found, and the data has been split into two chunks I can compute the minimum,lower forth median, median, upper forth median, and the largest value.\n\nmin(urban)\n\n[1] 4\n\nmedian(urban.lower)\n\n[1] 5.5\n\nmedian(urban)\n\n[1] 17\n\nmedian(urban.upper)\n\n[1] 28\n\nmax(urban)\n\n[1] 80\n\nmin(farm)\n\n[1] 0.3\n\nmedian(farm.lower)\n\n[1] 4\n\nmedian(farm)\n\n[1] 8.9\n\nmedian(farm.upper)\n\n[1] 10.1\n\nmax(farm)\n\n[1] 21\n\n\n\nThe authors of the cited article also provided endotoxin concentrations in dust bag dust:\n\n\nurban.bag <- c(34.0, 49.0, 13.0, 33.0, 24.0, 24.0, 35.0, 104.0, 34.0, 40.0, 38.0, 1.0)\nfarm.bag <- c(2.0, 64.0, 6.0, 17.0, 35.0, 11.0, 17.0, 13.0, 5.0, 27.0, 23.0,\n              28.0, 10.0, 13.0, 0.2)\nquantile(urban.bag)\n\n   0%   25%   50%   75%  100% \n  1.0  24.0  34.0  38.5 104.0 \n\nquantile(farm.bag)\n\n  0%  25%  50%  75% 100% \n 0.2  8.0 13.0 25.0 64.0 \n\n\nConstruct a comparative boxplot (as did the cited paper) and compare and contrast the four samples.\n\npar(mfrow = c(1,2))\nboxplot(urban)\nboxplot(urban.bag)\n\n\n\npar(mfrow = c(1,2))\nboxplot(farm)\nboxplot(farm.bag)"
  },
  {
    "objectID": "01_blog/2021_06_28_Stat-451-Hw1/index.html#the-article-a-thin-film-oxygen-uptake-test-for-the-evaluation-of-automotive-crankcase-lubricants-lubric.-engr.-1984-75-83-reported-the-following-data-on-oxidation-induction-time-min-for-various-commercial-oils",
    "href": "01_blog/2021_06_28_Stat-451-Hw1/index.html#the-article-a-thin-film-oxygen-uptake-test-for-the-evaluation-of-automotive-crankcase-lubricants-lubric.-engr.-1984-75-83-reported-the-following-data-on-oxidation-induction-time-min-for-various-commercial-oils",
    "title": "Statistics 451: Applied Statistics for Engineers and Scientists - Homework 1",
    "section": "1.51 The article â€œA Thin-Film Oxygen Uptake Test for the Evaluation of Automotive Crankcase Lubricantsâ€ (Lubric. Engr., 1984: 75-83) reported the following data on oxidation-induction time (min) for various commercial oils:",
    "text": "1.51 The article â€œA Thin-Film Oxygen Uptake Test for the Evaluation of Automotive Crankcase Lubricantsâ€ (Lubric. Engr., 1984: 75-83) reported the following data on oxidation-induction time (min) for various commercial oils:\n\noxi.induct.time.min <- c(87, 103, 130, 160, 180, 195, 132, 145, 211, 105, 145,\n                         153, 152, 138, 87, 99, 93, 119, 129)\n\n\na. Calculate the sample variance and the standard deviation.\n\noxi.var <- var(oxi.induct.time.min)\noxi.sd <- sd(oxi.induct.time.min)\noxi.var\n\n[1] 1264.766\n\noxi.sd\n\n[1] 35.56355\n\n\n\n\nb. If the observations were re-expressed in hours, what would be the resulting values of the sample variance and sample standard deviation? Answer without actually performing the re-expression.\nThe standard deviation has the same units as the data values (minutes) so in hours the standard deviation would be 35.56/60 (or a little over half an hour) whereas the variance is the standard deviation squared, so the values would be converted 1264.766/60^2.\n\noxi.var/60^2\n\n[1] 0.3513239\n\noxi.sd/60\n\n[1] 0.5927258\n\n# verification \noxi.induct.time.hour <- oxi.induct.time.min/60\nvar(oxi.induct.time.hour)\n\n[1] 0.3513239\n\nsd(oxi.induct.time.hour) \n\n[1] 0.5927258"
  },
  {
    "objectID": "01_blog/2021_06_28_Stat-451-Hw1/index.html#observations-on-burst-strength-lbin2-were-obtained-both-for-test-nozzle-welds-proper-procedures-are-the-key-to-welding-radioactive-waste-canisters-welding-j.-auud.-1997-61-67",
    "href": "01_blog/2021_06_28_Stat-451-Hw1/index.html#observations-on-burst-strength-lbin2-were-obtained-both-for-test-nozzle-welds-proper-procedures-are-the-key-to-welding-radioactive-waste-canisters-welding-j.-auud.-1997-61-67",
    "title": "Statistics 451: Applied Statistics for Engineers and Scientists - Homework 1",
    "section": "1.60 Observations on burst strength (lb/in2) were obtained both for test nozzle welds (â€œProper Procedures Are the Key to Welding Radioactive Waste Canisters,â€ Welding J., Auud. 1997: 61-67)",
    "text": "1.60 Observations on burst strength (lb/in2) were obtained both for test nozzle welds (â€œProper Procedures Are the Key to Welding Radioactive Waste Canisters,â€ Welding J., Auud. 1997: 61-67)\n\nTest <-c(7200, 6100, 7300, 7300, 8000, 7400,\n         7300, 7300, 8000, 6700, 8300)         \nCannister <- c(5250, 5625, 5900, 5900, 5700, 6050,\n               5800, 6000, 5875, 6100, 5850, 6600)\n\n\na. Construct a comparative boxplot and comment on interesting features (the cited article did not include such a picture, but the authors commented that they had looked at one).\n\npar(mfrow = c(1,2))\nboxplot(Test, ylim = c(5000, 8500), main = \"Test\")\nboxplot(Cannister, ylim = c(5000, 8500), main = \"Cannister\")\n\n\n\n\n\nmean(Test)-mean(Cannister)\n\n[1] 1467.045\n\nmean(Test)\n\n[1] 7354.545\n\nmean(Cannister)\n\n[1] 5887.5\n\nsd(Test)\n\n[1] 613.7811\n\nsd(Cannister)\n\n[1] 317.9301"
  },
  {
    "objectID": "00_data/about_data/movies.html",
    "href": "00_data/about_data/movies.html",
    "title": "Randi Bolt",
    "section": "",
    "text": "Movie Titles - Generes - Rating - Review\n\ntitles <- c(\"The Terminator 1\",\n            \"Terminator 2: Judgement Day\",\n            \"Terminator 3: Rise of the Machines\",\n          \"Peal\",\n          \"X\",\n          \"The Father\",\n          \"Our Friend\",\n          \"The Lighthouse\",\n          \"Men\")\n\n\ngenres <- c(\"Action\",\n           \"Horror / Thriller\",\n           \"Horror / Slasher\",\n           \"Drama\")\n\n\nstar_rating <- function(rating, max_rating = 5){\n  \n  star_icon <- function(status) {\n    \n    if (status == \"Half\") {\n      tagAppendAttributes(shiny::icon(\"star-half-alt\"),\n      style = paste(\"color: orange\"),\n      \"aria-hidden\" = \"true\")\n    } else {\n          tagAppendAttributes(shiny::icon(\"star\"),\n      style = paste(\"color:\", if (status == \"Empty\") \"#edf0f2\" else \"orange\"),\n      \"aria-hidden\" = \"true\"\n    )\n    }\n    \n  }\n  \n  rounded_rating <- floor(rating)\n  last_rating <- rating - rounded_rating\n  last_rating <- case_when(last_rating < .25 ~ \"Empty\",\n                           last_rating > .75 ~ \"Full\",\n                           TRUE ~ \"Half\"\n                           )\n  \n  stars <- lapply(seq_len(max_rating), function(i) {\n    if (i <= rounded_rating) { star_icon(status = \"Full\")} \n    else {\n      if (i == (rounded_rating+1)) star_icon(status = last_rating)\n      else {\n      star_icon(status = \"Empty\")\n    }\n    }\n    \n    })\n  \n  label <- sprintf(\"%s out of %s\", rating, max_rating)\n  div(title = label, \"aria-label\" = label, role = \"img\", stars)\n\n}\n\n# Example\nstar_rating(4.5)\n\n\n\n\n\n\n\n\n\n\n\nwatched <- c(\"12/22\",\n             \"12/22\",\n             \"12/22\",\n             \"12/22\")"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html",
    "title": "R and SQLite",
    "section": "",
    "text": "In this post I use fake hospital data to answer questions using both R and SQL (Structured Query Language) via a R package called RSQLite."
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#packages",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#packages",
    "title": "R and SQLite",
    "section": "0.1 Packages",
    "text": "0.1 Packages\nFor all my data quering and manipulation in R I will be using the tidyverse.\n\nlibrary(tidyverse)\n\nTo run create a SQL database, and run SQL queries in R chunks I will be using a package called RSQLite.\n\nlibrary(RSQLite)"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#data",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#data",
    "title": "R and SQLite",
    "section": "0.2 Data",
    "text": "0.2 Data\nThis post will use two data sets that I copied from Learn SQL:\n\npatients: Which includes patient_id, first_name, last_name, gender, birth_date, city, province_id, allergies, height, and weight. Note I only copied the first 1000 entries.\n\n\npatients <- utils::read.csv('../../00_data/patients.csv')\n\n\nprovince_names: Which includes province_id, and province_name.\n\n\nprovince_names <- utils::read.csv(\"../../00_data/province_names.csv\")"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#database",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#database",
    "title": "R and SQLite",
    "section": "0.3 Database",
    "text": "0.3 Database\nTo start I am using the dbConnect(), and SQLite() functions to create a hospital\nSince SQL lets the user access and manipulate data from a database, it is important to create this data base.\nCreate a Hospital database to store the patients data.\n\nhosp <- RSQLite::dbConnect(RSQLite::SQLite(),\n                           \"../../00_data/Hospital.db\")\n\n\nRSQLite::dbWriteTable(hosp,\n                      \"patients\",\n                      patients)\nRSQLite::dbWriteTable(hosp,\n                      \"province_names\",\n                      province_names)\n\n\nRSQLite::dbListTables(hosp)\n\n[1] \"patients\"       \"province_names\""
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r",
    "title": "R and SQLite",
    "section": "R",
    "text": "R\n\nutils::head(patients, 10)\n\n   patient_id first_name  last_name gender birth_date            city\n1           1     Donald Waterfield      M 1963-02-12          Barrie\n2           2     Mickey     Baasha      M 1981-05-28          Dundas\n3           3       Jiji     Sharma      M 1957-09-05        Hamilton\n4           4      Blair       Diaz      M 1967-01-07        Hamilton\n5           5    Charles      Wolfe      M 2017-11-19         Orillia\n6           6        Sue     Falcon      F 2017-09-30            Ajax\n7           7     Thomas     ONeill      M 1993-01-31      Burlington\n8           8      Sonny    Beckett      M 1952-12-11 Port Hawkesbury\n9           9     Sister    Spitzer      F 1966-10-15         Toronto\n10         10     Cedric   Coltrane      M 1961-11-10         Toronto\n   province_id  allergies height weight\n1           ON       NULL    156     65\n2           ON      Sulfa    185     76\n3           ON Penicillin    194    106\n4           ON       NULL    191    104\n5           ON Penicillin     47     10\n6           ON Penicillin     43      5\n7           ON       NULL    180    117\n8           NS       NULL    174    105\n9           ON Penicillin    173     95\n10          ON       NULL    157     61"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql",
    "title": "R and SQLite",
    "section": "SQL",
    "text": "SQL\n\nRSQLite::dbGetQuery(hosp, \n                    \"SELECT * \n                     FROM patients \n                     LIMIT 10\"\n                    )\n\n   patient_id first_name  last_name gender birth_date            city\n1           1     Donald Waterfield      M 1963-02-12          Barrie\n2           2     Mickey     Baasha      M 1981-05-28          Dundas\n3           3       Jiji     Sharma      M 1957-09-05        Hamilton\n4           4      Blair       Diaz      M 1967-01-07        Hamilton\n5           5    Charles      Wolfe      M 2017-11-19         Orillia\n6           6        Sue     Falcon      F 2017-09-30            Ajax\n7           7     Thomas     ONeill      M 1993-01-31      Burlington\n8           8      Sonny    Beckett      M 1952-12-11 Port Hawkesbury\n9           9     Sister    Spitzer      F 1966-10-15         Toronto\n10         10     Cedric   Coltrane      M 1961-11-10         Toronto\n   province_id  allergies height weight\n1           ON       NULL    156     65\n2           ON      Sulfa    185     76\n3           ON Penicillin    194    106\n4           ON       NULL    191    104\n5           ON Penicillin     47     10\n6           ON Penicillin     43      5\n7           ON       NULL    180    117\n8           NS       NULL    174    105\n9           ON Penicillin    173     95\n10          ON       NULL    157     61"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r-1",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r-1",
    "title": "R and SQLite",
    "section": "R",
    "text": "R\n\nbase::data.frame(\"total_admissions\" = base::nrow(patients))\n\n  total_admissions\n1             1000"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql-1",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql-1",
    "title": "R and SQLite",
    "section": "SQL",
    "text": "SQL\n\nRSQLite::dbGetQuery(hosp,\n                    \"SELECT COUNT(*) AS total_admissions \n                     FROM patients\"\n                    )\n\n  total_admissions\n1             1000"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r-2",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r-2",
    "title": "R and SQLite",
    "section": "R",
    "text": "R\n\nutils::head(\n  base::data.frame(\n    full_name = base::paste0(patients$first_name, \n                             \" \", \n                             patients$last_name)), \n  10)\n\n           full_name\n1  Donald Waterfield\n2      Mickey Baasha\n3        Jiji Sharma\n4         Blair Diaz\n5      Charles Wolfe\n6         Sue Falcon\n7      Thomas ONeill\n8      Sonny Beckett\n9     Sister Spitzer\n10   Cedric Coltrane"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql-2",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql-2",
    "title": "R and SQLite",
    "section": "SQL",
    "text": "SQL\n\nRSQLite::dbGetQuery(hosp,\n  \"SELECT first_name || ' ' || last_name AS full_name \n   FROM patients \n   LIMIT 10\"\n   )\n\n           full_name\n1  Donald Waterfield\n2      Mickey Baasha\n3        Jiji Sharma\n4         Blair Diaz\n5      Charles Wolfe\n6         Sue Falcon\n7      Thomas ONeill\n8      Sonny Beckett\n9     Sister Spitzer\n10   Cedric Coltrane"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r-3",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r-3",
    "title": "R and SQLite",
    "section": "R",
    "text": "R\n\npatients %>% \n  filter(province_id == \"NS\") %>%\n  summarise(unique_cities = unique(city)) \n\n    unique_cities\n1 Port Hawkesbury\n2         Halifax"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql-3",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql-3",
    "title": "R and SQLite",
    "section": "SQL",
    "text": "SQL\n\ndbGetQuery(hosp,\n           \"SELECT DISTINCT(city) AS unique_cities \n            FROM patients \n            WHERE province_id IS 'NS'\"\n           )\n\n    unique_cities\n1 Port Hawkesbury\n2         Halifax"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r-4",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r-4",
    "title": "R and SQLite",
    "section": "R",
    "text": "R\n\nbase::data.frame(\n  male_count = base::length(base::which(patients$gender == 'M')),\n  female_count = base::length(base::which(patients$gender == 'F'))\n  )\n\n  male_count female_count\n1        543          457"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql-4",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql-4",
    "title": "R and SQLite",
    "section": "SQL",
    "text": "SQL\n\ndbGetQuery(hosp,\n           \"SELECT \n           (SELECT COUNT(*) FROM patients WHERE gender = 'M') AS male_count, \n           (SELECT COUNT(*) FROM patients WHERE gender = 'F') AS female_count\")\n\n  male_count female_count\n1        543          457"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r-5",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r-5",
    "title": "R and SQLite",
    "section": "R",
    "text": "R\n\npatients %>% \n  filter(allergies != \"NULL\") %>%\n  group_by(allergies) %>%\n  summarise(total_diagnosis = n()) %>%\n  arrange(desc(total_diagnosis)) %>%\n  head(10)\n\n# A tibble: 10 Ã— 2\n   allergies   total_diagnosis\n   <chr>                 <int>\n 1 Penicillin              230\n 2 Codeine                  58\n 3 Sulfa                    35\n 4 ASA                      16\n 5 Sulfa Drugs              13\n 6 Tylenol                  11\n 7 Wheat                    11\n 8 Peanuts                  10\n 9 Bee Stings                9\n10 Iodine                    9"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql-5",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql-5",
    "title": "R and SQLite",
    "section": "SQL",
    "text": "SQL\n\ndbGetQuery(hosp,\n           \"SELECT allergies,\n            COUNT(*) AS total_diagnosis\n            FROM patients\n            WHERE allergies IS NOT 'NULL'\n            GROUP BY allergies\n            ORDER BY total_diagnosis DESC\n            LIMIT 10\"\n           )\n\n     allergies total_diagnosis\n1   Penicillin             230\n2      Codeine              58\n3        Sulfa              35\n4          ASA              16\n5  Sulfa Drugs              13\n6        Wheat              11\n7      Tylenol              11\n8      Peanuts              10\n9       Iodine               9\n10  Bee Stings               9"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r-6",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r-6",
    "title": "R and SQLite",
    "section": "R",
    "text": "R\n\nbase::merge(province_names, patients, by = \"province_id\") %>%\n  group_by(province_name) %>%\n  summarise(patient_count = n()) %>%\n  arrange(desc(patient_count))\n\n# A tibble: 8 Ã— 2\n  province_name             patient_count\n  <chr>                             <int>\n1 Ontario                             954\n2 Alberta                              14\n3 British Columbia                     11\n4 Nova Scotia                           9\n5 Manitoba                              7\n6 Newfoundland and Labrador             2\n7 Quebec                                2\n8 Saskatchewan                          1"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql-6",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql-6",
    "title": "R and SQLite",
    "section": "SQL",
    "text": "SQL\n\nRSQLite::dbGetQuery(hosp,\n                    \"SELECT province_name,\n                     COUNT(*) as patient_count\n                     FROM patients pa\n                     join province_names pr on pr.province_id = pa.province_id\n                     group by pr.province_id\n                     order by patient_count desc\")\n\n              province_name patient_count\n1                   Ontario           954\n2                   Alberta            14\n3          British Columbia            11\n4               Nova Scotia             9\n5                  Manitoba             7\n6                    Quebec             2\n7 Newfoundland and Labrador             2\n8              Saskatchewan             1"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r-7",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r-7",
    "title": "R and SQLite",
    "section": "R",
    "text": "R\n\nbase::merge(province_names, patients, by = \"province_id\") %>%\n  dplyr::group_by(province_name) %>%\n  dplyr::count(gender == \"M\", gender == \"F\") %>%\n  dplyr::slice(base::which.max(n)) %>%\n  dplyr::summarise(province_name = province_name)\n\n# A tibble: 8 Ã— 1\n  province_name            \n  <chr>                    \n1 Alberta                  \n2 British Columbia         \n3 Manitoba                 \n4 Newfoundland and Labrador\n5 Nova Scotia              \n6 Ontario                  \n7 Quebec                   \n8 Saskatchewan"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql-7",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql-7",
    "title": "R and SQLite",
    "section": "SQL",
    "text": "SQL\n\nRSQLite::dbGetQuery(hosp,\n                    \"SELECT pr.province_name\n                     FROM patients AS pa\n                     JOIN province_names AS pr ON pa.province_id = pr.province_id\n                     GROUP BY pr.province_id\n                     HAVING\n                     COUNT( CASE WHEN gender = 'M' THEN 1 END) >\n                     COUNT( CASE WHEN gender = 'F' THEN 1 END)\")\n\n              province_name\n1                   Alberta\n2          British Columbia\n3                  Manitoba\n4 Newfoundland and Labrador\n5               Nova Scotia\n6                   Ontario\n7                    Quebec\n8              Saskatchewan"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r-8",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r-8",
    "title": "R and SQLite",
    "section": "R",
    "text": "R\n\n\n\n\nfor(i in 1:length(patients$patient_id))\n  {\n  if(patients$patient_id[[i]]%%2==1){\n     patients$has_insurance[[i]] <- \"Yes\"\n  }else{\n    patients$has_insurance[[i]] <- \"No\"\n  }\n}\n\n#. patients"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql-8",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql-8",
    "title": "R and SQLite",
    "section": "SQL",
    "text": "SQL\n\nRSQLite::dbGetQuery(hosp,\n                    \"SELECT \n                        CASE WHEN patient_id % 2 = 0 Then 'Yes'\n                        ELSE 'No' \n                        END as has_insurance,\n                     SUM(\n                        CASE WHEN patient_id % 2 = 0 Then 10\n                        ELSE 50 \n                        END\n                         ) as cost_after_insurance\n                     FROM patients \n                     GROUP BY has_insurance;\")\n\n  has_insurance cost_after_insurance\n1            No                25000\n2           Yes                 5000"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r-9",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#r-9",
    "title": "R and SQLite",
    "section": "R",
    "text": "R\n\npatients %>%\n  filter(base::grepl(\"^.{2}[b]\", first_name),\n         gender == \"F\",\n         weight > 50 && weight < 80,\n         patient_id %%2==1,\n         city == \"Burlington\")\n\n  patient_id first_name last_name gender birth_date       city province_id\n1        695    Sabrina    Hettie      F 2000-11-25 Burlington          ON\n   allergies height weight has_insurance\n1 Penicillin    160     51           Yes"
  },
  {
    "objectID": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql-9",
    "href": "01_blog/2023_01_23_Data-Tool-Box-P1/index.html#sql-9",
    "title": "R and SQLite",
    "section": "SQL",
    "text": "SQL\n\nRSQLite::dbGetQuery(hosp,\n                    \"SELECT *\n                     FROM patients\n                     WHERE\n                      first_name LIKE '__b%'\n                      AND gender = 'F'\n                      AND weight BETWEEN 50 AND 70\n                      AND patient_id % 2 = 1\n                      AND city = 'Burlington';\")\n\n  patient_id first_name last_name gender birth_date       city province_id\n1        695    Sabrina    Hettie      F 2000-11-25 Burlington          ON\n   allergies height weight\n1 Penicillin    160     51"
  },
  {
    "objectID": "01_blog/2021_07_19_Quiz-1/index.html",
    "href": "01_blog/2021_07_19_Quiz-1/index.html",
    "title": "Proving If Two Angles Are Verticle, Then They Are Congruent",
    "section": "",
    "text": "This is a â€œpresentationâ€ style proof for Math-338: Modern College Geometry, and looks at congruence of two verticle angles."
  },
  {
    "objectID": "01_blog/2021_07_19_Quiz-1/index.html#suppose-two-angles-are-verticle.",
    "href": "01_blog/2021_07_19_Quiz-1/index.html#suppose-two-angles-are-verticle.",
    "title": "Proving If Two Angles Are Verticle, Then They Are Congruent",
    "section": "Suppose two angles are verticle.",
    "text": "Suppose two angles are verticle.\nProve that they are congruent."
  },
  {
    "objectID": "01_blog/2021_07_19_Quiz-1/index.html#vertical-angles",
    "href": "01_blog/2021_07_19_Quiz-1/index.html#vertical-angles",
    "title": "Proving If Two Angles Are Verticle, Then They Are Congruent",
    "section": "1.1 Vertical Angles",
    "text": "1.1 Vertical Angles\nIn class we defined vertical angles as being â€œacross from each otherâ€.\n\n\n\n\n\nFig. 1:  Vertical angles are shown in pink.\n\n\n\n\nWe can see a simple example of this in Fig. 1 where a pair of pink angles \\(\\angle AOB\\) and \\(\\angle COD\\) are vertical to each other.\nNote that \\(\\angle AOC\\) and \\(\\angle BOD\\) are vertical angles as well."
  },
  {
    "objectID": "01_blog/2021_07_19_Quiz-1/index.html#congruence",
    "href": "01_blog/2021_07_19_Quiz-1/index.html#congruence",
    "title": "Proving If Two Angles Are Verticle, Then They Are Congruent",
    "section": "1.2 Congruence",
    "text": "1.2 Congruence\n\\(x\\cong y\\) if there is an \\(\\underline{\\text{isometry}}\\) that superimposes x onto y.\n\nIsometry is a map that preserves distance and angles\n\ntranslation (move without turning)\nrotation (moving about a fixed point)\nreflection (mirror)\ncombination\n\n\n\n\n\n\n\nFig. 2:  Two congruent triangles\n\n\n\n\nIn Fig. 2 we see the two triangles are congruent, and would only need a translation isometry or two to map \\(\\triangle ABC\\) onto \\(\\triangle A_1B_1C_1\\)."
  },
  {
    "objectID": "01_blog/2021_07_19_Quiz-1/index.html#supplementary-angles",
    "href": "01_blog/2021_07_19_Quiz-1/index.html#supplementary-angles",
    "title": "Proving If Two Angles Are Verticle, Then They Are Congruent",
    "section": "1.3 Supplementary Angles",
    "text": "1.3 Supplementary Angles\nWe defined supplementary angles as angles whose measurement adds up to \\(180^\\circ\\).\n\n\n\n\n\nFig. 3: Supplementary angles are shown in pink and orange.\n\n\n\n\nIn Fig.3 we can clearly see that \\(m\\angle AOC\\) shown in pink and \\(m\\angle AOB\\) in orange adds to a straight line or \\(180^\\circ\\). We can also see three other pairs of supplementary angles:\n\n\\(m\\angle AOB+m\\angle BOD=180^\\circ\\)\n\\(m\\angle BOD+m\\angle COD=180^\\circ\\)\n\\(m\\angle COD+m\\angle AOC=180^\\circ\\)"
  },
  {
    "objectID": "01_blog/2021_07_19_Quiz-1/index.html#axioms-of-angle-measure",
    "href": "01_blog/2021_07_19_Quiz-1/index.html#axioms-of-angle-measure",
    "title": "Proving If Two Angles Are Verticle, Then They Are Congruent",
    "section": "2.1 Axioms of Angle Measure",
    "text": "2.1 Axioms of Angle Measure\n\nRight angle measures \\(90^\\circ\\)\n\\(m\\angle ABC=m\\angle CBA\\)\nIf D is the interior of \\(\\angle ABC\\), then \\(m\\angle ABC=m\\angle ABD+m\\angle BDC\\)\nThere exists a unique ray that is the angle bisector of \\(\\angle ABC\\)."
  },
  {
    "objectID": "01_blog/2021_07_19_Quiz-1/index.html#congruence-and-angle-measure-theorem",
    "href": "01_blog/2021_07_19_Quiz-1/index.html#congruence-and-angle-measure-theorem",
    "title": "Proving If Two Angles Are Verticle, Then They Are Congruent",
    "section": "2.2 Congruence and Angle Measure theorem",
    "text": "2.2 Congruence and Angle Measure theorem\n\\(\\angle ABC\\cong \\angle DEF \\Leftrightarrow m\\angle ABC=m\\angle DEF\\)\n\nIf two angles are congruent then the measure of those two angles is the same.\nIf the measure of two angles is the same, then those two angles are congruent.\n\n(Note that the measure for angles that will be used on the proof will be in degrees. )"
  },
  {
    "objectID": "01_blog/2021_07_19_Quiz-1/index.html#supplementary-interior-angle-theorem",
    "href": "01_blog/2021_07_19_Quiz-1/index.html#supplementary-interior-angle-theorem",
    "title": "Proving If Two Angles Are Verticle, Then They Are Congruent",
    "section": "2.3 Supplementary Interior Angle Theorem",
    "text": "2.3 Supplementary Interior Angle Theorem\nIf two lines are parallel then the supplementary interior angles add to \\(180^\\circ\\).\n\n\n\n\n\nFig. 4:  Supplementary interior angles are shown in red.\n\n\n\n\nIn Fig. 4 the supplementary interior angles \\(\\angle AEF\\) and \\(\\angle CFE\\) are shown in red and add up to \\(180^\\circ\\)."
  },
  {
    "objectID": "01_blog/2021_07_26_Quiz-2/index.html",
    "href": "01_blog/2021_07_26_Quiz-2/index.html",
    "title": "Proving that the Set of Symmetries of Non-Square Rhombus is a Group Under Composition",
    "section": "",
    "text": "This is a â€œpresentationâ€ style proof for Math-338: Modern College Geometry, and looks at the symmetries of a non-square rectangle."
  },
  {
    "objectID": "01_blog/2021_07_26_Quiz-2/index.html#suppose-r-is-a-non-square-rhombus.",
    "href": "01_blog/2021_07_26_Quiz-2/index.html#suppose-r-is-a-non-square-rhombus.",
    "title": "Proving that the Set of Symmetries of Non-Square Rhombus is a Group Under Composition",
    "section": "Suppose R is a non-square rhombus.",
    "text": "Suppose R is a non-square rhombus.\n\nList the symmetries of R. Write as a composition of translations, reflections, and rotations.\nProve that the set of symmetries of R is a group under composition."
  },
  {
    "objectID": "01_blog/2021_07_26_Quiz-2/index.html#parallelogram",
    "href": "01_blog/2021_07_26_Quiz-2/index.html#parallelogram",
    "title": "Proving that the Set of Symmetries of Non-Square Rhombus is a Group Under Composition",
    "section": "1.1 Parallelogram",
    "text": "1.1 Parallelogram\nBoth pairs of opposite sides are parallel.\n\n\n\n\n\nFig. 1:  Parallelogram\n\n\n\n\n\n\\(AB\\parallel DC\\)\n\\(CB\\parallel DA\\)"
  },
  {
    "objectID": "01_blog/2021_07_26_Quiz-2/index.html#rhombus",
    "href": "01_blog/2021_07_26_Quiz-2/index.html#rhombus",
    "title": "Proving that the Set of Symmetries of Non-Square Rhombus is a Group Under Composition",
    "section": "1.2 Rhombus",
    "text": "1.2 Rhombus\nParallelogram whose sides are all the same length.\nNotation: R\n\n\n\n\n\nFig. 2:  Rhombus\n\n\n\n\n\n\\(\\overline{AB}=\\overline{BC}=\\overline{CD}=\\overline{DA}\\)"
  },
  {
    "objectID": "01_blog/2021_07_26_Quiz-2/index.html#isometry",
    "href": "01_blog/2021_07_26_Quiz-2/index.html#isometry",
    "title": "Proving that the Set of Symmetries of Non-Square Rhombus is a Group Under Composition",
    "section": "1.3 Isometry",
    "text": "1.3 Isometry\nPreserves distance, length, and angle measure through â€œrigid motionâ€ of rotations, reflections, translations, and compositions.\n\n1.3.1 Translations\nMove all the points across a vector \\(\\vec{v}\\).\nNotation: \\(\\tau_{\\text{start point,end point}}\\)\n\n\n\n\n\nFig. 3:  Translation of line AB along vector v.\n\n\n\n\n\n\n1.3.2 Rotations\nPick a center O (origin), \\(\\theta\\) (angle), takes P to Pâ€™ on a circle on a circle with center O and radius \\(\\overline{OP}\\) with \\(\\angle POP'=\\theta\\).\nNotation: \\(R_{O,\\theta}\\)\n\n\n\n\n\nFig. 4:  Rotation of line OP.\n\n\n\n\n\n\n1.3.3 Reflections\nMirror of a shape across a line.\nPick line b, shown in red in Fig. 5.\n\nPoints on B donâ€™t move.\nPoints not on b, such as P, go to Pâ€™ where b is perpendicular to bisector of \\(\\overline{PP'}\\).\nMidpoint m of PPâ€™ on b make right angle \\(\\overline{PP'}\\)\n\nNotation: \\(r_{b}\\)\n\n\n\n\n\nFig. 5:  Triangle QPR reflected across line b.\n\n\n\n\n\n\n1.3.4 Compositions\nCombinations of rotations, reflections, and translations."
  },
  {
    "objectID": "01_blog/2021_07_26_Quiz-2/index.html#symmetry",
    "href": "01_blog/2021_07_26_Quiz-2/index.html#symmetry",
    "title": "Proving that the Set of Symmetries of Non-Square Rhombus is a Group Under Composition",
    "section": "1.4 Symmetry",
    "text": "1.4 Symmetry\nAn isometry that sends a geometric figure to itself."
  },
  {
    "objectID": "01_blog/2021_07_26_Quiz-2/index.html#group",
    "href": "01_blog/2021_07_26_Quiz-2/index.html#group",
    "title": "Proving that the Set of Symmetries of Non-Square Rhombus is a Group Under Composition",
    "section": "1.5 Group",
    "text": "1.5 Group\n\n1.5.0 Closure\n\nOrder doesnâ€™t matter.\n\\(ab=ba\\)\n\n\n\n1.5.1 Associativity\n\nParentheses donâ€™t matter.\n\\((ab)c=a(bc)\\)\n\n\n\n1.5.2 Identity\n\nAnything combined with identity equals itself.\n\\(ea=ae=a\\)\n\n\n\n1.5.3 Inverses\n\nUndoes isometry.\n\\(f^{-1}(f(a))=a\\)"
  },
  {
    "objectID": "01_blog/2021_07_26_Quiz-2/index.html#symmetries-of-r-1",
    "href": "01_blog/2021_07_26_Quiz-2/index.html#symmetries-of-r-1",
    "title": "Proving that the Set of Symmetries of Non-Square Rhombus is a Group Under Composition",
    "section": "2.1 4 Symmetries of R",
    "text": "2.1 4 Symmetries of R\n(Using Boyceâ€™s Notation)\n\n2.1.1 \\(e\\)\n\n\n\n\n\nIdentity\n\n\n\n\n\n\n2.1.2 \\(R_{O,180^\\circ}\\)\n\n\n\n\n\nRotation about center (O) by \\(180^o\\).\n\n\n\n\n\n\n2.1.3 \\(r_{m_1}\\)\n\n\n\n\n\nReflection over \\(m_1\\)\n\n\n\n\n\n\n2.1.4 \\(r_{m_2}\\)\n\n\n\n\n\nReflection over \\(m_2\\)\n\n\n\n\n\n\n2.1.5 Verify\nTo verify this we can imagine that one point only has two places to choose from, then the a different point only has two places to choose from, and then the remaining two points only have one place to choose i.e.Â \\(2\\cdot 2\\cdot 1\\cdot 1=4\\). Therefore there are only four possible symmetries of R."
  },
  {
    "objectID": "01_blog/2021_07_26_Quiz-2/index.html#claim-mathscrs-is-a-group-under-composition.",
    "href": "01_blog/2021_07_26_Quiz-2/index.html#claim-mathscrs-is-a-group-under-composition.",
    "title": "Proving that the Set of Symmetries of Non-Square Rhombus is a Group Under Composition",
    "section": "3.1 Claim: \\(\\mathscr{S}\\) is a group under composition.",
    "text": "3.1 Claim: \\(\\mathscr{S}\\) is a group under composition.\n\n3.1.0 Closure\nWe want to show that composing two symmetries equals a symmetry.\nLet \\(\\square 1234\\) be a non-square rhombus, and suppose F and G are in \\(\\mathscr{S}\\).\n\\[F\\circ G(\\square 1234)=F(G(\\square 1234))=F(\\square 1234)=\\square 1234\\]\nFor example:\nLet \\(F=r_{m_1}\\) and \\(G=r_{m_2}\\). Then \\(F\\circ G(\\square 1234)=R_{O,180^\\circ}\\).\n\n\n3.1.1 Associative\n\\(F\\circ(G\\circ H)=(F\\circ G)\\circ H\\)\n\\[\\begin{equation}\\label{D14,1}\n\\begin{split}\nF\\circ(G\\circ H) &= F\\circ (G\\circ H)(\\square 1234)\\\\\n&= F(G\\circ H (\\square 1234))\\\\\n&= F(G(H(\\square 1234)))\\\\\n&= (F\\circ G)\\circ H(\\square 1234)\n\\end{split}\n\\end{equation}\\]\n\n\n3.1.2 Identity\ne is one of the symmetries.\nExample: \\(R_{O,180^\\circ}\\circ e=R_{O,180^\\circ}\\)\n\n\n3.1.3 Inverses\nEvery symmetry of a rhombus undoes itself.\n\\(e\\circ e=e\\)\n\\(R_{O,180^\\circ}\\circ R_{O,180^\\circ}=e\\)\n\\(r_{m_1}\\circ r_{m_1}=e\\)\n\\(r_{m_2}\\circ r_{m_2}=e\\)"
  },
  {
    "objectID": "01_blog/2023_01_23_R-and-SQLite/index.html",
    "href": "01_blog/2023_01_23_R-and-SQLite/index.html",
    "title": "R and SQLite",
    "section": "",
    "text": "Naruto with SQL logo, and Sauske with the R Studio logo, standing back to back.\n\n\n\n0. Introduction\nThere are a handful of programming languages that data scientists use when querying, analyzing, and manipulating data. What I have found is that while R and Python have a lot more power in what they are capable of producing, SQL is used by a wider variety of roles to access and query data. So to get more practice using both SQL and R I pulled 10 questions and some data off a website called Learn SQL, and will be answering the following questions in both languages.\n\n0.0 Set-Up0.1 Packages0.2 Data0.3 Database\n\n\nContents:\n\n0.1 Packages\n0.2 Data\n0.3 Data base\n\n\n\nFor all my data queries and manipulation in R I will be using base R, dplyr, and magrittr.\n\nlibrary(dplyr)\nlibrary(magrittr)\n\nTo create a SQL database, and run SQL queries in R chunks I will be using a package called RSQLite.\n\nlibrary(RSQLite)\n\n\n\nThis post will use two data sets that I copied from Learn SQL:\n\npatients: Which includes patient_id, first_name, last_name, gender, birth_date, city, province_id, allergies, height, and weight. Note I only copied the first 1000 entries.\n\n\npatients <- utils::read.csv('../../00_data/patients.csv')\n\n\nprovince_names: Which includes province_id, and province_name.\n\n\nprovince_names <- utils::read.csv(\"../../00_data/province_names.csv\")\n\n\n\nTo create a database use:\n\ndbConnect() to connect to a SQL data base called Hospital.db in the 00_data folder.\nSQLite() to connect to a SQLite database file.\n\n\nhosp <- RSQLite::dbConnect(RSQLite::SQLite(),\n                           \"../../00_data/Hospital.db\")\n\nTo define data within the database use:\n\ndbWriteTable() to create a data set within the hospital database called patients and province_names with the respective data.\n\n\nRSQLite::dbWriteTable(hosp,\n                      \"patients\",\n                      patients)\nRSQLite::dbWriteTable(hosp,\n                      \"province_names\",\n                      province_names)\n\nVerify the two data sets are in the database using:\n\ndbListTables() to list the tables within the hosp database.\n\n\nRSQLite::dbListTables(hosp)\n\n[1] \"patients\"       \"province_names\"\n\n\n\n\n\n\n\n1. Show the first ten rows of patients data.\n\n1.01.1 R1.2 SQL\n\n\nContents\n\n1.1 Solution in R\n1.2 Solution in SQL\n\n\n\nIn R use:\n\nhead() to view the first 10 rows of the patients data.\n\n\nutils::head(patients, 10)\n\n   patient_id first_name  last_name gender birth_date            city\n1           1     Donald Waterfield      M 1963-02-12          Barrie\n2           2     Mickey     Baasha      M 1981-05-28          Dundas\n3           3       Jiji     Sharma      M 1957-09-05        Hamilton\n4           4      Blair       Diaz      M 1967-01-07        Hamilton\n5           5    Charles      Wolfe      M 2017-11-19         Orillia\n6           6        Sue     Falcon      F 2017-09-30            Ajax\n7           7     Thomas     ONeill      M 1993-01-31      Burlington\n8           8      Sonny    Beckett      M 1952-12-11 Port Hawkesbury\n9           9     Sister    Spitzer      F 1966-10-15         Toronto\n10         10     Cedric   Coltrane      M 1961-11-10         Toronto\n   province_id  allergies height weight\n1           ON       NULL    156     65\n2           ON      Sulfa    185     76\n3           ON Penicillin    194    106\n4           ON       NULL    191    104\n5           ON Penicillin     47     10\n6           ON Penicillin     43      5\n7           ON       NULL    180    117\n8           NS       NULL    174    105\n9           ON Penicillin    173     95\n10          ON       NULL    157     61\n\n\n\n\nIn R use:\n\ndbGetQuery() to run SQL commands from a given data base.\n\nIn SQL use:\n\nSELECT to select.\n(*) to include all columns.\nFROM to define the patients data for select to include all columns from.\nLIMIT to only show the top ten rows.\n\n\nRSQLite::dbGetQuery(hosp, \n                    \"SELECT * \n                     FROM patients \n                     LIMIT 10\"\n                    )\n\n   patient_id first_name  last_name gender birth_date            city\n1           1     Donald Waterfield      M 1963-02-12          Barrie\n2           2     Mickey     Baasha      M 1981-05-28          Dundas\n3           3       Jiji     Sharma      M 1957-09-05        Hamilton\n4           4      Blair       Diaz      M 1967-01-07        Hamilton\n5           5    Charles      Wolfe      M 2017-11-19         Orillia\n6           6        Sue     Falcon      F 2017-09-30            Ajax\n7           7     Thomas     ONeill      M 1993-01-31      Burlington\n8           8      Sonny    Beckett      M 1952-12-11 Port Hawkesbury\n9           9     Sister    Spitzer      F 1966-10-15         Toronto\n10         10     Cedric   Coltrane      M 1961-11-10         Toronto\n   province_id  allergies height weight\n1           ON       NULL    156     65\n2           ON      Sulfa    185     76\n3           ON Penicillin    194    106\n4           ON       NULL    191    104\n5           ON Penicillin     47     10\n6           ON Penicillin     43      5\n7           ON       NULL    180    117\n8           NS       NULL    174    105\n9           ON Penicillin    173     95\n10          ON       NULL    157     61\n\n\n\n\n\n\n\n2. Show total patients admitted.\n\n2.02.1 R2.2 SQL\n\n\nContents\n\n2.1 Solution in R\n2.2 Solution in SQL\n\n\n\nIn R use:\n\ndata.frame() to define a column for total_admissions.\nnrow() to count the rows in the patients data which will equal the total_admissions.\n\n\nbase::data.frame(\"total_admissions\" = base::nrow(patients))\n\n  total_admissions\n1             1000\n\n\n\n\nIn SQL use:\n\nSELECT to select.\nCOUNT(*) to count the total number of rows.\nAS to define that count as a new variable, total_admissions.\nFROM to define the patients data for select to count the total numbers of rows for, and define as total_admissions.\n\n\nRSQLite::dbGetQuery(hosp,\n                    \"SELECT COUNT(*) AS total_admissions \n                     FROM patients\"\n                    )\n\n  total_admissions\n1             1000\n\n\n\n\n\n\n\n3. Show first and last name as full_name.\n\n3.03.1 R3.2 SQL\n\n\nContents\n\n3.1 Solution in R\n3.2 Solution in SQL\n\n\n\nIn R use:\n\nhead() to show the first 10 rows of data.\ndata.frame() to define a data frame that includes full_name.\npaste0() to paste together the first_name, a space, and the last_name. This will equal the full_name.\n\n\nutils::head(\n  base::data.frame(\n    full_name = base::paste0(patients$first_name, \n                             \" \", \n                             patients$last_name)), \n  10)\n\n           full_name\n1  Donald Waterfield\n2      Mickey Baasha\n3        Jiji Sharma\n4         Blair Diaz\n5      Charles Wolfe\n6         Sue Falcon\n7      Thomas ONeill\n8      Sonny Beckett\n9     Sister Spitzer\n10   Cedric Coltrane\n\n\n\n\nIn SQL use:\n\nSELECT to select.\n|| to concatenate first_name, space, and last name.\nAS to define the concatination as full_name.\nFROM to define the patients data for select to concatenate data from.\nLIMIT to show the first 10 rows of data.\n\n\nRSQLite::dbGetQuery(hosp,\n  \"SELECT first_name || ' ' || last_name AS full_name \n   FROM patients \n   LIMIT 10\"\n   )\n\n           full_name\n1  Donald Waterfield\n2      Mickey Baasha\n3        Jiji Sharma\n4         Blair Diaz\n5      Charles Wolfe\n6         Sue Falcon\n7      Thomas ONeill\n8      Sonny Beckett\n9     Sister Spitzer\n10   Cedric Coltrane\n\n\n\n\n\n\n\n4. Show unique cities that are in province_id â€˜NSâ€™?\n\n4.04.1 R4.2 SQL\n\n\nContents\n\n4.1 Solution in R\n4.2 Solution in SQL\n\n\n\nIn R define the patients data then use:\n\n%>% to pipe data.\nfilter() to filter for all province_id that is equal to â€œNSâ€.\nsummerise() to define unique_cites.\nunique() to remove duplicate elements of the city column which will be defined as unique_cites.\n\n\npatients %>% \n  filter(province_id == \"NS\") %>%\n  summarise(unique_cities = unique(city)) \n\n    unique_cities\n1 Port Hawkesbury\n2         Halifax\n\n\n\n\nIn SQL:\n\nSELECT to select.\nDISTINCT() to define city as the column to remove duplicates from.\nAS to define those cities as unique_cites.\nFROM to define the patients data for select to get unique_cites from.\nWHERE specifies a condition.\nIS is the condition that â€˜NSâ€™ is equal to province_id.\n\n\ndbGetQuery(hosp,\n           \"SELECT DISTINCT(city) AS unique_cities \n            FROM patients \n            WHERE province_id IS 'NS'\"\n           )\n\n    unique_cities\n1 Port Hawkesbury\n2         Halifax\n\n\n\n\n\n\n\n5. Show the total number of male patients and the total number of female patients.\nDisplay the two results in the same row.\n\n5.05.1 R5.2 SQL\n\n\nContents\n\n5.1 Solution in R\n5.2 Solution in SQL\n\n\n\nIn R use:\n\ndata.frame() to create a data frame with two columns: male_count, and female_count.\nlength() to count the length of the input.\nwhich() to indicate which gender equals â€œMâ€ or â€œFâ€, and counts that length accordingly.\n\n\nbase::data.frame(\n  male_count = base::length(base::which(patients$gender == 'M')),\n  female_count = base::length(base::which(patients$gender == 'F'))\n  )\n\n  male_count female_count\n1        543          457\n\n\n\n\nIn SQL use:\n\nSELECT to select.\nCOUNT(*) to count all input values.\nFROM to define the patients data for select to count on.\nWHERE is a condition defined as gender = â€œMâ€ or â€œFâ€.\nAS is defining the count as male_count, or female_count respectively.\n\n\ndbGetQuery(hosp,\n           \"SELECT \n           (SELECT COUNT(*) FROM patients WHERE gender = 'M') AS male_count, \n           (SELECT COUNT(*) FROM patients WHERE gender = 'F') AS female_count\")\n\n  male_count female_count\n1        543          457\n\n\n\n\n\n\n\n6. Show all allergies ordered by popularity. Remove NULL values from the query.\n\n6.06.1 R6.2 SQL\n\n\nContents\n\n6.1 Solution in R\n6.2 Solution in SQL\n\n\n\nIn R define the patients data then use:\n\n%>% pipe the data.\nfilter() to subset data to all allergies that arenâ€™t â€œNULLâ€.\ngroup_by() to convert the table into one that is grouped by allergies.\nsummarise() to define total_diagnosis.\nn() to count the size of each group.\narrange() to define how the data is arranged.\ndesc() to define that the data is arranged in descending order by total_diagnosis.\n\n\npatients %>% \n  dplyr::filter(allergies != \"NULL\") %>%\n  dplyr::group_by(allergies) %>%\n  dplyr::summarise(total_diagnosis = dplyr::n()) %>%\n  dplyr::arrange(dplyr::desc(total_diagnosis)) %>%\n  utils::head(10)\n\n# A tibble: 10 Ã— 2\n   allergies   total_diagnosis\n   <chr>                 <int>\n 1 Penicillin              230\n 2 Codeine                  58\n 3 Sulfa                    35\n 4 ASA                      16\n 5 Sulfa Drugs              13\n 6 Tylenol                  11\n 7 Wheat                    11\n 8 Peanuts                  10\n 9 Bee Stings                9\n10 Iodine                    9\n\n\n\n\nIn SQL:\n\nSELECT the allergies column.\nCOUNT(*) count all input.\nAS to define the count as total_diagnosis.\nFROM to define the patients data to select the allergies column from.\nWHERE to define a condition.\nIS NOT is the condition that says allergies cannot be â€˜NULLâ€™.\nGROUP BY groups the data by allergies.\nOrder BY to define how the data order is output.\nDESC is the given condition that the data is ordered in descending order by total_diagnosis.\nLIMIT to limit output to the first 10 rows.\n\n\ndbGetQuery(hosp,\n           \"SELECT allergies,\n            COUNT(*) AS total_diagnosis\n            FROM patients\n            WHERE allergies IS NOT 'NULL'\n            GROUP BY allergies\n            ORDER BY total_diagnosis DESC\n            LIMIT 10\"\n           )\n\n     allergies total_diagnosis\n1   Penicillin             230\n2      Codeine              58\n3        Sulfa              35\n4          ASA              16\n5  Sulfa Drugs              13\n6        Wheat              11\n7      Tylenol              11\n8      Peanuts              10\n9       Iodine               9\n10  Bee Stings               9\n\n\n\n\n\n\n\n7. Display the total number of patients for each province. Order by descending.\n\n7.07.1 R7.1 SQL\n\n\nContents\n\n7.1 Solution in R\n7.2 Solution in SQL\n\n\n\nIn R use:\n\nmerge() to join the data sets province_names, and patients by â€œprovince_idâ€.\n%>% to pipe the data.\ngroup_by() to group by province name.\nsummarise() to define the patient count.\nn() to count the number of patients in each province. This will equal patient_count.\narrange() to define how the data is arranged.\ndesc() to define that the data is arranged in descending order by patient_count.\n\n\nbase::merge(province_names, patients, by = \"province_id\") %>%\n  dplyr::group_by(province_name) %>%\n  dplyr::summarise(patient_count = dplyr::n()) %>%\n  dplyr::arrange(dplyr::desc(patient_count))\n\n# A tibble: 8 Ã— 2\n  province_name             patient_count\n  <chr>                             <int>\n1 Ontario                             954\n2 Alberta                              14\n3 British Columbia                     11\n4 Nova Scotia                           9\n5 Manitoba                              7\n6 Newfoundland and Labrador             2\n7 Quebec                                2\n8 Saskatchewan                          1\n\n\n\n\nIn SQL use:\n\nSELECT select the province_name column.\nCOUNT(*) to count all input.\nAS to define count as patient_count.\nFROM to define the patients data AS pa to select province_name to count the number of patients from.\nJOIN to join the province_names data AS pr.\nON is the clause to join data based on pr.province_id = pa.province_id.\nGROUP BY to group the data by pr.province_id.\nORDER BY to define the order of the data output.\nDESC defines that the output data be arranged in order of descending patient_count.\n\n\nRSQLite::dbGetQuery(hosp,\n                    \"SELECT province_name,\n                     COUNT(*) AS patient_count\n                     FROM patients pa\n                     JOIN province_names pr ON pr.province_id = pa.province_id\n                     GROUP BY pr.province_id\n                     ORDER BY patient_count DESC\")\n\n              province_name patient_count\n1                   Ontario           954\n2                   Alberta            14\n3          British Columbia            11\n4               Nova Scotia             9\n5                  Manitoba             7\n6                    Quebec             2\n7 Newfoundland and Labrador             2\n8              Saskatchewan             1\n\n\n\n\n\n\n\n8. Show the provinces that have more patients identified as â€˜Mâ€™ than â€˜Fâ€™. Must only show full province_name.\n\n8.08.1 R8.2 SQL\n\n\nContents\n\n8.1 Solution in R\n8.2 Solution in SQL\n\n\n\nIn R use,\n\nmerge() to join the data sets province_names, and patients by â€œprovince_idâ€.\ngroup_by() to group by province name.\ncount() to count the number of â€œMâ€ and â€œFâ€ patients for each province.\nslice() to remove certain rows based on a given criteria.\nwhich.max() to determine which province has a greater number of male patients.\nsummarise() to define only province_name in the output.\n\n\nbase::merge(province_names, patients, by = \"province_id\") %>%\n  dplyr::group_by(province_name) %>%\n  dplyr::count(gender == \"M\", gender == \"F\") %>%\n  dplyr::slice(base::which.max(n)) %>%\n  dplyr::summarise(province_name = province_name)\n\n# A tibble: 8 Ã— 1\n  province_name            \n  <chr>                    \n1 Alberta                  \n2 British Columbia         \n3 Manitoba                 \n4 Newfoundland and Labrador\n5 Nova Scotia              \n6 Ontario                  \n7 Quebec                   \n8 Saskatchewan             \n\n\n\n\nIn SQL use,\n\nSELECT to select pr.province_name column.\nFROM to define the patients data to select pr.province_name from.\nAS to define patients data as pa.\nJOIN to join pa.province data with pr.province_name data.\nAS to define province_name data as pr.\nON to join pa.patients and pr.province_names data by province_id.\nGROUP BY to group data by province_id.\nHAVING to define a clause to filter the data where the number of â€œMâ€ patients is greater than â€œFâ€ patients.\nCOUNT() to count the given input.\nCASE to go through the condition of gender = â€œMâ€ or when gender = â€œFâ€\nWHEN to preform the count when the condition is true.\nTHEN 1 END to add a 1 to the count when the case is met.\n\n\nRSQLite::dbGetQuery(hosp,\n                    \"SELECT pr.province_name\n                     FROM patients AS pa\n                     JOIN province_names AS pr ON pa.province_id = pr.province_id\n                     GROUP BY pr.province_id\n                     HAVING\n                     COUNT( CASE WHEN gender = 'M' THEN 1 END) >\n                     COUNT( CASE WHEN gender = 'F' THEN 1 END)\")\n\n              province_name\n1                   Alberta\n2          British Columbia\n3                  Manitoba\n4 Newfoundland and Labrador\n5               Nova Scotia\n6                   Ontario\n7                    Quebec\n8              Saskatchewan\n\n\n\n\n\n\n\n9. Each admission costs $50 for patients without insurance, and $10 for patients with insurance. All patients with an even patient_id have insurance.\nGive each patient a â€˜Yesâ€™ if they have insurance, and a â€˜Noâ€™ if they donâ€™t have insurance. Add up the admission_total cost for each has_insurance group.\n\n9.09.1 R9.2 SQL\n\n\nContents\n\n9.1 Solution in R\n9.2 Solution in SQL\n\n\n\nIn R use,\n\n%>% to pipe the data.\nmutate() to mutate the data to include has_insurance, and cost_after_insurance information.\ncase_when() to define a case where if the patient id is odd then they donâ€™t have insurance, and if they are even they do have insurance.\ngroup_by() to group the data by has_insurance.\nsummarize() to define cost_after_insurance.\nsum() to add up the cost for all those with and without insurance.\n\n\npatients %>%\n  dplyr::mutate(\n    has_insurance = dplyr::case_when(\n    patient_id %%2==1 ~ \"Yes\",\n    patient_id %%2!=1 ~ \"No\"\n  ),cost_after_insurance = dplyr::case_when(\n    has_insurance == \"Yes\" ~ 10,\n    has_insurance == \"No\" ~ 50\n  )) %>%\n  group_by(has_insurance)  %>%\n  summarise(cost_after_insurance = base::sum(cost_after_insurance))\n\n# A tibble: 2 Ã— 2\n  has_insurance cost_after_insurance\n  <chr>                        <dbl>\n1 No                           25000\n2 Yes                           5000\n\n\n\n\nIn SQL use,\n\nSELECT to select.\nCASE to define a case.\nWHEN to select when a patient_id is even.\nTHEN to set insurance to â€œYesâ€ if patient_id is even.\nELSE to set has_insurance to â€œNoâ€ when patient_id is not even.\nEND to end the case.\nAS to define the first case values as has_insurance.\nSUM() to add up input.\nCASE to define another case.\nWHEN to select when a patient has an even id.\nTHEN to set cost_after_insurance to 10 if the patient id is even.\nELSE to set the cost_after_insurance to 50 if the patient id is not even.\nEND to end the case.\nAS to define the second case values as cost_after_insurance.\nFROM to define the patients data to select and figure out insurance costs for.\nGROUP BY to group data by has_insurance.\n\n\nRSQLite::dbGetQuery(hosp,\n                    \"SELECT \n                        CASE WHEN patient_id % 2 = 0 Then 'Yes'\n                        ELSE 'No' \n                        END as has_insurance,\n                     SUM(\n                        CASE WHEN patient_id % 2 = 0 Then 10\n                        ELSE 50 \n                        END\n                         ) AS cost_after_insurance\n                     FROM patients \n                     GROUP BY has_insurance;\")\n\n  has_insurance cost_after_insurance\n1            No                25000\n2           Yes                 5000\n\n\n\n\n\n\n\n10. We are looking for a specific patient. Pull all columns for the patient who matches the following criteria:\n\nFirst_name contains a â€˜bâ€™ after the first two letters.\nIdentifies their gender as â€˜Fâ€™\nTheir weight would be between 50 kg and 70 kg\nTheir patient_id is an odd number\nThey are from the city â€˜Burlingtonâ€™\n\n\n10.010.1 R10.2 SQL\n\n\nContents\n\n10.1 Solution in R\n10.2 Solution in SQL\n\n\n\nIn R define the patients data then use,\n\n%>% to pipe the data.\nfilter to filter the database on first name, gender, weight, patient_id, and city.\ngrepl to select first_names where the 3rd letter is b.\n\n\npatients %>%\n  dplyr::filter(base::grepl(\"^.{2}[b]\", first_name),\n         gender == \"F\",\n         weight > 50 && weight < 80,\n         patient_id %%2==1,\n         city == \"Burlington\")\n\n  patient_id first_name last_name gender birth_date       city province_id\n1        695    Sabrina    Hettie      F 2000-11-25 Burlington          ON\n   allergies height weight\n1 Penicillin    160     51\n\n\n\n\nIn SQL use:\n\nSELECT to select all * columns.\nFROM to select all columns from the patients data.\nWhere defines multiple conditions.\nLIKE is a condition where first_name has the third letter equal to a lower case b.\nAND to define multiple conditions such as gender, patient_id, and city.\nBETWEEN to define weight is greater than 50, but less than 70.\n\n\nRSQLite::dbGetQuery(hosp,\n                    \"SELECT *\n                     FROM patients\n                     WHERE\n                      first_name LIKE '__b%'\n                      AND gender = 'F'\n                      AND weight BETWEEN 50 AND 70\n                      AND patient_id % 2 = 1\n                      AND city = 'Burlington';\")\n\n  patient_id first_name last_name gender birth_date       city province_id\n1        695    Sabrina    Hettie      F 2000-11-25 Burlington          ON\n   allergies height weight\n1 Penicillin    160     51"
  },
  {
    "objectID": "01_qmd-files/index.html",
    "href": "01_qmd-files/index.html",
    "title": "Randi Bolt",
    "section": "",
    "text": "I post bimonthly about a range of topics that are related to data science, statistics, mathematics, or machine learning. Check out my journey, and feel free to leave my posts comments. Iâ€™d love to hear from you!\nThanks for stopping by, and please enjoy!\nðŸ˜˜âœ¨"
  },
  {
    "objectID": "01_qmd-files/about.html",
    "href": "01_qmd-files/about.html",
    "title": "Randi Bolt",
    "section": "",
    "text": "About\nI am a data analyst / scientist based out of Portland, Oregon.\nI have been writing about mathematics, statistics, and data science in my blog since 2021.\nI am constantly exploring new topics, and ways to improve upon past and current work.\nI graduated magna cum laude with a Bachelors of Science in Mathematics from Portland State University in 2022."
  },
  {
    "objectID": "02_blog/2023_01_23_R-and-SQLite/index.html",
    "href": "02_blog/2023_01_23_R-and-SQLite/index.html",
    "title": "R and SQLite",
    "section": "",
    "text": "Naruto with SQL logo, and Sauske with the R Studio logo, standing back to back.\n\n\n\n0. Introduction\nThere are a handful of programming languages that data scientists use when querying, analyzing, and manipulating data. What I have found is that while R and Python have a lot more power in what they are capable of producing, SQL is used by a wider variety of roles to access and query data. So to get more practice using both SQL and R I pulled 10 questions and some data off a website called Learn SQL, and will be answering the following questions in both languages.\n\n0.0 Set-Up0.1 Packages0.2 Data0.3 Database\n\n\nContents:\n\n0.1 Packages\n0.2 Data\n0.3 Data base\n\n\n\nFor all my data queries and manipulation in R I will be using base R, dplyr, and magrittr.\n\nlibrary(dplyr)\nlibrary(magrittr)\n\nTo create a SQL database, and run SQL queries in R chunks I will be using a package called RSQLite.\n\nlibrary(RSQLite)\n\n\n\nThis post will use two data sets that I copied from Learn SQL:\n\npatients: Which includes patient_id, first_name, last_name, gender, birth_date, city, province_id, allergies, height, and weight. Note I only copied the first 1000 entries.\n\n\npatients <- utils::read.csv('../../00_data/patients.csv')\n\n\nprovince_names: Which includes province_id, and province_name.\n\n\nprovince_names <- utils::read.csv(\"../../00_data/province_names.csv\")\n\n\n\nTo create a database use:\n\ndbConnect() to connect to a SQL data base called Hospital.db in the 00_data folder.\nSQLite() to connect to a SQLite database file.\n\n\nhosp <- RSQLite::dbConnect(RSQLite::SQLite(),\n                           \"../../00_data/Hospital.db\")\n\nTo define data within the database use:\n\ndbWriteTable() to create a data set within the hospital database called patients and province_names with the respective data.\n\n\nRSQLite::dbWriteTable(hosp,\n                      \"patients\",\n                      patients)\nRSQLite::dbWriteTable(hosp,\n                      \"province_names\",\n                      province_names)\n\nVerify the two data sets are in the database using:\n\ndbListTables() to list the tables within the hosp database.\n\n\nRSQLite::dbListTables(hosp)\n\n[1] \"patients\"       \"province_names\"\n\n\n\n\n\n\n\n1. Show the first ten rows of patients data.\n\n1.01.1 R1.2 SQL\n\n\nContents\n\n1.1 Solution in R\n1.2 Solution in SQL\n\n\n\nIn R use:\n\nhead() to view the first 10 rows of the patients data.\n\n\nutils::head(patients, 10)\n\n   patient_id first_name  last_name gender birth_date            city\n1           1     Donald Waterfield      M 1963-02-12          Barrie\n2           2     Mickey     Baasha      M 1981-05-28          Dundas\n3           3       Jiji     Sharma      M 1957-09-05        Hamilton\n4           4      Blair       Diaz      M 1967-01-07        Hamilton\n5           5    Charles      Wolfe      M 2017-11-19         Orillia\n6           6        Sue     Falcon      F 2017-09-30            Ajax\n7           7     Thomas     ONeill      M 1993-01-31      Burlington\n8           8      Sonny    Beckett      M 1952-12-11 Port Hawkesbury\n9           9     Sister    Spitzer      F 1966-10-15         Toronto\n10         10     Cedric   Coltrane      M 1961-11-10         Toronto\n   province_id  allergies height weight\n1           ON       NULL    156     65\n2           ON      Sulfa    185     76\n3           ON Penicillin    194    106\n4           ON       NULL    191    104\n5           ON Penicillin     47     10\n6           ON Penicillin     43      5\n7           ON       NULL    180    117\n8           NS       NULL    174    105\n9           ON Penicillin    173     95\n10          ON       NULL    157     61\n\n\n\n\nIn R use:\n\ndbGetQuery() to run SQL commands from a given data base.\n\nIn SQL use:\n\nSELECT to select.\n(*) to include all columns.\nFROM to define the patients data for select to include all columns from.\nLIMIT to only show the top ten rows.\n\n\nRSQLite::dbGetQuery(hosp, \n                    \"SELECT * \n                     FROM patients \n                     LIMIT 10\"\n                    )\n\n   patient_id first_name  last_name gender birth_date            city\n1           1     Donald Waterfield      M 1963-02-12          Barrie\n2           2     Mickey     Baasha      M 1981-05-28          Dundas\n3           3       Jiji     Sharma      M 1957-09-05        Hamilton\n4           4      Blair       Diaz      M 1967-01-07        Hamilton\n5           5    Charles      Wolfe      M 2017-11-19         Orillia\n6           6        Sue     Falcon      F 2017-09-30            Ajax\n7           7     Thomas     ONeill      M 1993-01-31      Burlington\n8           8      Sonny    Beckett      M 1952-12-11 Port Hawkesbury\n9           9     Sister    Spitzer      F 1966-10-15         Toronto\n10         10     Cedric   Coltrane      M 1961-11-10         Toronto\n   province_id  allergies height weight\n1           ON       NULL    156     65\n2           ON      Sulfa    185     76\n3           ON Penicillin    194    106\n4           ON       NULL    191    104\n5           ON Penicillin     47     10\n6           ON Penicillin     43      5\n7           ON       NULL    180    117\n8           NS       NULL    174    105\n9           ON Penicillin    173     95\n10          ON       NULL    157     61\n\n\n\n\n\n\n\n2. Show total patients admitted.\n\n2.02.1 R2.2 SQL\n\n\nContents\n\n2.1 Solution in R\n2.2 Solution in SQL\n\n\n\nIn R use:\n\ndata.frame() to define a column for total_admissions.\nnrow() to count the rows in the patients data which will equal the total_admissions.\n\n\nbase::data.frame(\"total_admissions\" = base::nrow(patients))\n\n  total_admissions\n1             1000\n\n\n\n\nIn SQL use:\n\nSELECT to select.\nCOUNT(*) to count the total number of rows.\nAS to define that count as a new variable, total_admissions.\nFROM to define the patients data for select to count the total numbers of rows for, and define as total_admissions.\n\n\nRSQLite::dbGetQuery(hosp,\n                    \"SELECT COUNT(*) AS total_admissions \n                     FROM patients\"\n                    )\n\n  total_admissions\n1             1000\n\n\n\n\n\n\n\n3. Show first and last name as full_name.\n\n3.03.1 R3.2 SQL\n\n\nContents\n\n3.1 Solution in R\n3.2 Solution in SQL\n\n\n\nIn R use:\n\nhead() to show the first 10 rows of data.\ndata.frame() to define a data frame that includes full_name.\npaste0() to paste together the first_name, a space, and the last_name. This will equal the full_name.\n\n\nutils::head(\n  base::data.frame(\n    full_name = base::paste0(patients$first_name, \n                             \" \", \n                             patients$last_name)), \n  10)\n\n           full_name\n1  Donald Waterfield\n2      Mickey Baasha\n3        Jiji Sharma\n4         Blair Diaz\n5      Charles Wolfe\n6         Sue Falcon\n7      Thomas ONeill\n8      Sonny Beckett\n9     Sister Spitzer\n10   Cedric Coltrane\n\n\n\n\nIn SQL use:\n\nSELECT to select.\n|| to concatenate first_name, space, and last name.\nAS to define the concatination as full_name.\nFROM to define the patients data for select to concatenate data from.\nLIMIT to show the first 10 rows of data.\n\n\nRSQLite::dbGetQuery(hosp,\n  \"SELECT first_name || ' ' || last_name AS full_name \n   FROM patients \n   LIMIT 10\"\n   )\n\n           full_name\n1  Donald Waterfield\n2      Mickey Baasha\n3        Jiji Sharma\n4         Blair Diaz\n5      Charles Wolfe\n6         Sue Falcon\n7      Thomas ONeill\n8      Sonny Beckett\n9     Sister Spitzer\n10   Cedric Coltrane\n\n\n\n\n\n\n\n4. Show unique cities that are in province_id â€˜NSâ€™?\n\n4.04.1 R4.2 SQL\n\n\nContents\n\n4.1 Solution in R\n4.2 Solution in SQL\n\n\n\nIn R define the patients data then use:\n\n%>% to pipe data.\nfilter() to filter for all province_id that is equal to â€œNSâ€.\nsummerise() to define unique_cites.\nunique() to remove duplicate elements of the city column which will be defined as unique_cites.\n\n\npatients %>% \n  filter(province_id == \"NS\") %>%\n  summarise(unique_cities = unique(city)) \n\n    unique_cities\n1 Port Hawkesbury\n2         Halifax\n\n\n\n\nIn SQL:\n\nSELECT to select.\nDISTINCT() to define city as the column to remove duplicates from.\nAS to define those cities as unique_cites.\nFROM to define the patients data for select to get unique_cites from.\nWHERE specifies a condition.\nIS is the condition that â€˜NSâ€™ is equal to province_id.\n\n\ndbGetQuery(hosp,\n           \"SELECT DISTINCT(city) AS unique_cities \n            FROM patients \n            WHERE province_id IS 'NS'\"\n           )\n\n    unique_cities\n1 Port Hawkesbury\n2         Halifax\n\n\n\n\n\n\n\n5. Show the total number of male patients and the total number of female patients.\nDisplay the two results in the same row.\n\n5.05.1 R5.2 SQL\n\n\nContents\n\n5.1 Solution in R\n5.2 Solution in SQL\n\n\n\nIn R use:\n\ndata.frame() to create a data frame with two columns: male_count, and female_count.\nlength() to count the length of the input.\nwhich() to indicate which gender equals â€œMâ€ or â€œFâ€, and counts that length accordingly.\n\n\nbase::data.frame(\n  male_count = base::length(base::which(patients$gender == 'M')),\n  female_count = base::length(base::which(patients$gender == 'F'))\n  )\n\n  male_count female_count\n1        543          457\n\n\n\n\nIn SQL use:\n\nSELECT to select.\nCOUNT(*) to count all input values.\nFROM to define the patients data for select to count on.\nWHERE is a condition defined as gender = â€œMâ€ or â€œFâ€.\nAS is defining the count as male_count, or female_count respectively.\n\n\ndbGetQuery(hosp,\n           \"SELECT \n           (SELECT COUNT(*) FROM patients WHERE gender = 'M') AS male_count, \n           (SELECT COUNT(*) FROM patients WHERE gender = 'F') AS female_count\")\n\n  male_count female_count\n1        543          457\n\n\n\n\n\n\n\n6. Show all allergies ordered by popularity. Remove NULL values from the query.\n\n6.06.1 R6.2 SQL\n\n\nContents\n\n6.1 Solution in R\n6.2 Solution in SQL\n\n\n\nIn R define the patients data then use:\n\n%>% pipe the data.\nfilter() to subset data to all allergies that arenâ€™t â€œNULLâ€.\ngroup_by() to convert the table into one that is grouped by allergies.\nsummarise() to define total_diagnosis.\nn() to count the size of each group.\narrange() to define how the data is arranged.\ndesc() to define that the data is arranged in descending order by total_diagnosis.\n\n\npatients %>% \n  dplyr::filter(allergies != \"NULL\") %>%\n  dplyr::group_by(allergies) %>%\n  dplyr::summarise(total_diagnosis = dplyr::n()) %>%\n  dplyr::arrange(dplyr::desc(total_diagnosis)) %>%\n  utils::head(10)\n\n# A tibble: 10 Ã— 2\n   allergies   total_diagnosis\n   <chr>                 <int>\n 1 Penicillin              230\n 2 Codeine                  58\n 3 Sulfa                    35\n 4 ASA                      16\n 5 Sulfa Drugs              13\n 6 Tylenol                  11\n 7 Wheat                    11\n 8 Peanuts                  10\n 9 Bee Stings                9\n10 Iodine                    9\n\n\n\n\nIn SQL:\n\nSELECT the allergies column.\nCOUNT(*) count all input.\nAS to define the count as total_diagnosis.\nFROM to define the patients data to select the allergies column from.\nWHERE to define a condition.\nIS NOT is the condition that says allergies cannot be â€˜NULLâ€™.\nGROUP BY groups the data by allergies.\nOrder BY to define how the data order is output.\nDESC is the given condition that the data is ordered in descending order by total_diagnosis.\nLIMIT to limit output to the first 10 rows.\n\n\ndbGetQuery(hosp,\n           \"SELECT allergies,\n            COUNT(*) AS total_diagnosis\n            FROM patients\n            WHERE allergies IS NOT 'NULL'\n            GROUP BY allergies\n            ORDER BY total_diagnosis DESC\n            LIMIT 10\"\n           )\n\n     allergies total_diagnosis\n1   Penicillin             230\n2      Codeine              58\n3        Sulfa              35\n4          ASA              16\n5  Sulfa Drugs              13\n6        Wheat              11\n7      Tylenol              11\n8      Peanuts              10\n9       Iodine               9\n10  Bee Stings               9\n\n\n\n\n\n\n\n7. Display the total number of patients for each province. Order by descending.\n\n7.07.1 R7.1 SQL\n\n\nContents\n\n7.1 Solution in R\n7.2 Solution in SQL\n\n\n\nIn R use:\n\nmerge() to join the data sets province_names, and patients by â€œprovince_idâ€.\n%>% to pipe the data.\ngroup_by() to group by province name.\nsummarise() to define the patient count.\nn() to count the number of patients in each province. This will equal patient_count.\narrange() to define how the data is arranged.\ndesc() to define that the data is arranged in descending order by patient_count.\n\n\nbase::merge(province_names, patients, by = \"province_id\") %>%\n  dplyr::group_by(province_name) %>%\n  dplyr::summarise(patient_count = dplyr::n()) %>%\n  dplyr::arrange(dplyr::desc(patient_count))\n\n# A tibble: 8 Ã— 2\n  province_name             patient_count\n  <chr>                             <int>\n1 Ontario                             954\n2 Alberta                              14\n3 British Columbia                     11\n4 Nova Scotia                           9\n5 Manitoba                              7\n6 Newfoundland and Labrador             2\n7 Quebec                                2\n8 Saskatchewan                          1\n\n\n\n\nIn SQL use:\n\nSELECT select the province_name column.\nCOUNT(*) to count all input.\nAS to define count as patient_count.\nFROM to define the patients data AS pa to select province_name to count the number of patients from.\nJOIN to join the province_names data AS pr.\nON is the clause to join data based on pr.province_id = pa.province_id.\nGROUP BY to group the data by pr.province_id.\nORDER BY to define the order of the data output.\nDESC defines that the output data be arranged in order of descending patient_count.\n\n\nRSQLite::dbGetQuery(hosp,\n                    \"SELECT province_name,\n                     COUNT(*) AS patient_count\n                     FROM patients pa\n                     JOIN province_names pr ON pr.province_id = pa.province_id\n                     GROUP BY pr.province_id\n                     ORDER BY patient_count DESC\")\n\n              province_name patient_count\n1                   Ontario           954\n2                   Alberta            14\n3          British Columbia            11\n4               Nova Scotia             9\n5                  Manitoba             7\n6                    Quebec             2\n7 Newfoundland and Labrador             2\n8              Saskatchewan             1\n\n\n\n\n\n\n\n8. Show the provinces that have more patients identified as â€˜Mâ€™ than â€˜Fâ€™. Must only show full province_name.\n\n8.08.1 R8.2 SQL\n\n\nContents\n\n8.1 Solution in R\n8.2 Solution in SQL\n\n\n\nIn R use,\n\nmerge() to join the data sets province_names, and patients by â€œprovince_idâ€.\ngroup_by() to group by province name.\ncount() to count the number of â€œMâ€ and â€œFâ€ patients for each province.\nslice() to remove certain rows based on a given criteria.\nwhich.max() to determine which province has a greater number of male patients.\nsummarise() to define only province_name in the output.\n\n\nbase::merge(province_names, patients, by = \"province_id\") %>%\n  dplyr::group_by(province_name) %>%\n  dplyr::count(gender == \"M\", gender == \"F\") %>%\n  dplyr::slice(base::which.max(n)) %>%\n  dplyr::summarise(province_name = province_name)\n\n# A tibble: 8 Ã— 1\n  province_name            \n  <chr>                    \n1 Alberta                  \n2 British Columbia         \n3 Manitoba                 \n4 Newfoundland and Labrador\n5 Nova Scotia              \n6 Ontario                  \n7 Quebec                   \n8 Saskatchewan             \n\n\n\n\nIn SQL use,\n\nSELECT to select pr.province_name column.\nFROM to define the patients data to select pr.province_name from.\nAS to define patients data as pa.\nJOIN to join pa.province data with pr.province_name data.\nAS to define province_name data as pr.\nON to join pa.patients and pr.province_names data by province_id.\nGROUP BY to group data by province_id.\nHAVING to define a clause to filter the data where the number of â€œMâ€ patients is greater than â€œFâ€ patients.\nCOUNT() to count the given input.\nCASE to go through the condition of gender = â€œMâ€ or when gender = â€œFâ€\nWHEN to preform the count when the condition is true.\nTHEN 1 END to add a 1 to the count when the case is met.\n\n\nRSQLite::dbGetQuery(hosp,\n                    \"SELECT pr.province_name\n                     FROM patients AS pa\n                     JOIN province_names AS pr ON pa.province_id = pr.province_id\n                     GROUP BY pr.province_id\n                     HAVING\n                     COUNT( CASE WHEN gender = 'M' THEN 1 END) >\n                     COUNT( CASE WHEN gender = 'F' THEN 1 END)\")\n\n              province_name\n1                   Alberta\n2          British Columbia\n3                  Manitoba\n4 Newfoundland and Labrador\n5               Nova Scotia\n6                   Ontario\n7                    Quebec\n8              Saskatchewan\n\n\n\n\n\n\n\n9. Each admission costs $50 for patients without insurance, and $10 for patients with insurance. All patients with an even patient_id have insurance.\nGive each patient a â€˜Yesâ€™ if they have insurance, and a â€˜Noâ€™ if they donâ€™t have insurance. Add up the admission_total cost for each has_insurance group.\n\n9.09.1 R9.2 SQL\n\n\nContents\n\n9.1 Solution in R\n9.2 Solution in SQL\n\n\n\nIn R use,\n\n%>% to pipe the data.\nmutate() to mutate the data to include has_insurance, and cost_after_insurance information.\ncase_when() to define a case where if the patient id is odd then they donâ€™t have insurance, and if they are even they do have insurance.\ngroup_by() to group the data by has_insurance.\nsummarize() to define cost_after_insurance.\nsum() to add up the cost for all those with and without insurance.\n\n\npatients %>%\n  dplyr::mutate(\n    has_insurance = dplyr::case_when(\n    patient_id %%2==1 ~ \"Yes\",\n    patient_id %%2!=1 ~ \"No\"\n  ),cost_after_insurance = dplyr::case_when(\n    has_insurance == \"Yes\" ~ 10,\n    has_insurance == \"No\" ~ 50\n  )) %>%\n  group_by(has_insurance)  %>%\n  summarise(cost_after_insurance = base::sum(cost_after_insurance))\n\n# A tibble: 2 Ã— 2\n  has_insurance cost_after_insurance\n  <chr>                        <dbl>\n1 No                           25000\n2 Yes                           5000\n\n\n\n\nIn SQL use,\n\nSELECT to select.\nCASE to define a case.\nWHEN to select when a patient_id is even.\nTHEN to set insurance to â€œYesâ€ if patient_id is even.\nELSE to set has_insurance to â€œNoâ€ when patient_id is not even.\nEND to end the case.\nAS to define the first case values as has_insurance.\nSUM() to add up input.\nCASE to define another case.\nWHEN to select when a patient has an even id.\nTHEN to set cost_after_insurance to 10 if the patient id is even.\nELSE to set the cost_after_insurance to 50 if the patient id is not even.\nEND to end the case.\nAS to define the second case values as cost_after_insurance.\nFROM to define the patients data to select and figure out insurance costs for.\nGROUP BY to group data by has_insurance.\n\n\nRSQLite::dbGetQuery(hosp,\n                    \"SELECT \n                        CASE WHEN patient_id % 2 = 0 Then 'Yes'\n                        ELSE 'No' \n                        END as has_insurance,\n                     SUM(\n                        CASE WHEN patient_id % 2 = 0 Then 10\n                        ELSE 50 \n                        END\n                         ) AS cost_after_insurance\n                     FROM patients \n                     GROUP BY has_insurance;\")\n\n  has_insurance cost_after_insurance\n1            No                25000\n2           Yes                 5000\n\n\n\n\n\n\n\n10. We are looking for a specific patient. Pull all columns for the patient who matches the following criteria:\n\nFirst_name contains a â€˜bâ€™ after the first two letters.\nIdentifies their gender as â€˜Fâ€™\nTheir weight would be between 50 kg and 70 kg\nTheir patient_id is an odd number\nThey are from the city â€˜Burlingtonâ€™\n\n\n10.010.1 R10.2 SQL\n\n\nContents\n\n10.1 Solution in R\n10.2 Solution in SQL\n\n\n\nIn R define the patients data then use,\n\n%>% to pipe the data.\nfilter to filter the database on first name, gender, weight, patient_id, and city.\ngrepl to select first_names where the 3rd letter is b.\n\n\npatients %>%\n  dplyr::filter(base::grepl(\"^.{2}[b]\", first_name),\n         gender == \"F\",\n         weight > 50 && weight < 80,\n         patient_id %%2==1,\n         city == \"Burlington\")\n\n  patient_id first_name last_name gender birth_date       city province_id\n1        695    Sabrina    Hettie      F 2000-11-25 Burlington          ON\n   allergies height weight\n1 Penicillin    160     51\n\n\n\n\nIn SQL use:\n\nSELECT to select all * columns.\nFROM to select all columns from the patients data.\nWhere defines multiple conditions.\nLIKE is a condition where first_name has the third letter equal to a lower case b.\nAND to define multiple conditions such as gender, patient_id, and city.\nBETWEEN to define weight is greater than 50, but less than 70.\n\n\nRSQLite::dbGetQuery(hosp,\n                    \"SELECT *\n                     FROM patients\n                     WHERE\n                      first_name LIKE '__b%'\n                      AND gender = 'F'\n                      AND weight BETWEEN 50 AND 70\n                      AND patient_id % 2 = 1\n                      AND city = 'Burlington';\")\n\n  patient_id first_name last_name gender birth_date       city province_id\n1        695    Sabrina    Hettie      F 2000-11-25 Burlington          ON\n   allergies height weight\n1 Penicillin    160     51"
  },
  {
    "objectID": "01_qmd-files/blog.html",
    "href": "01_qmd-files/blog.html",
    "title": "Blog",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "01_blog/2023_01_02_SportsObserveR-package/index.html",
    "href": "01_blog/2023_01_02_SportsObserveR-package/index.html",
    "title": "SportsObserveR - Part 2: Creating a Package in R",
    "section": "",
    "text": "In this tutorial I will be taking the functions I created in my previous post, SportsObserveR - Part 1: Scraping Functions, and using them to create my own package, SportsObserveR."
  },
  {
    "objectID": "01_blog/2023_01_02_SportsObserveR-package/index.html#technologies",
    "href": "01_blog/2023_01_02_SportsObserveR-package/index.html#technologies",
    "title": "SportsObserveR - Part 2: Creating a Package in R",
    "section": "0.1 Technologies",
    "text": "0.1 Technologies\nTo build a package in R you need three things:\n\nR installed on your computer.\nA coding editor such as R Studio, or Sublime.\nA bash terminal."
  },
  {
    "objectID": "01_blog/2023_01_02_SportsObserveR-package/index.html#creating-the-function",
    "href": "01_blog/2023_01_02_SportsObserveR-package/index.html#creating-the-function",
    "title": "SportsObserveR - Part 2: Creating a Package in R",
    "section": "8.1 Creating the Function",
    "text": "8.1 Creating the Function\nFrom the R Studio Console, create the function file, and load it into your enviroment.\n\nuse_r(\"scrape_nba_player_stats\")\n\n\nload_all()\n\nIn the R file named â€œscrape_nba_player_stats.Râ€ copy the code below:\n\n#' Scrapes NBA player stats tables off basketball-reference.com.\n#'\n#'@import rvest \n#'@import magrittr\n#'\n#'@param name is a char string that corresponds to the players name.\n#'@param stats_tb is a char string that corresponds to the statistics table such as #per_game, #totals, #per_36_minutes, and #advanced.\n#'\n#'@return a data frame of statistics for a specific NBA player. \n#'@export\n#'\n#'@examples\n#'scrape_nba_player_stats(\"Allen Iverson\", \"#per_game\")\nscrape_nba_player_stats <- function(name, stats_tb){\n  # make name lower case\n  lower_case_name <- base::tolower(name)\n\n  # split name \n  split_name <- base::strsplit(lower_case_name, \" +\")[[1]]\n\n  # define first and last name\n  first_name <- split_name[[1]]\n  last_name <- split_name[[2]]\n  \n  # first letter of last name\n  letter <- base::substr(last_name, 1,1)\n  \n  # first five letters of last name \n  last_5 <- base::substr(last_name, 1, 5)\n  \n  # first two letters of first name\n  first_2 <- base::substr(first_name, 1,2)\n  \n  # define team page URL\n  url <- base::paste0(\"https://www.basketball-reference.com/players/\",letter ,\"/\",last_5,first_2,\"01.html\")\n  \n  # Read stats table\n  stats_tb <- url %>%\n  read_html %>%\n  html_node(stats_tb) %>% \n  html_table()\n  \n  # Rename Column 2 to Name \n  names(stats_tb)[2] <- \"Name\"\n  \n  # Replace NA values with 0 (for stat functions)\n  stats_tb[base::is.na(stats_tb)] <- 0\n  \n  # make list a dataframe\n  df <- base::data.frame(stats_tb)\n  \n  base::return(df)\n  }\n\nNow save this file, and in the R Studio Console type document() to create documentation for this function.\n\ndocument()\n\nCheck that the documentation works:\n\n?scrape_nba_player_stats()\n\nUse the check() function to look at any potential errors.\n\ncheck()\n\nIf everything looks good, from the Bash Terminal push this code to github.\n\ngit status\n\n\ngit add --all\n\n\ngit status\n\n\ngit commit -m\"Created second function\"\n\n\ngit push origin main"
  },
  {
    "objectID": "01_blog/2023_01_02_SportsObserveR-package/index.html#creating-tests-1",
    "href": "01_blog/2023_01_02_SportsObserveR-package/index.html#creating-tests-1",
    "title": "SportsObserveR - Part 2: Creating a Package in R",
    "section": "8.2 Creating Tests",
    "text": "8.2 Creating Tests\nFrom the R Studio Console use use_test() again to create a test file for scrape_nba_player_stats().\n\nuse_test(\"scrape_nba_player_stats\")\n\nNext create a similar code to what was previously done for scrape_nba_team_stats().\n\ntest_that(\"Returns that typeof is list.\", {\n  expect_equal(typeof(scrape_nba_player_stats(\"Kareem Abdul-Jabbar\", \"#totals\")),\n               \"list\")\n})\n\nCheck for errors.\n\ncheck()\n\nIf everything looks green, from the Bash Terminal push to Github.\n\ngit status\n\n\ngit add --all\n\n\ngit status\n\n\ngit commit -m\"Created test for scrape_nba_player_stats\"\n\n\ngit push origin main"
  },
  {
    "objectID": "01_blog/2023_01_02_SportsObserveR-package/index.html#update-readme",
    "href": "01_blog/2023_01_02_SportsObserveR-package/index.html#update-readme",
    "title": "SportsObserveR - Part 2: Creating a Package in R",
    "section": "8.3 Update README",
    "text": "8.3 Update README\nAdd another example to the readme.rmd file using the scrape_nba_player_stats() function, and then update the .md file.\n\nbuild_readme()\n\nFrom the Bash Terminal push this update to Github.\n\ngit status\n\n\ngit add --all\n\n\ngit status\n\n\ngit commit -m\"added scrape_nba_player_stats example to readme\"\n\n\ngit push origin main"
  },
  {
    "objectID": "dictionary.html",
    "href": "dictionary.html",
    "title": "Terminology",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "02_terminology/Statistics/index.html",
    "href": "02_terminology/Statistics/index.html",
    "title": "Statistics",
    "section": "",
    "text": "COMING SOON!!"
  },
  {
    "objectID": "terminology.html",
    "href": "terminology.html",
    "title": "terminology",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "02_terminology/Machine-Learning/index.html",
    "href": "02_terminology/Machine-Learning/index.html",
    "title": "Machine Learning",
    "section": "",
    "text": "COMING SOON!!"
  },
  {
    "objectID": "02_terms/Statistics/index.html",
    "href": "02_terms/Statistics/index.html",
    "title": "Statistics",
    "section": "",
    "text": "COMING SOON!!"
  },
  {
    "objectID": "02_terms/Machine-Learning/index.html",
    "href": "02_terms/Machine-Learning/index.html",
    "title": "Machine Learning",
    "section": "",
    "text": "COMING SOON!!"
  }
]