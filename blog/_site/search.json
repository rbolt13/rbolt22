[
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "1 + 1\n\n[1] 2\n\n\nTry again.\n\nx <- data.frame(x = c(\"1\",\"2\",\"3\"), y = c(\"a\",\"b\",\"c\"))\nx\n\n  x y\n1 1 a\n2 2 b\n3 3 c"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesnâ€™t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Randi Bolt",
    "section": "",
    "text": "This website is currently under construction so be sure to check out the links below and my old blog which showcases all of my academic and personal projects from undergrad.\nI post bimonthly about a range of topics that are related to data science, statistics, mathematics, or machine learning. Check out my journey, and feel free to leave my posts comments. Iâ€™d love to hear from you!\nThanks for stopping by, and please enjoy!\nðŸ˜˜âœ¨"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Randi",
    "section": "",
    "text": "I graduated magna cum laude with a Bachelors of Science in Mathematics from Portland State University in 2022 with an emphasis on statistics. Since most of my undergrad was during COVID-19 lock down Iâ€™ve become proficient at collaborating remotely. I ran remote study groups through discord, participated in the GIS (Geographic Information Systems) club, spoke virtually at G.I.S. in Action, and in the summer of 2021 created my first blog.\nCurrently I am looking for work as a data analyst, data scientist, or a machine learning engineer. My hope is that this blog will not only showcase my technical skills in these areas, but also my determination, adaptability, and perseverance.\n\nPersonal\nðŸ©° Before I went to back to school to get my degree in mathematics I was a dancer. I have trained pre-professionally at Dance Vision and The SanFrancisco Conservatory of Dance. My favorite dance styles are ballet, hip-hop, and modern, but I love all kinds of dance and will try any form of movement. I unfortunately an not able to dance as much anymore due to a car accident in 2014 which required me to have two separate jaw surgeries in 2016 and 2017.\nðŸ‡¯ðŸ‡µ In high school I took Japanese, and have been appreciative of the culture ever since. Recently I bought plane tickets to visit Japan for the first time for my 30th birthday in 2023. While Iâ€™d still consider myself a beginner at speaking, writing, and reading the language, I am very much looking forward to the experience.\nðŸ€ I enjoy most sports, but especially soccor and basketball. Itâ€™s a great way to do hobby statistics, and get rowdy ðŸ˜œ. Growing up both of my sisters, and dad played basketball so I watched a lot of games, and I still enjoy watching the NBA and WNBA. My favorite NBA teams are the Portland Trail Blazers, Phoenix Suns, and New Orleans Pelicans.\nðŸŽ® I have a switch, and when I am not working on my blog I play Stardew Valley, Cat Cafe Manager, Unpacking, Mario Carts, Pokemon Legends Arceus, Animal Crossing, and most recently Just Dance.\n\nðŸ“šBooks Iâ€™m Currently ReadingðŸ“š\nBasketball Analytics\nEtiquette Guide to Japan\nWeapons of Math Destruction\n\nðŸŽ¶Music Iâ€™m Currently Listening ToðŸŽ¶\nFace Your Fears - Crazy Ex Girlfriend\nI Owe You Nothing\nNever Thought - Mel Bryant\nPudgy - Smino\nSupremacy - Muse\n\nðŸŽ¥Movies Iâ€™ve Watched RecentlyðŸŽ¥\nPearl\nX\nHellraiser (Remake, 1,2,3,4,5,6,7,8,9)\nThe Father"
  },
  {
    "objectID": "posts/life-update/index.html",
    "href": "posts/life-update/index.html",
    "title": "Life Update",
    "section": "",
    "text": "Here is a post."
  },
  {
    "objectID": "journal.html",
    "href": "journal.html",
    "title": "Misc",
    "section": "",
    "text": "2022 10 October\n\n\n\n\n\n\n\n\n\n\n\nOct 14, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2022 10 October\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2022 10 October\n\n\n\n\n\n\n\n\n\n\n\nOct 8, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2022 10 October\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n2022 10 October\n\n\n\n\n\n\n\n\n\n\n\nOct 6, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n2022 13 August\n\n\n\n\n\n\n\n\n\n\n\nAug 13, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2022 06 June\n\n\n\n\n\n\n\n\n\n\n\nJun 21, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n2022 06 June\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n2022 04 April\n\n\n\n\n\n\n\n\n\n\n\nApr 21, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "journal/life-update/index.html",
    "href": "journal/life-update/index.html",
    "title": "August 13th, 2022",
    "section": "",
    "text": "Hello hello! Welcome to the first post of my âœ¨new blogâœ¨ . Iâ€™ve started this Journal to help develop my written skills and hopefully boost my confidence when communicating complicated subject matter.\nFor this first post Iâ€™ve decided to give a life update on some of the big events of the last six months."
  },
  {
    "objectID": "journal/2022-10-06/index.html",
    "href": "journal/2022-10-06/index.html",
    "title": "October 6th, 2022",
    "section": "",
    "text": "Tim and Sam from the telivision show Detroiters making suprised faces."
  },
  {
    "objectID": "journal/life-update/index.html#april-2022",
    "href": "journal/life-update/index.html#april-2022",
    "title": "August 13th, 2022",
    "section": "April 2022",
    "text": "April 2022\nMy partner and I bought a house ðŸ’—"
  },
  {
    "objectID": "journal/life-update/index.html#june-2022",
    "href": "journal/life-update/index.html#june-2022",
    "title": "August 13th, 2022",
    "section": "June 2022",
    "text": "June 2022\nI graduated magna cum laude from Portland State University with my Bachelors of Science in Mathematics.\nI also started my job as a Product Owner (software analyst expert?), thanks to a referral by my friend Amy."
  },
  {
    "objectID": "journal/life-update/index.html#august-2022",
    "href": "journal/life-update/index.html#august-2022",
    "title": "August 13th, 2022",
    "section": "August 2022",
    "text": "August 2022\nMy sister got married.\n\n\n\nPhoto of my family from my sisterâ€™s wedding."
  },
  {
    "objectID": "journal/life-update/index.html#october-2022",
    "href": "journal/life-update/index.html#october-2022",
    "title": "August 13th, 2022",
    "section": "October 2022",
    "text": "October 2022\nI created this blog, and my partner set up plex."
  },
  {
    "objectID": "journal/2022-04-21/index.html",
    "href": "journal/2022-04-21/index.html",
    "title": "April 21st, 2022",
    "section": "",
    "text": "My Partner Tanner and I bought a house."
  },
  {
    "objectID": "journal/2022-10-08/index.html",
    "href": "journal/2022-10-08/index.html",
    "title": "October 8th, 2022",
    "section": "",
    "text": "Wasnâ€™t able to work on my blog as much as I would have liked, because the internet was down. However we did get some yard work and house chores done.\nTomorrow I am going on a wine tasting with some people who work for the same company as me. My friend who got me the job, also set up the wine tasting. Iâ€™m nervous, but looking forward to it."
  },
  {
    "objectID": "journal/2022-10-07/index.html",
    "href": "journal/2022-10-07/index.html",
    "title": "October 7th, 2022",
    "section": "",
    "text": "I did another Linkedin Learn video today on web scrapping and natural language processing. Tomorrow Iâ€™m hoping to spend more time on my blog.\nIâ€™m just keeping my head down at work, and trying to figure out more productive ways to interact with my coworkers. It will be helpful to use the long weekend to clear my head."
  },
  {
    "objectID": "journal/2022-06-21/index.html",
    "href": "journal/2022-06-21/index.html",
    "title": "June 21st, 2022",
    "section": "",
    "text": "I started my first day as a product owner / software analyst at finastra."
  },
  {
    "objectID": "journal/2022-08-13/index.html",
    "href": "journal/2022-08-13/index.html",
    "title": "August 13th, 2022",
    "section": "",
    "text": "Photo of my family from my sisterâ€™s wedding."
  },
  {
    "objectID": "journal/2022-08-13/index.html#april-2022",
    "href": "journal/2022-08-13/index.html#april-2022",
    "title": "August 13th, 2022",
    "section": "April 2022",
    "text": "April 2022\nMy partner and I bought a house ðŸ’—"
  },
  {
    "objectID": "journal/2022-08-13/index.html#june-2022",
    "href": "journal/2022-08-13/index.html#june-2022",
    "title": "August 13th, 2022",
    "section": "June 2022",
    "text": "June 2022\nI graduated magna cum laude from Portland State University with my Bachelors of Science in Mathematics.\nI also started my job as a Product Owner (software analyst expert?), thanks to a referral by my friend Amy."
  },
  {
    "objectID": "journal/2022-08-13/index.html#august-2022",
    "href": "journal/2022-08-13/index.html#august-2022",
    "title": "August 13th, 2022",
    "section": "August 2022",
    "text": "August 2022\nMy sister got married.\n\n\n\nPhoto of my family from my sisterâ€™s wedding."
  },
  {
    "objectID": "journal/2022-08-13/index.html#october-2022",
    "href": "journal/2022-08-13/index.html#october-2022",
    "title": "August 13th, 2022",
    "section": "October 2022",
    "text": "October 2022\nI created this blog, and my partner set up plex."
  },
  {
    "objectID": "journal/2022-06-12/index.html",
    "href": "journal/2022-06-12/index.html",
    "title": "June 12th, 2022",
    "section": "",
    "text": "I graduated magna cum laude from Portland State University with my Bachelors of Science in Mathematics."
  },
  {
    "objectID": "misc/2022-08-13/index.html",
    "href": "misc/2022-08-13/index.html",
    "title": "August 13th, 2022",
    "section": "",
    "text": "Photo of my family from my sisterâ€™s wedding."
  },
  {
    "objectID": "misc/2022-04-21/index.html",
    "href": "misc/2022-04-21/index.html",
    "title": "April 21st, 2022",
    "section": "",
    "text": "My Partner Tanner and I bought a house."
  },
  {
    "objectID": "misc/2022-06-12/index.html",
    "href": "misc/2022-06-12/index.html",
    "title": "June 12th, 2022",
    "section": "",
    "text": "I graduated magna cum laude from Portland State University with my Bachelors of Science in Mathematics."
  },
  {
    "objectID": "misc/2022-06-21/index.html",
    "href": "misc/2022-06-21/index.html",
    "title": "June 21st, 2022",
    "section": "",
    "text": "I started my first day as a product owner / software analyst at finastra."
  },
  {
    "objectID": "misc/2022-10-08/index.html",
    "href": "misc/2022-10-08/index.html",
    "title": "October 8th, 2022",
    "section": "",
    "text": "Tanner got the compost bin set up and some weeds pulled."
  },
  {
    "objectID": "misc/2022-10-06/index.html",
    "href": "misc/2022-10-06/index.html",
    "title": "October 6th, 2022",
    "section": "",
    "text": "Tim and Sam from the telivision show Detroiters making suprised faces."
  },
  {
    "objectID": "misc/2022-10-07/index.html",
    "href": "misc/2022-10-07/index.html",
    "title": "October 7th, 2022",
    "section": "",
    "text": "â€œCan you keep the deep water still and clear, so it reflects without blurring?â€ - Techniques, Tao Te Ching"
  },
  {
    "objectID": "misc/2022-10-10/index.html",
    "href": "misc/2022-10-10/index.html",
    "title": "Octorber 10th, 2022",
    "section": "",
    "text": "The full moon in October is the Hunterâ€™s Moon."
  },
  {
    "objectID": "datsci.html",
    "href": "datsci.html",
    "title": "Data Science",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "datsci/post-with-code/index.html",
    "href": "datsci/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "1 + 1\n\n[1] 2\n\n\nTry again.\n\nx <- data.frame(x = c(\"1\",\"2\",\"3\"), y = c(\"a\",\"b\",\"c\"))\nx\n\n  x y\n1 1 a\n2 2 b\n3 3 c"
  },
  {
    "objectID": "datsci/welcome/index.html",
    "href": "datsci/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesnâ€™t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "misc/2022-10-14/index.html",
    "href": "misc/2022-10-14/index.html",
    "title": "October 14th, 2022",
    "section": "",
    "text": "Headphones on. Do not disturb mode activated."
  },
  {
    "objectID": "00_index.html",
    "href": "00_index.html",
    "title": "Randi Bolt",
    "section": "",
    "text": "Hello, and welcome to my blog!!"
  },
  {
    "objectID": "03_misc.html",
    "href": "03_misc.html",
    "title": "Miscellaneous",
    "section": "",
    "text": "2022 10 October\n\n\n\n\n\n\n\n\n\n\n\nOct 14, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2022 10 October\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2022 10 October\n\n\n\n\n\n\n\n\n\n\n\nOct 8, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2022 10 October\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n2022 10 October\n\n\n\n\n\n\n\n\n\n\n\nOct 6, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n2022 13 August\n\n\n\n\n\n\n\n\n\n\n\nAug 13, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2022 06 June\n\n\n\n\n\n\n\n\n\n\n\nJun 21, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n2022 06 June\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n2022 04 April\n\n\n\n\n\n\n\n\n\n\n\nApr 21, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "03_misc/2022-10-10/index.html",
    "href": "03_misc/2022-10-10/index.html",
    "title": "Octorber 10th, 2022",
    "section": "",
    "text": "The full moon in October is the Hunterâ€™s Moon."
  },
  {
    "objectID": "03_misc/2022-08-13/index.html",
    "href": "03_misc/2022-08-13/index.html",
    "title": "August 13th, 2022",
    "section": "",
    "text": "Photo of my family from my sisterâ€™s wedding."
  },
  {
    "objectID": "03_misc/2022-04-21/index.html",
    "href": "03_misc/2022-04-21/index.html",
    "title": "April 21st, 2022",
    "section": "",
    "text": "My Partner Tanner and I bought a house."
  },
  {
    "objectID": "03_misc/2022-06-12/index.html",
    "href": "03_misc/2022-06-12/index.html",
    "title": "June 12th, 2022",
    "section": "",
    "text": "I graduated magna cum laude from Portland State University with my Bachelors of Science in Mathematics."
  },
  {
    "objectID": "03_misc/2022-10-14/index.html",
    "href": "03_misc/2022-10-14/index.html",
    "title": "October 14th, 2022",
    "section": "",
    "text": "Headphones on. Do not disturb mode activated."
  },
  {
    "objectID": "03_misc/2022-06-21/index.html",
    "href": "03_misc/2022-06-21/index.html",
    "title": "June 21st, 2022",
    "section": "",
    "text": "I started my first day as a product owner / software analyst at finastra."
  },
  {
    "objectID": "03_misc/2022-10-08/index.html",
    "href": "03_misc/2022-10-08/index.html",
    "title": "October 8th, 2022",
    "section": "",
    "text": "Tanner got the compost bin set up and some weeds pulled."
  },
  {
    "objectID": "03_misc/2022-10-06/index.html",
    "href": "03_misc/2022-10-06/index.html",
    "title": "October 6th, 2022",
    "section": "",
    "text": "Tim and Sam from the telivision show Detroiters making suprised faces."
  },
  {
    "objectID": "03_misc/2022-10-07/index.html",
    "href": "03_misc/2022-10-07/index.html",
    "title": "October 7th, 2022",
    "section": "",
    "text": "â€œCan you keep the deep water still and clear, so it reflects without blurring?â€ - Techniques, Tao Te Ching"
  },
  {
    "objectID": "01_datsci/post-with-code/index.html",
    "href": "01_datsci/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "1 + 1\n\n[1] 2\n\n\nTry again.\n\nx <- data.frame(x = c(\"1\",\"2\",\"3\"), y = c(\"a\",\"b\",\"c\"))\nx\n\n  x y\n1 1 a\n2 2 b\n3 3 c"
  },
  {
    "objectID": "01_datsci/welcome/index.html",
    "href": "01_datsci/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesnâ€™t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "01_datsci.html",
    "href": "01_datsci.html",
    "title": "Data Science",
    "section": "",
    "text": "NBA\n\n\nWeb-Scraping\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "02_math.html",
    "href": "02_math.html",
    "title": "Mathematics",
    "section": "",
    "text": "Proof\n\n\n\n\n\n\n\n\n\n\n\nOct 17, 2022\n\n\nRandi Bolt\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "04_proj.html",
    "href": "04_proj.html",
    "title": "Projects",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "05_stat.html",
    "href": "05_stat.html",
    "title": "Statistics",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "03_stat.html",
    "href": "03_stat.html",
    "title": "Statistics",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "04_misc/2022-10-10/index.html",
    "href": "04_misc/2022-10-10/index.html",
    "title": "Octorber 10th, 2022",
    "section": "",
    "text": "The full moon in October is the Hunterâ€™s Moon."
  },
  {
    "objectID": "04_misc/2022-08-13/index.html",
    "href": "04_misc/2022-08-13/index.html",
    "title": "August 13th, 2022",
    "section": "",
    "text": "Photo of my family from my sisterâ€™s wedding."
  },
  {
    "objectID": "04_misc/2022-04-21/index.html",
    "href": "04_misc/2022-04-21/index.html",
    "title": "April 21st, 2022",
    "section": "",
    "text": "My Partner Tanner and I bought a house."
  },
  {
    "objectID": "04_misc/2022-06-12/index.html",
    "href": "04_misc/2022-06-12/index.html",
    "title": "June 12th, 2022",
    "section": "",
    "text": "I graduated magna cum laude from Portland State University with my Bachelors of Science in Mathematics."
  },
  {
    "objectID": "04_misc/2022-10-14/index.html",
    "href": "04_misc/2022-10-14/index.html",
    "title": "October 14th, 2022",
    "section": "",
    "text": "Headphones on. Do not disturb mode activated."
  },
  {
    "objectID": "04_misc/2022-06-21/index.html",
    "href": "04_misc/2022-06-21/index.html",
    "title": "June 21st, 2022",
    "section": "",
    "text": "I started my first day as a product owner / software analyst at finastra."
  },
  {
    "objectID": "04_misc/2022-10-08/index.html",
    "href": "04_misc/2022-10-08/index.html",
    "title": "October 8th, 2022",
    "section": "",
    "text": "Tanner got the compost bin set up and some weeds pulled."
  },
  {
    "objectID": "04_misc/2022-10-06/index.html",
    "href": "04_misc/2022-10-06/index.html",
    "title": "October 6th, 2022",
    "section": "",
    "text": "Tim and Sam from the telivision show Detroiters making suprised faces."
  },
  {
    "objectID": "04_misc/2022-10-07/index.html",
    "href": "04_misc/2022-10-07/index.html",
    "title": "October 7th, 2022",
    "section": "",
    "text": "â€œCan you keep the deep water still and clear, so it reflects without blurring?â€ - Techniques, Tao Te Ching"
  },
  {
    "objectID": "04_misc.html",
    "href": "04_misc.html",
    "title": "Miscellaneous",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "01_datsci/2022_10_19_NBA-functions/index.html",
    "href": "01_datsci/2022_10_19_NBA-functions/index.html",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "",
    "text": "In this tutorial I will be creating functions to scrape NBA data. The goal here is to prepare these functions to use in a package for future analysis."
  },
  {
    "objectID": "01_datsci/2022_10_19_NBA-functions/index.html#team-statistics",
    "href": "01_datsci/2022_10_19_NBA-functions/index.html#team-statistics",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "1_1. Team Statistics:",
    "text": "1_1. Team Statistics:\nThe first function Iâ€™m creating scrapes team statistics, which will need the user to input the teams url slug, the year that team attended or attends the NBA playoffs, and the stats_tb or statistics table that corresponds to what is shown on Basketball Reference. Currently not all tables work, but it should work for: #per_game, #totals, #per_36_minutes, and #advanced.\n\nscrape_team_data <- function(slug, year, stats_tb){\n    \"\n  A function that returns a data frame of team statistics. \n  \n  @param slug is string of three letters that represents the teams url. \n  @param year is a string that corresponds to the NBA finals.\n  @param stats_tb is a string that corresponds to the statistics table on BasketBall Reference such as #per_game, #totals, #per_36_minutes, and #advanced\n  \n  @return a df of team statistics\n  \"\n  # define team page URL\n  url <- base::paste0(\"https://www.basketball-reference.com/teams/\",\n                slug,\"/\", year, \".html\")\n  \n  # Read stats table\n  stats_tb <- url %>%\n  read_html %>%\n  html_node(stats_tb) %>% \n  html_table()\n  \n  # Rename Column 2 to Name \n  base::names(stats_tb)[2] <- \"Name\"\n  \n  # Replace NA values with 0 (for stat functions)\n  stats_tb[base::is.na(stats_tb)] <- 0\n  \n  # make data frame\n  df <- base::data.frame(stats_tb)\n  base::return(df)\n  }\n\n\nExamples\n\nA. Current Blazers Roster\n\nzers_roster <- scrape_team_data(\"POR\",\"2022\",\"#roster\")\nutils::head(zers_roster)\n\n  No.              Name Pos  Ht  Wt         Birth.Date Var.7 Exp\n1  21    Keljin Blevins  SF 6-4 200  November 24, 1995    us   1\n2   4    Greg Brown III  SF 6-9 205  September 1, 2001    us   R\n3  33  Robert Covington  PF 6-7 209  December 14, 1990    us   8\n4  34 Jarron Cumberland  SG 6-5 205 September 22, 1997    us   R\n5  18         Kris Dunn  PG 6-3 205     March 18, 1994    us   5\n6  16         CJ Elleby  SF 6-6 200      June 16, 2000    us   1\n                       College\n1 Southern Miss, Montana State\n2                        Texas\n3              Tennessee State\n4                   Cincinnati\n5                   Providence\n6             Washington State\n\n\n\n\nB. 1997 Chicago Bulls Total Statistics\n\nbulls_totals <- scrape_team_data(\"CHI\", \"1998\", \"#totals\")\nutils::head(bulls_totals)\n\n  Rk           Name Age  G GS   MP  FG  FGA   FG. X3P X3PA  X3P. X2P X2PA  X2P.\n1  1 Michael Jordan  34 82 82 3181 881 1893 0.465  30  126 0.238 851 1767 0.482\n2  2  Dennis Rodman  36 80 66 2856 155  360 0.431   4   23 0.174 151  337 0.448\n3  3     Ron Harper  34 82 82 2284 293  665 0.441  16   84 0.190 277  581 0.477\n4  4     Toni KukoÄ  29 74 52 2235 383  841 0.455  63  174 0.362 320  667 0.480\n5  5    Luc Longley  29 58 58 1703 277  609 0.455   0    0 0.000 277  609 0.455\n6  6 Scottie Pippen  32 44 44 1652 315  704 0.447  61  192 0.318 254  512 0.496\n   eFG.  FT FTA   FT. ORB DRB  TRB AST STL BLK TOV  PF  PTS\n1 0.473 565 721 0.784 130 345  475 283 141  45 185 151 2357\n2 0.436  61 111 0.550 421 780 1201 230  47  18 147 238  375\n3 0.453 162 216 0.750 107 183  290 241 108  48  91 181  764\n4 0.493 155 219 0.708 121 206  327 314  76  37 154 149  984\n5 0.455 109 148 0.736 113 228  341 161  34  62 130 206  663\n6 0.491 150 193 0.777  53 174  227 254  79  43 109 116  841\n\n\nHere we can see when Michael Jordan won his 6th ring with the Chicago Bulls he was also the leagues leading point scorer with 2,357 total points that season. Dennis Rodman was also a league leader that season in rebounds collecting a total of 1,201 rebounds."
  },
  {
    "objectID": "01_datsci/2022_10_19_NBA-functions/index.html#player-statistics",
    "href": "01_datsci/2022_10_19_NBA-functions/index.html#player-statistics",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "1_2. Player Statistics",
    "text": "1_2. Player Statistics\nThe second function will scrape player statistics. The user will need to input the players name, and the stats_tb or statistics table that corresponds to what is shown on Basketball Reference. Currently not all tables work, but it should work for: #per_game, #totals, #per_36_minutes, and #advanced.\n\nscrape_player_data <- function(name, stats_tb){\n  \"\n  A function that returns a data frame of player statistics. \n  \n  @param name is a string that represnets an NBA players name\n  @param stats_tb is a string that corresponds to the statistics table on BasketBall Reference such as #per_game, #totals, #per_36_minutes, and #advanced\n  \n  @return a df of player statistics\n  \"\n  # make name lower case\n  lower_case_name <- base::tolower(name)\n\n  # split name \n  split_name <- base::strsplit(lower_case_name, \" +\")[[1]]\n\n  # define first and last name\n  first_name <- split_name[[1]]\n  last_name <- split_name[[2]]\n  \n  # first letter of last name\n  letter <- base::substr(last_name, 1,1)\n  \n  # first five letters of last name \n  last_5 <- base::substr(last_name, 1, 5)\n  \n  # first two letters of first name\n  first_2 <- base::substr(first_name, 1,2)\n  \n  # define team page URL\n  url <- base::paste0(\"https://www.basketball-reference.com/players/\",letter ,\"/\",last_5,first_2,\"01.html\")\n  \n  # Read stats table\n  stats_tb <- url %>%\n  read_html %>%\n  html_node(stats_tb) %>% \n  html_table()\n  \n  # Rename Column 2 to Name \n  names(stats_tb)[2] <- \"Name\"\n  \n  # Replace NA values with 0 (for stat functions)\n  stats_tb[base::is.na(stats_tb)] <- 0\n  \n  # make list a dataframe\n  df <- base::data.frame(stats_tb)\n  \n  base::return(df)\n  }\n\n\nExamples\n\nC. Allen Iverson Per Game Stats\n\nai_per_game <- scrape_player_data(\"Allen Iverson\", \"#per_game\")\nhead(ai_per_game)\n\n   Season Name  Tm  Lg Pos  G GS   MP   FG  FGA  FG. X3P X3PA X3P. X2P X2PA\n1 1996-97   21 PHI NBA  PG 76 74 40.1  8.2 19.8 .416 2.0  6.0 .341 6.2 13.8\n2 1997-98   22 PHI NBA  PG 80 80 39.4  8.1 17.6 .461 0.9  2.9 .298 7.2 14.7\n3 1998-99   23 PHI NBA  SG 48 48 41.5  9.1 22.0 .412 1.2  4.1 .291 7.9 17.9\n4 1999-00   24 PHI NBA  SG 70 70 40.8 10.4 24.8 .421 1.3  3.7 .341 9.1 21.0\n5 2000-01   25 PHI NBA  SG 71 71 42.0 10.7 25.5 .420 1.4  4.3 .320 9.4 21.2\n6 2001-02   26 PHI NBA  SG 60 59 43.7 11.1 27.8 .398 1.3  4.5 .291 9.8 23.4\n  X2P. eFG.  FT  FTA  FT. ORB DRB TRB AST STL BLK TOV  PF  PTS\n1 .448 .467 5.0  7.2 .702 1.5 2.6 4.1 7.5 2.1 0.3 4.4 3.1 23.5\n2 .494 .486 4.9  6.7 .729 1.1 2.6 3.7 6.2 2.2 0.3 3.1 2.5 22.0\n3 .440 .439 7.4  9.9 .751 1.4 3.5 4.9 4.6 2.3 0.1 3.5 2.0 26.8\n4 .435 .446 6.3  8.9 .713 1.0 2.8 3.8 4.7 2.1 0.1 3.3 2.3 28.4\n5 .441 .447 8.2 10.1 .814 0.7 3.1 3.8 4.6 2.5 0.3 3.3 2.1 31.1\n6 .419 .422 7.9  9.8 .812 0.7 3.8 4.5 5.5 2.8 0.2 4.0 1.7 31.4\n\n\nNotice that when Allen Iverson won the NBAâ€™s MVP in 2001 he was putting up about 31 points a game.\n\n\nD. Kareem Abdul-Jabbar Totals\n\nkaj_totals <- scrape_player_data(\"Kareem Abdul-Jabbar\", \"#totals\")\nutils::head(kaj_totals)\n\n   Season Name  Tm  Lg Pos  G GS   MP   FG  FGA   FG. X3P X3PA X3P.  X2P X2PA\n1 1969-70   22 MIL NBA   C 82  0 3534  938 1810 0.518   0    0    0  938 1810\n2 1970-71   23 MIL NBA   C 82  0 3288 1063 1843 0.577   0    0    0 1063 1843\n3 1971-72   24 MIL NBA   C 81  0 3583 1159 2019 0.574   0    0    0 1159 2019\n4 1972-73   25 MIL NBA   C 76  0 3254  982 1772 0.554   0    0    0  982 1772\n5 1973-74   26 MIL NBA   C 81  0 3548  948 1759 0.539   0    0    0  948 1759\n6 1974-75   27 MIL NBA   C 65  0 2747  812 1584 0.513   0    0    0  812 1584\n   X2P.  eFG.  FT FTA   FT. ORB DRB  TRB AST STL BLK TOV  PF  PTS Var.31\n1 0.518 0.518 485 743 0.653   0   0 1190 337   0   0   0 283 2361      0\n2 0.577 0.577 470 681 0.690   0   0 1311 272   0   0   0 264 2596      0\n3 0.574 0.574 504 732 0.689   0   0 1346 370   0   0   0 235 2822      0\n4 0.554 0.554 328 460 0.713   0   0 1224 379   0   0   0 208 2292      0\n5 0.539 0.539 295 420 0.702 287 891 1178 386 112 283   0 238 2191      0\n6 0.513 0.513 325 426 0.763 194 718  912 264  65 212   0 205 1949      0\n  Trp.Dbl\n1       0\n2       1\n3       1\n4       2\n5       3\n6       1"
  },
  {
    "objectID": "04_misc/post-with-code/index.html",
    "href": "04_misc/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "1 + 1\n\n[1] 2\n\n\nTry again.\n\nx <- data.frame(x = c(\"1\",\"2\",\"3\"), y = c(\"a\",\"b\",\"c\"))\nx\n\n  x y\n1 1 a\n2 2 b\n3 3 c"
  },
  {
    "objectID": "04_misc/welcome/index.html",
    "href": "04_misc/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesnâ€™t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "02_math/02_00_P-logically-equivalent-neg-neg-P/index.html",
    "href": "02_math/02_00_P-logically-equivalent-neg-neg-P/index.html",
    "title": "Prove P is Logically Equivalent to the Negation of the Negation of P",
    "section": "",
    "text": "Solution 1\nConsider the truth table for P, \\(\\neg P\\), and \\(\\neg (\\neg P)\\), as shown below in Figure 1:\n\n\nFigure 1: Truth Table\n\n\nP\n\\(\\neg P\\)\n\\(\\neg (\\neg P)\\)\n\n\n\n\nT\nF\nT\n\n\nF\nT\nF\n\n\n\n\nSince the truth values for P and \\(\\neg (\\neg P)\\) are the same then P and \\(\\neg (\\neg P)\\) are logically equivalent.\n\n\nSolution 2\nSuppose by way of contradiction (BWOC) that P and \\(\\neg (\\neg P)\\) are not logically equivalent.\nLet P be true and then \\(\\neg (\\neg P)\\) would be false.\nIf P is true then \\(\\neg P\\) would be false, but \\(\\neg P\\) and \\(\\neg (\\neg P)\\) cannot both be false. Therefore BWOC \\(\\neg (\\neg P)\\equiv P\\).\n\\(\\square\\)"
  },
  {
    "objectID": "03_stat/2022_11_8_test/index.html",
    "href": "03_stat/2022_11_8_test/index.html",
    "title": "Test",
    "section": "",
    "text": "Hi hi"
  },
  {
    "objectID": "01_datsci/2022_10_19_NBA-functions/index.html#about-the-data",
    "href": "01_datsci/2022_10_19_NBA-functions/index.html#about-the-data",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "0_1. About-The-Data",
    "text": "0_1. About-The-Data\nI will be scrapping data from Basketball Reference which gets thier data updated regularly by a handful of contributors and sources. The main reasons I like using this data is because itâ€™s reliable, updated regularly, and similar sites exist for other non-NBA Sports (such as: WNBA, Baseball, Football, and others) if I wanted to expand my research outside the NBA."
  },
  {
    "objectID": "01_datsci/2022_10_19_NBA-functions/index.html#package-installs",
    "href": "01_datsci/2022_10_19_NBA-functions/index.html#package-installs",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "0_2. Package Installs",
    "text": "0_2. Package Installs\nThe packages I will be using are rvest to scrape the data and magrittr to pipe it. To install these packages, copy the code below and remove the first comment hash (command - shift - c).\n\n## install packages\n# install.packages(\"rvest\",  \"magrittr\")\n\nThen load:\n\n# load packages \nlibrary(rvest) \nlibrary(magrittr)"
  },
  {
    "objectID": "01_datsci/2022_10_19_NBA-functions/index.html#box-scores",
    "href": "01_datsci/2022_10_19_NBA-functions/index.html#box-scores",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "1_3. Box Scores",
    "text": "1_3. Box Scores\nThe last function still needs a bit of work, but will pull box scores of all the NBA games on a given day. The user will need to enter the game_day or day of the games they want box scores for.\nNote: Ideally this function would return a list with each game being its own df, but for now it only prints one data frame that includes all games played on that date. There also seem to be issues when only one game is played, or it is the first game of the season (see examples below), but for now those issues are manageable.\n\nbox_scores <- function(game_day){\n  \"\n  A function that returns a data frame of box scores. \n  \n  @param game_day is a string that represents the date in the form Y-M-D\n  \n  @return a df of box scores from that day.\n  \"\n  # split by dash\n  split_date <- base::strsplit(game_day, \"-\")\n  \n  # year - month - day \n  year <- split_date[[1]][[1]]\n  month <- split_date[[1]][[2]]\n  day <- split_date[[1]][[3]]\n  \n  #url\n  url <- base::paste0(\"https://www.basketball-reference.com/boxscores/?month=\",\n                month ,\"&day=\", day,\"&year=\", year)\n  \n  # read url\n  html <- read_html(url)\n  \n  # extract all the 'div\" items from the html as tables\n  div <- html %>% \n    html_elements(\"div\") %>% \n    html_table()\n  \n  #remove empties\n  div <- div[base::sapply(div, function(i) dim(i)[1]) > 0]\n  \n  # only keep rows == 7\n  div <- div[base::sapply(div, function(i) nrow(i)[1]) == 7]\n  \n  # empty list\n  my_vec <- base::list()\n  \n  #for loop\n  for(i in 1:base::length(div)) {        \n  my_out <- div[[i]][3:5,] \n  my_vec <- c(my_vec, my_out)\n  df <- base::data.frame(my_vec)\n  }\n  \n  df <- df[-1,]\n  \n  base::return(df)\n}\n\n\nExample\n\nE. Box Scores for 10-19-2022 (works correctly)\n\noct_19 <- box_scores(\"2022-10-19\")\noct_19\n\n       X1 X2 X3 X4 X5        X1.1 X2.1 X3.1 X4.1 X5.1    X1.2 X2.2 X3.2 X4.2\n2 Houston 20 30 30 27 New Orleans   32   26   40   32 Orlando   28   27   28\n3 Atlanta 26 33 25 33    Brooklyn   14   36   28   30 Detroit   17   40   34\n  X5.2       X1.3 X2.3 X3.3 X4.3 X5.3     X1.4 X2.4 X3.4 X4.4 X5.4 X6    X1.5\n2   26 Washington   36   24   27   27 New York   23   23   33   29  4 Chicago\n3   22    Indiana   25   27   25   30  Memphis   25   36   24   23  7   Miami\n  X2.5 X3.5 X4.5 X5.5          X1.6 X2.6 X3.6 X4.6 X5.6    X1.7 X2.7 X3.7 X4.7\n2   28   31   37   20 Oklahoma City   22   30   35   21  Dallas   32   30   19\n3   33   26   27   22     Minnesota   35   30   22   28 Phoenix   24   21   31\n  X5.7       X1.8 X2.8 X3.8 X4.8 X5.8        X1.9 X2.9 X3.9 X4.9 X5.9     X1.10\n2   24   Portland   32   19   33   31   Charlotte   38   30   30   31 Cleveland\n3   31 Sacramento   23   32   29   24 San Antonio   22   25   28   27   Toronto\n  X2.10 X3.10 X4.10 X5.10  X1.11 X2.11 X3.11 X4.11 X5.11\n2    22    35    27    21 Denver    30    23    27    22\n3    28    23    25    32   Utah    37    38    19    29\n\n\n\n\nF. Box scores for the first day of the â€™22/â€™23 NBA season (issues)\n\noct_18 <- box_scores(\"2022-10-18\")\noct_18\n\n            X1 X2 X3 X4 X5         X1.1 X2.1 X3.1 X4.1 X5.1               X1.2\n2 Philadelphia 29 34 25 29    LA Lakers   22   30   19   38 Philadelphia 76ers\n3       Boston 24 39 35 28 Golden State   25   34   32   32 Western Conference\n  X2.2 X3.2 X4.2 X5.2    X6    X7   X8   X9 X10 X11 X12  X13 X14 X15  X16 X17\n2    0    1 .000  1.0 117.0 126.0 <NA> <NA>  NA  NA  NA <NA>  NA  NA <NA>  NA\n3    W    L W/L%   GB  PS/G  PA/G <NA> <NA>  NA  NA  NA <NA>  NA  NA <NA>  NA\n  X18 X19 X20 X21 X22  X23  X24  X25  X26  X27  X28  X29  X30  X31 X32 X33 X34\n2  NA  NA  NA  NA  NA <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>  NA  NA  NA\n3  NA  NA  NA  NA  NA <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>  NA  NA  NA\n   X35 X36 X37  X38 X39 X40 X41 X42 X43 X44\n2 <NA>  NA  NA <NA>  NA  NA  NA  NA  NA  NA\n3 <NA>  NA  NA <NA>  NA  NA  NA  NA  NA  NA\n\n\nIssue: For the first game of the season there is an are NA tables that are being pulled in.\nG. First game of the 1992 NBA Finals AKA Michael Jordanâ€™s famous Shrug (issues)\n\nfinals_92_g1 <- box_scores(\"1992-6-3\")\nfinals_92_g1\n\n        X1 X2 X3 X4 X5     X1.1 X2.1 X3.1 X4.1 X5.1\n2 Portland 30 21 17 21 Portland   30   21   17   21\n3  Chicago 33 33 38 18  Chicago   33   33   38   18\n\n\nIssue: For days where only one game is played the one game is printed twice in the data frame."
  },
  {
    "objectID": "01_blog.html",
    "href": "01_blog.html",
    "title": "Blog",
    "section": "",
    "text": "Statistics\n\n\nLinear Regression\n\n\n\n\n\n\n\n\n\n\n\nDec 5, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nPython\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\nNov 28, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nQuarto\n\n\n\n\n\n\n\n\n\n\n\nNov 21, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nNBA\n\n\nWeb-Scraping\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nMath\n\n\nProof\n\n\n\n\n\n\n\n\n\n\n\nOct 31, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJul 25, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nNBA\n\n\nWeb-Scraping\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\n\nJul 18, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nStatistics\n\n\n\n\n\n\n\n\n\n\n\nJun 20, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nGeometry\n\n\n\n\n\n\n\n\n\n\n\nMay 30, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAbstract Math\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\n\nApr 25, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nNLP\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\nApr 18, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAbstract Math\n\n\n\n\n\n\n\n\n\n\n\nMar 28, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nGeometry\n\n\n\n\n\n\n\n\n\n\n\nMar 21, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\nFeb 21, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nGeometry\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nMath\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nLinear Regression\n\n\n\n\n\n\n\n\n\n\n\nDec 20, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nProof\n\n\nStatistics\n\n\nLinear Regression\n\n\n\n\n\n\n\n\n\n\n\nNov 29, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nStatistics\n\n\n\n\n\n\n\n\n\n\n\nNov 22, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nMath\n\n\nAbstract Math\n\n\n\n\n\n\n\n\n\n\n\nOct 25, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nConditional Probabilty\n\n\nTree Diagrams\n\n\nStatistics\n\n\n\n\n\n\n\n\n\n\n\nOct 18, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nGenerative Art\n\n\n\n\n\n\n\n\n\n\n\nSep 27, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\ntidycensus\n\n\nAPI\n\n\n\n\n\n\n\n\n\n\n\nSep 20, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\nAug 30, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nQuarto\n\n\n\n\n\n\n\n\n\n\n\nAug 23, 2021\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "01_blog/2022_10_19_NBA-functions/index.html",
    "href": "01_blog/2022_10_19_NBA-functions/index.html",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "",
    "text": "In this tutorial I will be creating functions to scrape NBA data. The goal here is to prepare these functions to use in a package for future analysis."
  },
  {
    "objectID": "01_blog/2022_10_19_NBA-functions/index.html#about-the-data",
    "href": "01_blog/2022_10_19_NBA-functions/index.html#about-the-data",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "0_1. About-The-Data",
    "text": "0_1. About-The-Data\nI will be scrapping data from Basketball Reference which gets thier data updated regularly by a handful of contributors and sources. The main reasons I like using this data is because itâ€™s reliable, updated regularly, and similar sites exist for other non-NBA Sports (such as: WNBA, Baseball, Football, and others) if I wanted to expand my research outside the NBA."
  },
  {
    "objectID": "01_blog/2022_10_19_NBA-functions/index.html#package-installs",
    "href": "01_blog/2022_10_19_NBA-functions/index.html#package-installs",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "0_2. Package Installs",
    "text": "0_2. Package Installs\nThe packages I will be using are rvest to scrape the data and magrittr to pipe it. To install these packages, copy the code below and remove the first comment hash (command - shift - c).\n\n## install packages\n# install.packages(\"rvest\",  \"magrittr\")\n\nThen load:\n\n# load packages \nlibrary(rvest) \nlibrary(magrittr)"
  },
  {
    "objectID": "01_blog/2022_10_19_NBA-functions/index.html#team-statistics",
    "href": "01_blog/2022_10_19_NBA-functions/index.html#team-statistics",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "1_1. Team Statistics:",
    "text": "1_1. Team Statistics:\nThe first function Iâ€™m creating scrapes team statistics, which will need the user to input the teams url slug, the year that team attended or attends the NBA playoffs, and the stats_tb or statistics table that corresponds to what is shown on Basketball Reference. Currently not all tables work, but it should work for: #per_game, #totals, #per_36_minutes, and #advanced.\n\nscrape_team_data <- function(slug, year, stats_tb){\n    \"\n  A function that returns a data frame of team statistics. \n  \n  @param slug is string of three letters that represents the teams url. \n  @param year is a string that corresponds to the NBA finals.\n  @param stats_tb is a string that corresponds to the statistics table on BasketBall Reference such as #per_game, #totals, #per_36_minutes, and #advanced\n  \n  @return a df of team statistics\n  \"\n  # define team page URL\n  url <- base::paste0(\"https://www.basketball-reference.com/teams/\",\n                slug,\"/\", year, \".html\")\n  \n  # Read stats table\n  stats_tb <- url %>%\n  read_html %>%\n  html_node(stats_tb) %>% \n  html_table()\n  \n  # Rename Column 2 to Name \n  base::names(stats_tb)[2] <- \"Name\"\n  \n  # Replace NA values with 0 (for stat functions)\n  stats_tb[base::is.na(stats_tb)] <- 0\n  \n  # make data frame\n  df <- base::data.frame(stats_tb)\n  base::return(df)\n  }\n\n\nExamples\n\nA. Current Blazers Roster\n\nzers_roster <- scrape_team_data(\"POR\",\"2022\",\"#roster\")\nutils::head(zers_roster)\n\n  No.              Name Pos  Ht  Wt         Birth.Date Var.7 Exp\n1  21    Keljin Blevins  SF 6-4 200  November 24, 1995    us   1\n2   4    Greg Brown III  SF 6-9 205  September 1, 2001    us   R\n3  33  Robert Covington  PF 6-7 209  December 14, 1990    us   8\n4  34 Jarron Cumberland  SG 6-5 205 September 22, 1997    us   R\n5  18         Kris Dunn  PG 6-3 205     March 18, 1994    us   5\n6  16         CJ Elleby  SF 6-6 200      June 16, 2000    us   1\n                       College\n1 Southern Miss, Montana State\n2                        Texas\n3              Tennessee State\n4                   Cincinnati\n5                   Providence\n6             Washington State\n\n\n\n\nB. 1997 Chicago Bulls Total Statistics\n\nbulls_totals <- scrape_team_data(\"CHI\", \"1998\", \"#totals\")\nutils::head(bulls_totals)\n\n  Rk           Name Age  G GS   MP  FG  FGA   FG. X3P X3PA  X3P. X2P X2PA  X2P.\n1  1 Michael Jordan  34 82 82 3181 881 1893 0.465  30  126 0.238 851 1767 0.482\n2  2  Dennis Rodman  36 80 66 2856 155  360 0.431   4   23 0.174 151  337 0.448\n3  3     Ron Harper  34 82 82 2284 293  665 0.441  16   84 0.190 277  581 0.477\n4  4     Toni KukoÄ  29 74 52 2235 383  841 0.455  63  174 0.362 320  667 0.480\n5  5    Luc Longley  29 58 58 1703 277  609 0.455   0    0 0.000 277  609 0.455\n6  6 Scottie Pippen  32 44 44 1652 315  704 0.447  61  192 0.318 254  512 0.496\n   eFG.  FT FTA   FT. ORB DRB  TRB AST STL BLK TOV  PF  PTS\n1 0.473 565 721 0.784 130 345  475 283 141  45 185 151 2357\n2 0.436  61 111 0.550 421 780 1201 230  47  18 147 238  375\n3 0.453 162 216 0.750 107 183  290 241 108  48  91 181  764\n4 0.493 155 219 0.708 121 206  327 314  76  37 154 149  984\n5 0.455 109 148 0.736 113 228  341 161  34  62 130 206  663\n6 0.491 150 193 0.777  53 174  227 254  79  43 109 116  841\n\n\nHere we can see when Michael Jordan won his 6th ring with the Chicago Bulls he was also the leagues leading point scorer with 2,357 total points that season. Dennis Rodman was also a league leader that season in rebounds collecting a total of 1,201 rebounds."
  },
  {
    "objectID": "01_blog/2022_10_19_NBA-functions/index.html#player-statistics",
    "href": "01_blog/2022_10_19_NBA-functions/index.html#player-statistics",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "1_2. Player Statistics",
    "text": "1_2. Player Statistics\nThe second function will scrape player statistics. The user will need to input the players name, and the stats_tb or statistics table that corresponds to what is shown on Basketball Reference. Currently not all tables work, but it should work for: #per_game, #totals, #per_36_minutes, and #advanced.\n\nscrape_player_data <- function(name, stats_tb){\n  \"\n  A function that returns a data frame of player statistics. \n  \n  @param name is a string that represnets an NBA players name\n  @param stats_tb is a string that corresponds to the statistics table on BasketBall Reference such as #per_game, #totals, #per_36_minutes, and #advanced\n  \n  @return a df of player statistics\n  \"\n  # make name lower case\n  lower_case_name <- base::tolower(name)\n\n  # split name \n  split_name <- base::strsplit(lower_case_name, \" +\")[[1]]\n\n  # define first and last name\n  first_name <- split_name[[1]]\n  last_name <- split_name[[2]]\n  \n  # first letter of last name\n  letter <- base::substr(last_name, 1,1)\n  \n  # first five letters of last name \n  last_5 <- base::substr(last_name, 1, 5)\n  \n  # first two letters of first name\n  first_2 <- base::substr(first_name, 1,2)\n  \n  # define team page URL\n  url <- base::paste0(\"https://www.basketball-reference.com/players/\",letter ,\"/\",last_5,first_2,\"01.html\")\n  \n  # Read stats table\n  stats_tb <- url %>%\n  read_html %>%\n  html_node(stats_tb) %>% \n  html_table()\n  \n  # Rename Column 2 to Name \n  names(stats_tb)[2] <- \"Name\"\n  \n  # Replace NA values with 0 (for stat functions)\n  stats_tb[base::is.na(stats_tb)] <- 0\n  \n  # make list a dataframe\n  df <- base::data.frame(stats_tb)\n  \n  base::return(df)\n  }\n\n\nExamples\n\nC. Allen Iverson Per Game Stats\n\nai_per_game <- scrape_player_data(\"Allen Iverson\", \"#per_game\")\nhead(ai_per_game)\n\n   Season Name  Tm  Lg Pos  G GS   MP   FG  FGA  FG. X3P X3PA X3P. X2P X2PA\n1 1996-97   21 PHI NBA  PG 76 74 40.1  8.2 19.8 .416 2.0  6.0 .341 6.2 13.8\n2 1997-98   22 PHI NBA  PG 80 80 39.4  8.1 17.6 .461 0.9  2.9 .298 7.2 14.7\n3 1998-99   23 PHI NBA  SG 48 48 41.5  9.1 22.0 .412 1.2  4.1 .291 7.9 17.9\n4 1999-00   24 PHI NBA  SG 70 70 40.8 10.4 24.8 .421 1.3  3.7 .341 9.1 21.0\n5 2000-01   25 PHI NBA  SG 71 71 42.0 10.7 25.5 .420 1.4  4.3 .320 9.4 21.2\n6 2001-02   26 PHI NBA  SG 60 59 43.7 11.1 27.8 .398 1.3  4.5 .291 9.8 23.4\n  X2P. eFG.  FT  FTA  FT. ORB DRB TRB AST STL BLK TOV  PF  PTS\n1 .448 .467 5.0  7.2 .702 1.5 2.6 4.1 7.5 2.1 0.3 4.4 3.1 23.5\n2 .494 .486 4.9  6.7 .729 1.1 2.6 3.7 6.2 2.2 0.3 3.1 2.5 22.0\n3 .440 .439 7.4  9.9 .751 1.4 3.5 4.9 4.6 2.3 0.1 3.5 2.0 26.8\n4 .435 .446 6.3  8.9 .713 1.0 2.8 3.8 4.7 2.1 0.1 3.3 2.3 28.4\n5 .441 .447 8.2 10.1 .814 0.7 3.1 3.8 4.6 2.5 0.3 3.3 2.1 31.1\n6 .419 .422 7.9  9.8 .812 0.7 3.8 4.5 5.5 2.8 0.2 4.0 1.7 31.4\n\n\nNotice that when Allen Iverson won the NBAâ€™s MVP in 2001 he was putting up about 31 points a game.\n\n\nD. Kareem Abdul-Jabbar Totals\n\nkaj_totals <- scrape_player_data(\"Kareem Abdul-Jabbar\", \"#totals\")\nutils::head(kaj_totals)\n\n   Season Name  Tm  Lg Pos  G GS   MP   FG  FGA   FG. X3P X3PA X3P.  X2P X2PA\n1 1969-70   22 MIL NBA   C 82  0 3534  938 1810 0.518   0    0    0  938 1810\n2 1970-71   23 MIL NBA   C 82  0 3288 1063 1843 0.577   0    0    0 1063 1843\n3 1971-72   24 MIL NBA   C 81  0 3583 1159 2019 0.574   0    0    0 1159 2019\n4 1972-73   25 MIL NBA   C 76  0 3254  982 1772 0.554   0    0    0  982 1772\n5 1973-74   26 MIL NBA   C 81  0 3548  948 1759 0.539   0    0    0  948 1759\n6 1974-75   27 MIL NBA   C 65  0 2747  812 1584 0.513   0    0    0  812 1584\n   X2P.  eFG.  FT FTA   FT. ORB DRB  TRB AST STL BLK TOV  PF  PTS Var.31\n1 0.518 0.518 485 743 0.653   0   0 1190 337   0   0   0 283 2361      0\n2 0.577 0.577 470 681 0.690   0   0 1311 272   0   0   0 264 2596      0\n3 0.574 0.574 504 732 0.689   0   0 1346 370   0   0   0 235 2822      0\n4 0.554 0.554 328 460 0.713   0   0 1224 379   0   0   0 208 2292      0\n5 0.539 0.539 295 420 0.702 287 891 1178 386 112 283   0 238 2191      0\n6 0.513 0.513 325 426 0.763 194 718  912 264  65 212   0 205 1949      0\n  Trp.Dbl\n1       0\n2       1\n3       1\n4       2\n5       3\n6       1"
  },
  {
    "objectID": "01_blog/2022_10_19_NBA-functions/index.html#box-scores",
    "href": "01_blog/2022_10_19_NBA-functions/index.html#box-scores",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "1_3. Box Scores",
    "text": "1_3. Box Scores\nThe last function still needs a bit of work, but will pull box scores of all the NBA games on a given day. The user will need to enter the game_day or day of the games they want box scores for.\nNote: Ideally this function would return a list with each game being its own df, but for now it only prints one data frame that includes all games played on that date. There also seem to be issues when only one game is played, or it is the first game of the season (see examples below), but for now those issues are manageable.\n\nbox_scores <- function(game_day){\n  \"\n  A function that returns a data frame of box scores. \n  \n  @param game_day is a string that represents the date in the form Y-M-D\n  \n  @return a df of box scores from that day.\n  \"\n  # split by dash\n  split_date <- base::strsplit(game_day, \"-\")\n  \n  # year - month - day \n  year <- split_date[[1]][[1]]\n  month <- split_date[[1]][[2]]\n  day <- split_date[[1]][[3]]\n  \n  #url\n  url <- base::paste0(\"https://www.basketball-reference.com/boxscores/?month=\",\n                month ,\"&day=\", day,\"&year=\", year)\n  \n  # read url\n  html <- read_html(url)\n  \n  # extract all the 'div\" items from the html as tables\n  div <- html %>% \n    html_elements(\"div\") %>% \n    html_table()\n  \n  #remove empties\n  div <- div[base::sapply(div, function(i) dim(i)[1]) > 0]\n  \n  # only keep rows == 7\n  div <- div[base::sapply(div, function(i) nrow(i)[1]) == 7]\n  \n  # empty list\n  my_vec <- base::list()\n  \n  #for loop\n  for(i in 1:base::length(div)) {        \n  my_out <- div[[i]][3:5,] \n  my_vec <- c(my_vec, my_out)\n  df <- base::data.frame(my_vec)\n  }\n  \n  df <- df[-1,]\n  \n  base::return(df)\n}\n\n\nExample\n\nE. Box Scores for 10-19-2022 (works correctly)\n\noct_19 <- box_scores(\"2022-10-19\")\noct_19\n\n       X1 X2 X3 X4 X5        X1.1 X2.1 X3.1 X4.1 X5.1    X1.2 X2.2 X3.2 X4.2\n2 Houston 20 30 30 27 New Orleans   32   26   40   32 Orlando   28   27   28\n3 Atlanta 26 33 25 33    Brooklyn   14   36   28   30 Detroit   17   40   34\n  X5.2       X1.3 X2.3 X3.3 X4.3 X5.3     X1.4 X2.4 X3.4 X4.4 X5.4 X6    X1.5\n2   26 Washington   36   24   27   27 New York   23   23   33   29  4 Chicago\n3   22    Indiana   25   27   25   30  Memphis   25   36   24   23  7   Miami\n  X2.5 X3.5 X4.5 X5.5          X1.6 X2.6 X3.6 X4.6 X5.6    X1.7 X2.7 X3.7 X4.7\n2   28   31   37   20 Oklahoma City   22   30   35   21  Dallas   32   30   19\n3   33   26   27   22     Minnesota   35   30   22   28 Phoenix   24   21   31\n  X5.7       X1.8 X2.8 X3.8 X4.8 X5.8        X1.9 X2.9 X3.9 X4.9 X5.9     X1.10\n2   24   Portland   32   19   33   31   Charlotte   38   30   30   31 Cleveland\n3   31 Sacramento   23   32   29   24 San Antonio   22   25   28   27   Toronto\n  X2.10 X3.10 X4.10 X5.10  X1.11 X2.11 X3.11 X4.11 X5.11\n2    22    35    27    21 Denver    30    23    27    22\n3    28    23    25    32   Utah    37    38    19    29\n\n\n\n\nF. Box scores for the first day of the â€™22/â€™23 NBA season (issues)\n\noct_18 <- box_scores(\"2022-10-18\")\noct_18\n\n            X1 X2 X3 X4 X5         X1.1 X2.1 X3.1 X4.1 X5.1               X1.2\n2 Philadelphia 29 34 25 29    LA Lakers   22   30   19   38 Philadelphia 76ers\n3       Boston 24 39 35 28 Golden State   25   34   32   32 Western Conference\n  X2.2 X3.2 X4.2 X5.2    X6    X7   X8   X9 X10 X11 X12  X13 X14 X15  X16 X17\n2    0    1 .000  1.0 117.0 126.0 <NA> <NA>  NA  NA  NA <NA>  NA  NA <NA>  NA\n3    W    L W/L%   GB  PS/G  PA/G <NA> <NA>  NA  NA  NA <NA>  NA  NA <NA>  NA\n  X18 X19 X20 X21 X22  X23  X24  X25  X26  X27  X28  X29  X30  X31 X32 X33 X34\n2  NA  NA  NA  NA  NA <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>  NA  NA  NA\n3  NA  NA  NA  NA  NA <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>  NA  NA  NA\n   X35 X36 X37  X38 X39 X40 X41 X42 X43 X44\n2 <NA>  NA  NA <NA>  NA  NA  NA  NA  NA  NA\n3 <NA>  NA  NA <NA>  NA  NA  NA  NA  NA  NA\n\n\nIssue: For the first game of the season there is an are NA tables that are being pulled in.\nG. First game of the 1992 NBA Finals AKA Michael Jordanâ€™s famous Shrug (issues)\n\nfinals_92_g1 <- box_scores(\"1992-6-3\")\nfinals_92_g1\n\n        X1 X2 X3 X4 X5     X1.1 X2.1 X3.1 X4.1 X5.1\n2 Portland 30 21 17 21 Portland   30   21   17   21\n3  Chicago 33 33 38 18  Chicago   33   33   38   18\n\n\nIssue: For days where only one game is played the one game is printed twice in the data frame."
  },
  {
    "objectID": "01_blog/02_00_P-logically-equivalent-neg-neg-P/index.html",
    "href": "01_blog/02_00_P-logically-equivalent-neg-neg-P/index.html",
    "title": "Prove P is Logically Equivalent to the Negation of the Negation of P",
    "section": "",
    "text": "Solution 1\nConsider the truth table for P, \\(\\neg P\\), and \\(\\neg (\\neg P)\\), as shown below in Figure 1:\n\n\nFigure 1: Truth Table\n\n\nP\n\\(\\neg P\\)\n\\(\\neg (\\neg P)\\)\n\n\n\n\nT\nF\nT\n\n\nF\nT\nF\n\n\n\n\nSince the truth values for P and \\(\\neg (\\neg P)\\) are the same then P and \\(\\neg (\\neg P)\\) are logically equivalent.\n\n\nSolution 2\nSuppose by way of contradiction (BWOC) that P and \\(\\neg (\\neg P)\\) are not logically equivalent.\nLet P be true and then \\(\\neg (\\neg P)\\) would be false.\nIf P is true then \\(\\neg P\\) would be false, but \\(\\neg P\\) and \\(\\neg (\\neg P)\\) cannot both be false. Therefore BWOC \\(\\neg (\\neg P)\\equiv P\\).\n\\(\\square\\)"
  },
  {
    "objectID": "01_blog/2022-01-06-latex-hacks/index.html",
    "href": "01_blog/2022-01-06-latex-hacks/index.html",
    "title": "Latex",
    "section": "",
    "text": "Basic Symbols :\n\n\\(\\sim\\) : \\sim\n\\(\\circ\\) : \\circ\n\\(\\square\\) : \\square\n\\(\\equiv\\) : \\equiv\n\\(\\cong\\) : \\cong\n\\(\\unlhd\\) : \\unlhd\n\\(\\div\\) : \\div\n\\(\\nless\\) : \\nless\n\\(\\ngtr\\) : ngtr\n\\(\\emptyset\\) : \\emptyset\n\\(\\subseteq\\) : \\subseteq\n\\(a\\choose b\\) : a\\choose b\n\\(\\underset{i\\in I}U\\) : \\underset{i\\in I}U\n\\(\\Leftrightarrow\\) : \\Leftrightarrow\n\\(\\langle\\rangle\\) : \\langle\\rangle\n\\(\\overrightarrow{\\rm AB}\\) : \\overrightarrow{\\rm AB}\n\\(\\underline{\\text{Underline Text}}\\) : \\underline{\\text{Underline Text}}\n\\(\\mathbb{R}\\) : \\mathbb{R}\n\nbb : blackboard bold\n\n\\(\\mathcal{F}\\) : \\mathcal{F}\n\\(\\mathscr{F}\\) : \\mathscr{F}\n\n\n\nGreek :\n\n\\(\\tau\\) : \\tau\n\\(\\rho\\) : \\rho\n\\(\\alpha\\) : \\alpha\n\\(\\beta\\) : \\beta\n\\(\\Gamma\\) : \\Gamma\n\\(\\epsilon\\) : \\epsilon\n\\(\\mathcal{E}\\) : \\mathcal{E}\n\\(\\varepsilon\\) : \\varepsilon\n\\(\\varphi\\) : \\varphi\n\n\n\nInline :\nLimits above and below sums and integrals\n\n\\(\\sum\\limits_{n}^{i}\\int_0^1\\) : \\limits\n\nMatrices and Matrix Equations\n\n\\(\\begin{smallmatrix} 1 & 0 \\\\ 0 & 1\\end{smallmatrix}\\) : \\begin{smallmatrix} 1 & 0 \\\\ 0 & 1\\end{smallmatrix}\n\n\\(I=[\\begin{smallmatrix} 1 & 0 \\\\ 0 & 1\\end{smallmatrix}]\\)\n\\((\\begin{smallmatrix} 1 & 1 \\\\ 1 & 0\\end{smallmatrix})(\\begin{smallmatrix} 1 & 1 \\\\ 0 & 1\\end{smallmatrix})\\ne(\\begin{smallmatrix} 1 & 1 \\\\ 0 & 1\\end{smallmatrix})(\\begin{smallmatrix} 1 & 1 \\\\ 1 & 0\\end{smallmatrix})\\)\n\n\n\n\nMultiple Lines :\nFunction\n\n\\(F(x)=\\begin{cases}1 & x\\geq 0\\\\0 & \\text{otherwise}\\end{cases}\\) : F(x)=\\begin{cases} . . . \\end{cases}\n\n1 & x \\geq 0 \\\\\n0 & \\text{otherwise}\n\n\nMatrix\n\n\\(F(x)=\\begin{bmatrix}1\\\\2\\\\3\\\\4\\\\5\\\\6\\\\\\end{bmatrix}\\) : F(x)=\\begin{bmatrix}1\\\\2\\\\3\\\\4\\\\5\\\\6\\\\\\end{bmatrix}\n\nSeries of Equalities\n\n\\(\\begin{equation}\\label{a}\\begin{split}x &= a+b+c\\\\&=1+2+3\\\\&=6\\end{split}\\end{equation}\\)\n\n: \\begin{equation}\\{label}\\begin{split}... \\end{split}\\end{equation}\n\nx &= a+b+c \\\\\n&= 1+2+3\n&= 6\n\n\n\nPotential Errors :\nSpelling\n\nEx: \\overlien{AB} should be \\overline{AB}\n\nlabel , table\n\n\nMore than two backslashes\n\nEx: Equation will work but \\end{equation} will show at the end. One of the lines has more than two backslashes at the end of at least one of the lines.\n\nSpace before final $\n\nEx: $\\angle ABC $ should be $\\angle ABC$\n\nMore $ on one side of equation than the other\n\nEx: $A^2+B^2=C^2$$ should be $A^2+B^2=C^2$\n\nClosing {}\n\nEx: $\\int\\limits_{1}^{2$ should be $\\int\\limits_{1}^{2}$\n\nUnderset on the wrong side\n\nEx: U\\underset{i\\in I} should be \\underset{i\\in I}U\n\n\n\nAdvice :\nDetextify\n\nIf you donâ€™t know what a symbol is, draw it in Detextify here.\n\nGoogle Docs Equations Boxes\n\nMost latex backslashes work in google docâ€™s equation boxes. If I have to do a â€œquickâ€ homework, and dont want to spend a lot of time formatting a pdf in R, I will use google docs and latex in the equations boxes.\n\nNote: This is how I began learning latex.\nWhy learn Latex?\n\nGenerally speaking it looks nicer, especially on reports, projects, and presentations.\nA lot of my peers and professors who wrote math by hand would have problems in their dominate writing hand. Typing math with latex helps spread that tension out to two hands.\nIt saves time in the long run, since updating a line in a typed document is a lot easier than re-writing an entire problem by hand. Not to mention the ability to use copy paste."
  },
  {
    "objectID": "01_blog/2022-01-06-latex-hacks/index.en.html",
    "href": "01_blog/2022-01-06-latex-hacks/index.en.html",
    "title": "Latex",
    "section": "",
    "text": "Basic Symbols :\n\n\\(\\sim\\) : \\sim\n\\(\\circ\\) : \\circ\n\\(\\square\\) : \\square\n\\(\\equiv\\) : \\equiv\n\\(\\cong\\) : \\cong\n\\(\\unlhd\\) : \\unlhd\n\\(\\div\\) : \\div\n\\(\\nless\\) : \\nless\n\\(\\ngtr\\) : ngtr\n\\(\\emptyset\\) : \\emptyset\n\\(\\subseteq\\) : \\subseteq\n\\(a\\choose b\\) : a\\choose b\n\\(\\underset{i\\in I}U\\) : \\underset{i\\in I}U\n\\(\\Leftrightarrow\\) : \\Leftrightarrow\n\\(\\langle\\rangle\\) : \\langle\\rangle\n\\(\\overrightarrow{\\rm AB}\\) : \\overrightarrow{\\rm AB}\n\\(\\underline{\\text{Underline Text}}\\) : \\underline{\\text{Underline Text}}\n\\(\\mathbb{R}\\) : \\mathbb{R}\n\nbb : blackboard bold\n\n\\(\\mathcal{F}\\) : \\mathcal{F}\n\\(\\mathscr{F}\\) : \\mathscr{F}\n\n\n\nGreek :\n\n\\(\\tau\\) : \\tau\n\\(\\rho\\) : \\rho\n\\(\\alpha\\) : \\alpha\n\\(\\beta\\) : \\beta\n\\(\\Gamma\\) : \\Gamma\n\\(\\epsilon\\) : \\epsilon\n\\(\\mathcal{E}\\) : \\mathcal{E}\n\\(\\varepsilon\\) : \\varepsilon\n\\(\\varphi\\) : \\varphi\n\n\n\nInline :\nLimits above and below sums and integrals\n\n\\(\\sum\\limits_{n}^{i}\\int_0^1\\) : \\limits\n\nMatrices and Matrix Equations\n\n\\(\\begin{smallmatrix} 1 & 0 \\\\ 0 & 1\\end{smallmatrix}\\) : \\begin{smallmatrix} 1 & 0 \\\\ 0 & 1\\end{smallmatrix}\n\n\\(I=[\\begin{smallmatrix} 1 & 0 \\\\ 0 & 1\\end{smallmatrix}]\\)\n\\((\\begin{smallmatrix} 1 & 1 \\\\ 1 & 0\\end{smallmatrix})(\\begin{smallmatrix} 1 & 1 \\\\ 0 & 1\\end{smallmatrix})\\ne(\\begin{smallmatrix} 1 & 1 \\\\ 0 & 1\\end{smallmatrix})(\\begin{smallmatrix} 1 & 1 \\\\ 1 & 0\\end{smallmatrix})\\)\n\n\n\n\nMultiple Lines :\nFunction\n\n\\(F(x)=\\begin{cases}1 & x\\geq 0\\\\0 & \\text{otherwise}\\end{cases}\\) : F(x)=\\begin{cases} . . . \\end{cases}\n\n1 & x \\geq 0 \\\\\n0 & \\text{otherwise}\n\n\nMatrix\n\n\\(F(x)=\\begin{bmatrix}1\\\\2\\\\3\\\\4\\\\5\\\\6\\\\\\end{bmatrix}\\) : F(x)=\\begin{bmatrix}1\\\\2\\\\3\\\\4\\\\5\\\\6\\\\\\end{bmatrix}\n\nSeries of Equalities\n\n\\(\\begin{equation}\\label{a}\\begin{split}x &= a+b+c\\\\&=1+2+3\\\\&=6\\end{split}\\end{equation}\\) : `\\[\\begin{equation}\\{label}\\begin{split}... \\end{split}\\end{equation}\\]â€™\n\nx &= a+b+c \\\\\n&= 1+2+3\n&= 6\n\n\nNote: still havenâ€™t figured out how to get multiple lines of equations to work in blogposts.\n\n\nPotential Errors :\nSpelling\n\nEx: \\overlien{AB} should be \\overline{AB}\n\nlabel , table\n\n\nMore than two backslashes\n\nEx: Equation will work but \\end{equation} will show at the end. One of the lines has more than two backslashes at the end of at least one of the lines.\n\nSpace before final $\n\nEx: $\\angle ABC $ should be $\\angle ABC$\n\nMore $ on one side of equation than the other\n\nEx: $A^2+B^2=C^2$$ should be $A^2+B^2=C^2$\n\nClosing {}\n\nEx: $\\int\\limits_{1}^{2$ should be $\\int\\limits_{1}^{2}$\n\nUnderset on the wrong side\n\nEx: U\\underset{i\\in I} should be \\underset{i\\in I}U\n\n\n\nAdvice :\nDetextify\n\nIf you donâ€™t know what a symbol is, draw it in Detextify here.\n\nGoogle Docs Equations Boxes\n\nMost latex backslashes work in google docâ€™s equation boxes. If I have to do a â€œquickâ€ homework, and dont want to spend a lot of time formatting a pdf in R, I will use google docs and latex in the equations boxes.\n\nNote: This is how I began learning latex.\nWhy learn Latex?\nWhen you type with latex instead of writting by hand:\n\nGenerally speaking it looks nicer, especially on reports, projects, and presentations.\nCan spread any tension that is normally located in your dominate hand into both.\nIt saves time in the long run updating a document on your computer than re-writing an entire problem by hand."
  },
  {
    "objectID": "01_blog/2021_08_26_Emojis/index.html",
    "href": "01_blog/2021_08_26_Emojis/index.html",
    "title": "Enable Emojis in Quarto",
    "section": "",
    "text": "1. Visual Editor\nOne way to add emojis to a quarto blog posts is from the â€˜Visualâ€™ editor in R Studio, select the Insert tab \\(\\rightarrow\\) â€˜Special Charactersâ€™ \\(\\rightarrow\\) â€˜Insert Emoji â€¦â€™ and then selecting you desired emoji from a large list.\n\n\n2. Include 'from: markdown+emoji' in Header\nThe second way to add emojiâ€™s into a quarto blog is to include â€˜from: markdown+emojiâ€™ in the .qmd header, and then type the name of the emoji you want to include encased in colons as shown below:\n:grinning: \\(\\rightarrow\\) ðŸ˜€\n:smile: \\(\\rightarrow\\) ðŸ˜„\n:heart: \\(\\rightarrow\\) â¤ï¸\n:thumbsup: \\(\\rightarrow\\) ðŸ‘\n:call_me_hand: \\(\\rightarrow\\) ðŸ¤™\n\n\n\n\n\nFootnotes\n\n\nFrom Quarto Documentation - Content Editingâ†©ï¸Ž"
  },
  {
    "objectID": "01_blog/2022_10_17_P-logically-equivalent-neg-neg-P/index.html",
    "href": "01_blog/2022_10_17_P-logically-equivalent-neg-neg-P/index.html",
    "title": "Prove P is Logically Equivalent to the Negation of the Negation of P",
    "section": "",
    "text": "Solution 1\nConsider the truth table for P, \\(\\neg P\\), and \\(\\neg (\\neg P)\\), as shown below in Figure 1:\n\n\nFigure 1: Truth Table\n\n\nP\n\\(\\neg P\\)\n\\(\\neg (\\neg P)\\)\n\n\n\n\nT\nF\nT\n\n\nF\nT\nF\n\n\n\n\nSince the truth values for P and \\(\\neg (\\neg P)\\) are the same then P and \\(\\neg (\\neg P)\\) are logically equivalent.\n\n\nSolution 2\nSuppose by way of contradiction (BWOC) that P and \\(\\neg (\\neg P)\\) are not logically equivalent.\nLet P be true and then \\(\\neg (\\neg P)\\) would be false.\nIf P is true then \\(\\neg P\\) would be false, but \\(\\neg P\\) and \\(\\neg (\\neg P)\\) cannot both be false. Therefore BWOC \\(\\neg (\\neg P)\\equiv P\\).\n\\(\\square\\)"
  },
  {
    "objectID": "01_blog/2022_08_27_Ch.3-R-for-ds/index.html",
    "href": "01_blog/2022_08_27_Ch.3-R-for-ds/index.html",
    "title": "R for Data Science - Ch.3: Data Visualisations",
    "section": "",
    "text": "1. Set Up\nThis first chunk will remove warning messages from all chunks in this file. To hide this chunk use include=FALSE within the {} brackets.\n\nknitr::opts_chunk$set(warning = FALSE, message = FALSE) \n\nThis second chunk calls two packages:\n\ntidyverse: to tidy data and create visuals with ggplot2.\ngridExtra: to arrange data in a grid\n\n\nlibrary(tidyverse)\nlibrary(gridExtra)\n\nThis chapter analyzes the mpg data so Iâ€™m using the head() function from utils to view the first five rows in the mpg data set.\n\nutils::head(mpg, 5)\n\n# A tibble: 5 Ã— 11\n  manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class \n  <chr>        <chr> <dbl> <int> <int> <chr>      <chr> <int> <int> <chr> <chr> \n1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p     compaâ€¦\n2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p     compaâ€¦\n3 audi         a4      2    2008     4 manual(m6) f        20    31 p     compaâ€¦\n4 audi         a4      2    2008     4 auto(av)   f        21    30 p     compaâ€¦\n5 audi         a4      2.8  1999     6 auto(l5)   f        16    26 p     compaâ€¦\n\n\n\n\n2. Visuals\n\\(\\underline{\\text{Question 1}}\\): Do cars with big engines use more fuel than cars with small engines?\nTo answer this question I will focus on two columns:\ndispl : a cars engine size in litres\nhwy : a carâ€™s fuel efficiency on the highway in mpg.\n\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = hwy))\n\n\n\n\nNote:\n\nThere is a negative relation between engine size and fuel efficiency.\nThe mapping argument is always paired with aes(), and the x and y arguments of aes() specify which variables to map to the x and y axes.\n\n\n\n3. 3.2.4 Exercises\n\nThe following code chunk creates an empty square.\n\n\nggplot2::ggplot(data = mpg)\n\n\n\n\n\nThe mpg data set has 234 rows and 11 columns.\nThe drv variable is the type of drive the car has such as f = front wheel, r = rear wheel, and 4 = 4 wheel drive.\nThe following plot shows hwy vs.Â cyl.\n\n\nggplot2::ggplot(mpg) +\n  ggplot2::geom_point(ggplot2::aes(x = cyl, y = hwy))\n\n\n\n\nNote: This isnâ€™t very useful because it is obvious that as the number of cylinders increases the miles per gallon decreases.\n\nThe following plot shows class vs.Â drv.\n\n\nggplot2::ggplot(mpg) +\n  ggplot2::geom_point(ggplot2::aes(x = drv, y = class))\n\n\n\n\nNote: This plot isnâ€™t useful because there are no obvious trends. Categorical variables usually have a small number of values they are limited to, so it only seems like there are 12 observed values.\n\n\n4. Aesthetics\nWithin the aes() function when specifying that color is equal to a column variable then ggplot will add a color key to these variables, as shown below.\n\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = hwy, color = class))\n\n\n\n\nWhen defining color outside aes() then color is equal to a specific color (such as red or blue), and ggplot will make all points that one color, as shown below.\n\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = hwy), color = \"blue\")\n\n\n\n\nsize:\n\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = hwy, size = class))\n\n\n\n\n(Warning: using size for a discrete variable is not advised.)\nalpha: (transparency)\n\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = hwy, alpha = class))\n\n\n\n\nshape:\n\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = hwy, shape = class))\n\n\n\n\n\n\n\nshapes built into R\n\n\n\n\n5. 3.3.1 Exercises\n\nThe following code is incorrect because color is inside aes(), which is labeling all the points as â€œblueâ€.\n\n\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = hwy, color = \"blue\"))\n\n\n\n\n\nCategorical : manufacturer, model name, trans, drv, fl, and class  Continuous : displ, cty, year of manufacture, number of cylinders, and hwy\n\n\nNotice in the printed data frame the categorical variables are usually character  values, where continuous variables are numeric values such as  or .\n\n\nWhen mapping a continuous variable to an aes() such as color then then there the key also becomes continuos as shown below.\n\n\n# Categorical\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = manufacturer, color = trans))\n\n\n\n# Continuous\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = manufacturer, color = hwy))\n\n\n\n\n\nWhen mapping the same variable to multiple aesthetics then multiple keys are added as shown below.\n\n\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = hwy, size = hwy, color = displ))\n\n\n\n\n\nStroke adjusts the thickness of the boarder (for shapes 21-25) as shown below.\n\n\nggplot2::ggplot(mtcars, ggplot2::aes(wt, mpg)) +\n  ggplot2::geom_point(shape = 21, colour = \"black\", fill = \"pink\", size = 5, stroke = 5)\n\n\n\n\n\nWhen defining something like color to be displ < 5, it sets up a true or false argument for this, and applies one color (blue) to true values less than 5 and red for false values greater than 5.\n\n\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = hwy, color = displ < 5))\n\n\n\n\n\n\n6. Facets\nfacet_wrap() should be used for discrete values as shown below:\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_wrap(~ class, nrow = 2)\n\n\n\n\nTo facet on a combination of variables use facet_grid() as shown below:\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_grid(drv ~ cyl)\n\n\n\n\nUse + facet_grid(.~cyl) to not facet rows.\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_grid(.~ cyl)\n\n\n\n\n\n\n7. 3.5.1 Exercises\n\nWhen you facet a continuous variable you make A LOT of graphs.\n\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_wrap(~ hwy)\n\n\n\n\n\nThe empty cells in the facet_grid(drv ~ cyl) plot above are showing the empty points in the graph below. For example cars with four wheel drive only have an even number of cylinders so the plot of 4 wheel drive with 5 cylinders is empty because it does not exist.\n\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = drv, y = cyl))\n\n\n\n\n\nOne of the below plots is shown in rows and the other in columns. The period says not to facet the rows or the columns.\n\n\n# rows\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) +\n  facet_grid(drv ~ .)\n\n\n\n#columns\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) +\n  facet_grid(. ~ cyl)\n\n\n\n\n\nThe advantages of facet wrap allow for data with various classes or types to be analyzed by such. Additionally itâ€™s difficult for humans to visualize a large amount of color so it is easier to digest the variety of date spread out. The disadvantage of this could be that spreading the data out would make it difficult to compare observations between different categories.\n\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_wrap(~ class, nrow = 2)\n\n\n\n\n\nnrow and ncol define the number of rows and columns in the facet wrap.There is also scales, shrink, labeler, as.table, switch, drop, dir, and stip.position. Facet grid doesnâ€™t have these because it is specified in the function instead.\nVariables with more unique levels should be in columns when using facet_grid() because there is more space for columns if the plot is laid out horizontally.\n\n\n\n8. Geometric Objects\nThe side by side graphs below show the same data. The left graph uses the geometric object geom_point() which shows all the points, and the right graphs uses geom_smooth() which creates a best fit line with the dataâ€™s standard error without all the data points.\n\n# left graph: geom_point()\na <- ggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy))\n# right graph: geom_smooth()\nb <- ggplot(data = mpg) + \n  geom_smooth(mapping = aes(x = displ, y = hwy))\n# both together\ngrid.arrange(a,b, nrow = 1)\n\n\n\n\nFor different line â€œshapesâ€ geom_smooth() can be used with different linetypes within aes() as shown below.\n\nggplot(data = mpg) + \n  geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv))\n\n\n\n\nFor the following geoms, you can set the group aesthetic to a categorical variable to draw multiple objects.\n\nc <- ggplot(data = mpg) +\n  geom_smooth(mapping = aes(x = displ, y = hwy))\n              \nd <- ggplot(data = mpg) +\n  geom_smooth(mapping = aes(x = displ, y = hwy, group = drv))\n    \ne <- ggplot(data = mpg) +\n  geom_smooth(\n    mapping = aes(x = displ, y = hwy, color = drv),\n    show.legend = FALSE)\ngrid.arrange(c,d,e, nrow = 1)\n\n\n\n\nBelow multiple geometric objects are added to one plot.\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) +\n  geom_smooth(mapping = aes(x = displ, y = hwy))\n\n\n\n\nDefining the mapping aes() helps reduce repetion, as shown below.\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_smooth()\n\n\n\n\nGlobal Mapping\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(color = class)) + \n  geom_smooth()\n\n\n\n\nSubcompact (subset) mapping\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(color = class)) + \n  geom_smooth(data = filter(mpg, class == \"subcompact\"), se = FALSE)\n\n\n\n\n\n\n9. 3.6.1 Exercises\n\nline chart: geom_line()  boxplot: geom_boxplot()  histogram: geom_histogram()  area chart: geom_area()\nPrediction: the below code will show the various points and lines for drv without any standard error.\n\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + \n  geom_point() + \n  geom_smooth(se = FALSE)\n\n\n\n\n\nshow.legend = FALSE hides the legend box, and was used earlier in this chapter because it changes the size of the graphs, which would make it more difficult to compare to the other graphs."
  },
  {
    "objectID": "01_blog/2021_08_30_APIs-and-tidycensus/index.html",
    "href": "01_blog/2021_08_30_APIs-and-tidycensus/index.html",
    "title": "APIâ€™s and tidycensus",
    "section": "",
    "text": "1. Set-up\nTo start Request a Key to get an API key.\nThen create an .Renviron file to your projects main directory with â€œCENSUS_API_KEY=XXXXXXXXXXXâ€, where all the Xâ€™s represent you key.\nNote:\n\nThis key will not work with spaces on either side of the equal sign.\ntidycensus already has this utility worked into it (read ?census_api_key). They call their api key CENSUS_API_KEY (it is common for this key to be in all caps), so that is what I also called mine. This will be especially helpful in not mixing up API keys if I use other API keys in the future.\n\nNow load the tidycensus package and use readRenviron() to access the API key.\n\nlibrary(tidycensus)\nbase::readRenviron(\"../../.Renviron\")\n\nNote:\n\nThe first time you access your API key you may want to reload your environment so you donâ€™t have to restart R.\n../ tells your machine to go one folder outside the folder it is in.\nUse Sys.getenv(\"CENSUS_API_KEY\") to check your key is accesible and correct.\n\n\n\n2. Using tidycensus\nUse load_variables(year, dataset, chache=T/F) for various data sets. Read ?load_variables() for more information.\nNote:\n\nlabel shows the estimates by total, and then sex and age range.\nconcept is by sex, then race, origins, and ancestry.\n\n\na <- tidycensus::load_variables(2019, \"acs1\")\nutils::head(a, 10)\n\n# A tibble: 10 Ã— 3\n   name       label                                    concept   \n   <chr>      <chr>                                    <chr>     \n 1 B01001_001 Estimate!!Total:                         SEX BY AGE\n 2 B01001_002 Estimate!!Total:!!Male:                  SEX BY AGE\n 3 B01001_003 Estimate!!Total:!!Male:!!Under 5 years   SEX BY AGE\n 4 B01001_004 Estimate!!Total:!!Male:!!5 to 9 years    SEX BY AGE\n 5 B01001_005 Estimate!!Total:!!Male:!!10 to 14 years  SEX BY AGE\n 6 B01001_006 Estimate!!Total:!!Male:!!15 to 17 years  SEX BY AGE\n 7 B01001_007 Estimate!!Total:!!Male:!!18 and 19 years SEX BY AGE\n 8 B01001_008 Estimate!!Total:!!Male:!!20 years        SEX BY AGE\n 9 B01001_009 Estimate!!Total:!!Male:!!21 years        SEX BY AGE\n10 B01001_010 Estimate!!Total:!!Male:!!22 to 24 years  SEX BY AGE\n\n\nLetâ€™s only focus on the first line for now, â€œB01001_001â€ which should be the total estimates. Then we can use get_acs() to get data population data by state from the American Community Survey.\n\nb <- tidycensus::get_acs(geography = \"state\", year = 2019, variable = \"B01001_001\")\nutils::head(b, 10)\n\n# A tibble: 10 Ã— 5\n   GEOID NAME                 variable   estimate   moe\n   <chr> <chr>                <chr>         <dbl> <dbl>\n 1 01    Alabama              B01001_001  4876250    NA\n 2 02    Alaska               B01001_001   737068    NA\n 3 04    Arizona              B01001_001  7050299    NA\n 4 05    Arkansas             B01001_001  2999370    NA\n 5 06    California           B01001_001 39283497    NA\n 6 08    Colorado             B01001_001  5610349    NA\n 7 09    Connecticut          B01001_001  3575074    NA\n 8 10    Delaware             B01001_001   957248    NA\n 9 11    District of Columbia B01001_001   692683    NA\n10 12    Florida              B01001_001 20901636    NA\n\n\nWe can get similar population estimates setting the variable = c(â€œPOP), with get_estimates. As well asâ€DENSITYâ€; for housing unit estimates, c(â€œHUESTâ€); and for components of change estimates, c(â€œBIRTHSâ€, â€œDEATHSâ€, â€œDOMESTICMIGâ€, â€œINTERNATIONALMIGâ€, â€œNATURALINCâ€, â€œNETMIGâ€, â€œRBIRTHâ€, â€œRDEATHâ€, â€œRDOMESTICMIGâ€, â€œRINTERNATIONALMIGâ€, â€œRNATURALINCâ€, â€œRNETMIGâ€).\n\nc <- tidycensus::get_estimates(geography = \"state\", year = 2019, variable = c(\"POP\"))\nutils::head(c, 10)\n\n# A tibble: 10 Ã— 4\n   NAME                 GEOID variable    value\n   <chr>                <chr> <chr>       <dbl>\n 1 Alabama              01    POP       4903185\n 2 Alaska               02    POP        731545\n 3 Arizona              04    POP       7278717\n 4 Arkansas             05    POP       3017804\n 5 California           06    POP      39512223\n 6 Colorado             08    POP       5758736\n 7 Delaware             10    POP        973764\n 8 District of Columbia 11    POP        705749\n 9 Connecticut          09    POP       3565287\n10 Florida              12    POP      21477737\n\n\n\nd <- tidycensus::get_estimates(geography = \"county\", state = \"OR\", year = 2019, variable = c(\"POP\"))\nutils::head(d, 10)\n\n# A tibble: 10 Ã— 4\n   NAME                      GEOID variable  value\n   <chr>                     <chr> <chr>     <dbl>\n 1 Lane County, Oregon       41039 POP      382067\n 2 Washington County, Oregon 41067 POP      601592\n 3 Clatsop County, Oregon    41007 POP       40224\n 4 Jackson County, Oregon    41029 POP      220944\n 5 Grant County, Oregon      41023 POP        7199\n 6 Clackamas County, Oregon  41005 POP      418187\n 7 Tillamook County, Oregon  41057 POP       27036\n 8 Josephine County, Oregon  41033 POP       87487\n 9 Umatilla County, Oregon   41059 POP       77950\n10 Columbia County, Oregon   41009 POP       52354"
  },
  {
    "objectID": "01_blog/2021_10_19_Generative-Art-Jasmines/index.html",
    "href": "01_blog/2021_10_19_Generative-Art-Jasmines/index.html",
    "title": "Generative Art with Jasmines",
    "section": "",
    "text": "1. Set-Up\nI will be using jasmines to create art, and dplyr to pipe the code.\n\nlibrary(jasmines)\nlibrary(dplyr) \n\n\n\n2. Randi\nWhen playing around with this package, I initially had something less fluid and full of right angles, but wanted to show more movement in the design. I have a dance background and aside from fluid movement we also focused a lot on circles and rotation. Another reason I like this design is because it reminds me of a flower. I have seven tattoos, two of which are flowers. The two colors I chose are salmon and rosewood. I enjoy different shades of pink, and colors like salmon, and rosewood feel like a more sophisticated pink to me.\n\nuse_seed(5) %>%\n  entity_circle(grain = 1000, size = 10) %>%\n  unfold_warp(iterations = 100) %>%\n  style_ribbon(\n    color = \"#9E4244\",\n    background = \"#FDAB9F\")\n\n\n\n\n\n\n3. Unfolding Circle\n\nuse_seed(1) %>%\n  entity_circle(grain = 1000, size = 4) %>%\n  unfold_warp(iterations = 100) %>%\n  style_ribbon(\n    palette=\"base\",\n    colour = \"ind\",\n    background = \"mistyrose\")\n\n\n\n\n\n\n4. Typophobia\n\nscene_discs(\n  rings = 13, \n  points = 500, \n  size = 5\n  ) %>%\n  mutate(ind = 1:n()\n         ) %>%\n  unfold_warp(\n    iterations = 10,\n    scale = .5, \n    output = \"layer\" \n  ) %>%\n  unfold_tempest(\n    iterations = 10,\n    scale = .01\n  ) %>%\n  style_ribbon(\n    color = \"#48AAAD\",\n    colour = \"ind\",\n    alpha = c(.4,.1),\n    background = \"#016064\" \n  ) \n\n\n\n\n\n\n5. Snake Charmer\n\nuse_seed(4) %>%\n  entity_circle(grain = 10000) %>%\n  unfold_tempest(iterations = 13) %>%\n  style_ribbon(background = \"oldlace\")"
  },
  {
    "objectID": "01_blog/2021_10_19_Tree-Diagrams/index.html",
    "href": "01_blog/2021_10_19_Tree-Diagrams/index.html",
    "title": "Tree Diagrams",
    "section": "",
    "text": "1. Set-Up\nThis example is from W3-D5 Example 1 of my Statistics-461 Notes, and uses the data.tree package which can create a multiple node object.\n\nlibrary(data.tree)\n\n\n\n2. Creating a Node Object\nAll trees are constructed by tying together Node object, so to start I will create a new Node object for example 1.\n\nex1 <- data.tree::Node$new(\"Example 1\")\n\nFor example 1 we suppose that 1% of the population uses a certain drug. So next I want to AddChild to ex1 to show those who use the drug (d) and do not use the drug (dc, where c means compliment).\n\nd <- ex1$AddChild(\"Uses Drug\", p = 0.01)\ndc <- ex1$AddChild(\"Does Not Use Drug\", p = 0.99)\n\nNow let t be tests positive for the disease. The drug manufacturer claims that \\(P(T|D^C)=0.015\\) and \\(P(T^C|D)=0.005\\). Which means that:\n\\(P(T^C|D^C)=1-P(T|D^C)=1-0.015=0.985\\) and\n\\(P(T|D)=1-P(T^C|D)=1-0.005=0.995\\)\nSo lets add another layer of nodes to example 1.\n\nt <- d$AddChild(\"Positive Test\", p = 0.995)\ntc <- d$AddChild(\"Negative Test\", p = 0.005)\nt <- dc$AddChild(\"Positive Test\", p = 0.015)\ntc<- dc$AddChild(\"Negative Test\", p = 0.985)\n\nAnd then print what information we have.\n\nbase::print(ex1, 'p')\n\n              levelName     p\n1 Example 1                NA\n2  Â¦--Uses Drug         0.010\n3  Â¦   Â¦--Positive Test 0.995\n4  Â¦   Â°--Negative Test 0.005\n5  Â°--Does Not Use Drug 0.990\n6      Â¦--Positive Test 0.015\n7      Â°--Negative Test 0.985\n\n\nIf the probability column shows as a percentages we can use the SetFormat() function to set the decimal to 3 places.\n\ndata.tree::SetFormat(ex1, \"p\", formatFun = data.tree::FormatFixedDecimal(3))\n\nAnd print the information we have.\n\nbase::print(ex1, 'p')\n\n              levelName     p\n1 Example 1                NA\n2  Â¦--Uses Drug         0.010\n3  Â¦   Â¦--Positive Test 0.995\n4  Â¦   Â°--Negative Test 0.005\n5  Â°--Does Not Use Drug 0.990\n6      Â¦--Positive Test 0.015\n7      Â°--Negative Test 0.985\n\n\n\n\n3. Conditional Probability\nGiven a positive test, we can find the probability that a person actually uese the drug with the following equation:\n\\(\\begin{equation}\\label{a}\\begin{split}P(D|T) &= \\frac{P(T|D)\\times P(D)}{[P(T|D)\\times P(D)]+[P(T|D^C)\\times P(D^C)]}\\\\&=\\frac{(0.995)(0.01)}{(0.995\\times 0.01)+(0.015\\times 0.99)}\\\\&=\\frac{199}{496}\\\\&\\approx 0.4012\\end{split}\\end{equation}\\)\n\n\n4. Plotting a Tree Diagram\nLastly we can use the plot() function to print a Tree Diagram:\n\nbase::plot(ex1)\n\n\n\n\n\nTo visualize the tree diagram from left to right instead of top to bottom we can use the SetGraphStyle() function as shown below.\n\ndata.tree::SetGraphStyle(ex1, rankdir = \"LR\")\nbase::plot(ex1)"
  },
  {
    "objectID": "01_blog/2021_08_23_Emojis/index.html",
    "href": "01_blog/2021_08_23_Emojis/index.html",
    "title": "Enable Emojis in Quarto",
    "section": "",
    "text": "1. Visual Editor\nOne way to add emojis to a quarto blog posts is from the â€˜Visualâ€™ editor in R Studio, select the Insert tab \\(\\rightarrow\\) â€˜Special Charactersâ€™ \\(\\rightarrow\\) â€˜Insert Emoji â€¦â€™ and then selecting you desired emoji from a large list.\n\n\n2. Include 'from: markdown+emoji' in Header\nThe second way to add emojiâ€™s into a quarto blog is to include â€˜from: markdown+emojiâ€™ in the .qmd header, and then type the name of the emoji you want to include encased in colons as shown below:\n:grinning: \\(\\rightarrow\\) ðŸ˜€\n:smile: \\(\\rightarrow\\) ðŸ˜„\n:heart: \\(\\rightarrow\\) â¤ï¸\n:thumbsup: \\(\\rightarrow\\) ðŸ‘\n:call_me_hand: \\(\\rightarrow\\) ðŸ¤™\n\n\n\n\n\nFootnotes\n\n\nQuarto Documentation - Content Editingâ†©ï¸Ž"
  },
  {
    "objectID": "01_blog/2021_08_30_Ch.3-R-for-ds/index.html",
    "href": "01_blog/2021_08_30_Ch.3-R-for-ds/index.html",
    "title": "R for Data Science - Ch.3: Data Visualisations",
    "section": "",
    "text": "1. Set Up\nThis first chunk will remove warning messages from all chunks in this file. To hide this chunk use include=FALSE within the {} brackets.\n\nknitr::opts_chunk$set(warning = FALSE, message = FALSE) \n\nThis second chunk calls two packages:\n\ntidyverse: to tidy data and create visuals with ggplot2.\ngridExtra: to arrange data in a grid\n\n\nlibrary(tidyverse)\nlibrary(gridExtra)\n\nThis chapter analyzes the mpg data so Iâ€™m using the head() function from utils to view the first five rows in the mpg data set.\n\nutils::head(mpg, 5)\n\n# A tibble: 5 Ã— 11\n  manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class \n  <chr>        <chr> <dbl> <int> <int> <chr>      <chr> <int> <int> <chr> <chr> \n1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p     compaâ€¦\n2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p     compaâ€¦\n3 audi         a4      2    2008     4 manual(m6) f        20    31 p     compaâ€¦\n4 audi         a4      2    2008     4 auto(av)   f        21    30 p     compaâ€¦\n5 audi         a4      2.8  1999     6 auto(l5)   f        16    26 p     compaâ€¦\n\n\n\n\n2. Visuals\n\\(\\underline{\\text{Question 1}}\\): Do cars with big engines use more fuel than cars with small engines?\nTo answer this question I will focus on two columns:\ndispl : a cars engine size in litres\nhwy : a carâ€™s fuel efficiency on the highway in mpg.\n\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = hwy))\n\n\n\n\nNote:\n\nThere is a negative relation between engine size and fuel efficiency.\nThe mapping argument is always paired with aes(), and the x and y arguments of aes() specify which variables to map to the x and y axes.\n\n\n\n3. 3.2.4 Exercises\n\nThe following code chunk creates an empty square.\n\n\nggplot2::ggplot(data = mpg)\n\n\n\n\n\nThe mpg data set has 234 rows and 11 columns.\nThe drv variable is the type of drive the car has such as f = front wheel, r = rear wheel, and 4 = 4 wheel drive.\nThe following plot shows hwy vs.Â cyl.\n\n\nggplot2::ggplot(mpg) +\n  ggplot2::geom_point(ggplot2::aes(x = cyl, y = hwy))\n\n\n\n\nNote: This isnâ€™t very useful because it is obvious that as the number of cylinders increases the miles per gallon decreases.\n\nThe following plot shows class vs.Â drv.\n\n\nggplot2::ggplot(mpg) +\n  ggplot2::geom_point(ggplot2::aes(x = drv, y = class))\n\n\n\n\nNote: This plot isnâ€™t useful because there are no obvious trends. Categorical variables usually have a small number of values they are limited to, so it only seems like there are 12 observed values.\n\n\n4. Aesthetics\nWithin the aes() function when specifying that color is equal to a column variable then ggplot will add a color key to these variables, as shown below.\n\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = hwy, color = class))\n\n\n\n\nWhen defining color outside aes() then color is equal to a specific color (such as red or blue), and ggplot will make all points that one color, as shown below.\n\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = hwy), color = \"blue\")\n\n\n\n\nsize:\n\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = hwy, size = class))\n\n\n\n\n(Warning: using size for a discrete variable is not advised.)\nalpha: (transparency)\n\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = hwy, alpha = class))\n\n\n\n\nshape:\n\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = hwy, shape = class))\n\n\n\n\n\n\n\nshapes built into R\n\n\n\n\n5. 3.3.1 Exercises\n\nThe following code is incorrect because color is inside aes(), which is labeling all the points as â€œblueâ€.\n\n\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = hwy, color = \"blue\"))\n\n\n\n\n\nCategorical : manufacturer, model name, trans, drv, fl, and class  Continuous : displ, cty, year of manufacture, number of cylinders, and hwy\n\n\nNotice in the printed data frame the categorical variables are usually character  values, where continuous variables are numeric values such as  or .\n\n\nWhen mapping a continuous variable to an aes() such as color then then there the key also becomes continuos as shown below.\n\n\n# Categorical\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = manufacturer, color = trans))\n\n\n\n# Continuous\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = manufacturer, color = hwy))\n\n\n\n\n\nWhen mapping the same variable to multiple aesthetics then multiple keys are added as shown below.\n\n\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = hwy, size = hwy, color = displ))\n\n\n\n\n\nStroke adjusts the thickness of the boarder (for shapes 21-25) as shown below.\n\n\nggplot2::ggplot(mtcars, ggplot2::aes(wt, mpg)) +\n  ggplot2::geom_point(shape = 21, colour = \"black\", fill = \"pink\", size = 5, stroke = 5)\n\n\n\n\n\nWhen defining something like color to be displ < 5, it sets up a true or false argument for this, and applies one color (blue) to true values less than 5 and red for false values greater than 5.\n\n\nggplot2::ggplot(data = mpg) + \n  ggplot2::geom_point(mapping = ggplot2::aes(x = displ, y = hwy, color = displ < 5))\n\n\n\n\n\n\n6. Facets\nfacet_wrap() should be used for discrete values as shown below:\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_wrap(~ class, nrow = 2)\n\n\n\n\nTo facet on a combination of variables use facet_grid() as shown below:\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_grid(drv ~ cyl)\n\n\n\n\nUse + facet_grid(.~cyl) to not facet rows.\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_grid(.~ cyl)\n\n\n\n\n\n\n7. 3.5.1 Exercises\n\nWhen you facet a continuous variable you make A LOT of graphs.\n\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_wrap(~ hwy)\n\n\n\n\n\nThe empty cells in the facet_grid(drv ~ cyl) plot above are showing the empty points in the graph below. For example cars with four wheel drive only have an even number of cylinders so the plot of 4 wheel drive with 5 cylinders is empty because it does not exist.\n\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = drv, y = cyl))\n\n\n\n\n\nOne of the below plots is shown in rows and the other in columns. The period says not to facet the rows or the columns.\n\n\n# rows\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) +\n  facet_grid(drv ~ .)\n\n\n\n#columns\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) +\n  facet_grid(. ~ cyl)\n\n\n\n\n\nThe advantages of facet wrap allow for data with various classes or types to be analyzed by such. Additionally itâ€™s difficult for humans to visualize a large amount of color so it is easier to digest the variety of date spread out. The disadvantage of this could be that spreading the data out would make it difficult to compare observations between different categories.\n\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) + \n  facet_wrap(~ class, nrow = 2)\n\n\n\n\n\nnrow and ncol define the number of rows and columns in the facet wrap.There is also scales, shrink, labeler, as.table, switch, drop, dir, and stip.position. Facet grid doesnâ€™t have these because it is specified in the function instead.\nVariables with more unique levels should be in columns when using facet_grid() because there is more space for columns if the plot is laid out horizontally.\n\n\n\n8. Geometric Objects\nThe side by side graphs below show the same data. The left graph uses the geometric object geom_point() which shows all the points, and the right graphs uses geom_smooth() which creates a best fit line with the dataâ€™s standard error without all the data points.\n\n# left graph: geom_point()\na <- ggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy))\n# right graph: geom_smooth()\nb <- ggplot(data = mpg) + \n  geom_smooth(mapping = aes(x = displ, y = hwy))\n# both together\ngrid.arrange(a,b, nrow = 1)\n\n\n\n\nFor different line â€œshapesâ€ geom_smooth() can be used with different linetypes within aes() as shown below.\n\nggplot(data = mpg) + \n  geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv))\n\n\n\n\nFor the following geoms, you can set the group aesthetic to a categorical variable to draw multiple objects.\n\nc <- ggplot(data = mpg) +\n  geom_smooth(mapping = aes(x = displ, y = hwy))\n              \nd <- ggplot(data = mpg) +\n  geom_smooth(mapping = aes(x = displ, y = hwy, group = drv))\n    \ne <- ggplot(data = mpg) +\n  geom_smooth(\n    mapping = aes(x = displ, y = hwy, color = drv),\n    show.legend = FALSE)\ngrid.arrange(c,d,e, nrow = 1)\n\n\n\n\nBelow multiple geometric objects are added to one plot.\n\nggplot(data = mpg) + \n  geom_point(mapping = aes(x = displ, y = hwy)) +\n  geom_smooth(mapping = aes(x = displ, y = hwy))\n\n\n\n\nDefining the mapping aes() helps reduce repetion, as shown below.\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_smooth()\n\n\n\n\nGlobal Mapping\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(color = class)) + \n  geom_smooth()\n\n\n\n\nSubcompact (subset) mapping\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n  geom_point(mapping = aes(color = class)) + \n  geom_smooth(data = filter(mpg, class == \"subcompact\"), se = FALSE)\n\n\n\n\n\n\n9. 3.6.1 Exercises\n\nline chart: geom_line()  boxplot: geom_boxplot()  histogram: geom_histogram()  area chart: geom_area()\nPrediction: the below code will show the various points and lines for drv without any standard error.\n\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + \n  geom_point() + \n  geom_smooth(se = FALSE)\n\n\n\n\n\nshow.legend = FALSE hides the legend box, and was used earlier in this chapter because it changes the size of the graphs, which would make it more difficult to compare to the other graphs."
  },
  {
    "objectID": "01_blog/2021_09_20_APIs-and-tidycensus/index.html",
    "href": "01_blog/2021_09_20_APIs-and-tidycensus/index.html",
    "title": "APIâ€™s and tidycensus",
    "section": "",
    "text": "1. Set-up\nTo start Request a Key to get an API key.\nThen create an .Renviron file to your projects main directory with â€œCENSUS_API_KEY=XXXXXXXXXXXâ€, where all the Xâ€™s represent you key.\nNote:\n\nThis key will not work with spaces on either side of the equal sign.\ntidycensus already has this utility worked into it (read ?census_api_key). They call their api key CENSUS_API_KEY (it is common for this key to be in all caps), so that is what I also called mine. This will be especially helpful in not mixing up API keys if I use other API keys in the future.\n\nNow load the tidycensus package and use readRenviron() to access the API key.\n\nlibrary(tidycensus)\nbase::readRenviron(\"../../.Renviron\")\n\nNote:\n\nThe first time you access your API key you may want to reload your environment so you donâ€™t have to restart R.\n../ tells your machine to go one folder outside the folder it is in.\nUse Sys.getenv(\"CENSUS_API_KEY\") to check your key is accesible and correct.\n\n\n\n2. Using tidycensus\nUse load_variables(year, dataset, chache=T/F) for various data sets. Read ?load_variables() for more information.\nNote:\n\nlabel shows the estimates by total, and then sex and age range.\nconcept is by sex, then race, origins, and ancestry.\n\n\na <- tidycensus::load_variables(2019, \"acs1\")\nutils::head(a, 10)\n\n# A tibble: 10 Ã— 3\n   name       label                                    concept   \n   <chr>      <chr>                                    <chr>     \n 1 B01001_001 Estimate!!Total:                         SEX BY AGE\n 2 B01001_002 Estimate!!Total:!!Male:                  SEX BY AGE\n 3 B01001_003 Estimate!!Total:!!Male:!!Under 5 years   SEX BY AGE\n 4 B01001_004 Estimate!!Total:!!Male:!!5 to 9 years    SEX BY AGE\n 5 B01001_005 Estimate!!Total:!!Male:!!10 to 14 years  SEX BY AGE\n 6 B01001_006 Estimate!!Total:!!Male:!!15 to 17 years  SEX BY AGE\n 7 B01001_007 Estimate!!Total:!!Male:!!18 and 19 years SEX BY AGE\n 8 B01001_008 Estimate!!Total:!!Male:!!20 years        SEX BY AGE\n 9 B01001_009 Estimate!!Total:!!Male:!!21 years        SEX BY AGE\n10 B01001_010 Estimate!!Total:!!Male:!!22 to 24 years  SEX BY AGE\n\n\nLetâ€™s only focus on the first line for now, â€œB01001_001â€ which should be the total estimates. Then we can use get_acs() to get data population data by state from the American Community Survey.\n\nb <- tidycensus::get_acs(geography = \"state\", year = 2019, variable = \"B01001_001\")\nutils::head(b, 10)\n\n# A tibble: 10 Ã— 5\n   GEOID NAME                 variable   estimate   moe\n   <chr> <chr>                <chr>         <dbl> <dbl>\n 1 01    Alabama              B01001_001  4876250    NA\n 2 02    Alaska               B01001_001   737068    NA\n 3 04    Arizona              B01001_001  7050299    NA\n 4 05    Arkansas             B01001_001  2999370    NA\n 5 06    California           B01001_001 39283497    NA\n 6 08    Colorado             B01001_001  5610349    NA\n 7 09    Connecticut          B01001_001  3575074    NA\n 8 10    Delaware             B01001_001   957248    NA\n 9 11    District of Columbia B01001_001   692683    NA\n10 12    Florida              B01001_001 20901636    NA\n\n\nWe can get similar population estimates setting the variable = c(â€œPOP), with get_estimates. As well asâ€DENSITYâ€; for housing unit estimates, c(â€œHUESTâ€); and for components of change estimates, c(â€œBIRTHSâ€, â€œDEATHSâ€, â€œDOMESTICMIGâ€, â€œINTERNATIONALMIGâ€, â€œNATURALINCâ€, â€œNETMIGâ€, â€œRBIRTHâ€, â€œRDEATHâ€, â€œRDOMESTICMIGâ€, â€œRINTERNATIONALMIGâ€, â€œRNATURALINCâ€, â€œRNETMIGâ€).\n\nc <- tidycensus::get_estimates(geography = \"state\", year = 2019, variable = c(\"POP\"))\nutils::head(c, 10)\n\n# A tibble: 10 Ã— 4\n   NAME                 GEOID variable    value\n   <chr>                <chr> <chr>       <dbl>\n 1 Alabama              01    POP       4903185\n 2 Alaska               02    POP        731545\n 3 Arizona              04    POP       7278717\n 4 Arkansas             05    POP       3017804\n 5 California           06    POP      39512223\n 6 Colorado             08    POP       5758736\n 7 Delaware             10    POP        973764\n 8 District of Columbia 11    POP        705749\n 9 Connecticut          09    POP       3565287\n10 Florida              12    POP      21477737\n\n\n\nd <- tidycensus::get_estimates(geography = \"county\", state = \"OR\", year = 2019, variable = c(\"POP\"))\nutils::head(d, 10)\n\n# A tibble: 10 Ã— 4\n   NAME                      GEOID variable  value\n   <chr>                     <chr> <chr>     <dbl>\n 1 Lane County, Oregon       41039 POP      382067\n 2 Washington County, Oregon 41067 POP      601592\n 3 Clatsop County, Oregon    41007 POP       40224\n 4 Jackson County, Oregon    41029 POP      220944\n 5 Grant County, Oregon      41023 POP        7199\n 6 Clackamas County, Oregon  41005 POP      418187\n 7 Tillamook County, Oregon  41057 POP       27036\n 8 Josephine County, Oregon  41033 POP       87487\n 9 Umatilla County, Oregon   41059 POP       77950\n10 Columbia County, Oregon   41009 POP       52354"
  },
  {
    "objectID": "01_blog/2021_09_27_Generative-Art-Jasmines/index.html",
    "href": "01_blog/2021_09_27_Generative-Art-Jasmines/index.html",
    "title": "Generative Art with Jasmines",
    "section": "",
    "text": "1. Set-Up\nI will be using jasmines to create art, and dplyr to pipe the code.\n\nlibrary(jasmines)\nlibrary(dplyr) \n\n\n\n2. Randi\nWhen playing around with this package, I initially had something less fluid and full of right angles, but wanted to show more movement in the design. I have a dance background and aside from fluid movement we also focused a lot on circles and rotation. Another reason I like this design is because it reminds me of a flower. I have seven tattoos, two of which are flowers. The two colors I chose are salmon and rosewood. I enjoy different shades of pink, and colors like salmon, and rosewood feel like a more sophisticated pink to me.\n\nuse_seed(5) %>%\n  entity_circle(grain = 1000, size = 10) %>%\n  unfold_warp(iterations = 100) %>%\n  style_ribbon(\n    color = \"#9E4244\",\n    background = \"#FDAB9F\")\n\n\n\n\n\n\n3. Unfolding Circle\n\nuse_seed(1) %>%\n  entity_circle(grain = 1000, size = 4) %>%\n  unfold_warp(iterations = 100) %>%\n  style_ribbon(\n    palette=\"base\",\n    colour = \"ind\",\n    background = \"mistyrose\")\n\n\n\n\n\n\n4. Typophobia\n\nscene_discs(\n  rings = 13, \n  points = 500, \n  size = 5\n  ) %>%\n  mutate(ind = 1:n()\n         ) %>%\n  unfold_warp(\n    iterations = 10,\n    scale = .5, \n    output = \"layer\" \n  ) %>%\n  unfold_tempest(\n    iterations = 10,\n    scale = .01\n  ) %>%\n  style_ribbon(\n    color = \"#48AAAD\",\n    colour = \"ind\",\n    alpha = c(.4,.1),\n    background = \"#016064\" \n  ) \n\n\n\n\n\n\n5. Snake Charmer\n\nuse_seed(4) %>%\n  entity_circle(grain = 10000) %>%\n  unfold_tempest(iterations = 13) %>%\n  style_ribbon(background = \"oldlace\")"
  },
  {
    "objectID": "01_blog/2021_10_18_Tree-Diagrams/index.html",
    "href": "01_blog/2021_10_18_Tree-Diagrams/index.html",
    "title": "Tree Diagrams",
    "section": "",
    "text": "1. Set-Up\nThis example is from W3-D5 Example 1 of my Statistics-461 Notes, and uses the data.tree package which can create a multiple node object.\n\nlibrary(data.tree)\n\n\n\n2. Creating a Node Object\nAll trees are constructed by tying together Node object, so to start I will create a new Node object for example 1.\n\nex1 <- data.tree::Node$new(\"Example 1\")\n\nFor example 1 we suppose that 1% of the population uses a certain drug. So next I want to AddChild to ex1 to show those who use the drug (d) and do not use the drug (dc, where c means compliment).\n\nd <- ex1$AddChild(\"Uses Drug\", p = 0.01)\ndc <- ex1$AddChild(\"Does Not Use Drug\", p = 0.99)\n\nNow let t be tests positive for the disease. The drug manufacturer claims that \\(P(T|D^C)=0.015\\) and \\(P(T^C|D)=0.005\\). Which means that:\n\\(P(T^C|D^C)=1-P(T|D^C)=1-0.015=0.985\\) and\n\\(P(T|D)=1-P(T^C|D)=1-0.005=0.995\\)\nSo lets add another layer of nodes to example 1.\n\nt <- d$AddChild(\"Positive Test\", p = 0.995)\ntc <- d$AddChild(\"Negative Test\", p = 0.005)\nt <- dc$AddChild(\"Positive Test\", p = 0.015)\ntc<- dc$AddChild(\"Negative Test\", p = 0.985)\n\nAnd then print what information we have.\n\nbase::print(ex1, 'p')\n\n              levelName     p\n1 Example 1                NA\n2  Â¦--Uses Drug         0.010\n3  Â¦   Â¦--Positive Test 0.995\n4  Â¦   Â°--Negative Test 0.005\n5  Â°--Does Not Use Drug 0.990\n6      Â¦--Positive Test 0.015\n7      Â°--Negative Test 0.985\n\n\nIf the probability column shows as a percentages we can use the SetFormat() function to set the decimal to 3 places.\n\ndata.tree::SetFormat(ex1, \"p\", formatFun = data.tree::FormatFixedDecimal(3))\n\nAnd print the information we have.\n\nbase::print(ex1, 'p')\n\n              levelName     p\n1 Example 1                NA\n2  Â¦--Uses Drug         0.010\n3  Â¦   Â¦--Positive Test 0.995\n4  Â¦   Â°--Negative Test 0.005\n5  Â°--Does Not Use Drug 0.990\n6      Â¦--Positive Test 0.015\n7      Â°--Negative Test 0.985\n\n\n\n\n3. Conditional Probability\nGiven a positive test, we can find the probability that a person actually uese the drug with the following equation:\n\\(\\begin{equation}\\label{a}\\begin{split}P(D|T) &= \\frac{P(T|D)\\times P(D)}{[P(T|D)\\times P(D)]+[P(T|D^C)\\times P(D^C)]}\\\\&=\\frac{(0.995)(0.01)}{(0.995\\times 0.01)+(0.015\\times 0.99)}\\\\&=\\frac{199}{496}\\\\&\\approx 0.4012\\end{split}\\end{equation}\\)\n\n\n4. Plotting a Tree Diagram\nLastly we can use the plot() function to print a Tree Diagram:\n\nbase::plot(ex1)\n\n\n\n\n\nTo visualize the tree diagram from left to right instead of top to bottom we can use the SetGraphStyle() function as shown below.\n\ndata.tree::SetGraphStyle(ex1, rankdir = \"LR\")\nbase::plot(ex1)"
  },
  {
    "objectID": "01_blog/2021_10_25_Epsilon-min/index.html",
    "href": "01_blog/2021_10_25_Epsilon-min/index.html",
    "title": "Let epsilon = min(x-a, b-x)",
    "section": "",
    "text": "Explanation\nConsider the real number line \\(\\mathbb{R}\\) and some value x which lies between (a,b). When \\(\\epsilon=\\text{min}(x-a,b-x)\\) then \\(\\epsilon\\) is equal to \\(2\\times\\) smaller distance to either a or b. For example, in the picture below x is closer to a, so x-a is smaller than b-x. Therefore \\(\\epsilon=2(x-a)\\).\n\nIf it helps to apply values consider \\(a=1\\), \\(b=4\\), and \\(x=2\\). Then\n\\(\\epsilon=\\text{min}(x-a,b-x)=\\text{min}(2-1,4-2)=\\text{min}(1,2)=2(1)=2\\)"
  },
  {
    "objectID": "01_blog/2022_01_06-latex-hacks/index.html",
    "href": "01_blog/2022_01_06-latex-hacks/index.html",
    "title": "Latex",
    "section": "",
    "text": "Basic Symbols :\n\n\\(\\sim\\) : \\sim\n\\(\\circ\\) : \\circ\n\\(\\square\\) : \\square\n\\(\\equiv\\) : \\equiv\n\\(\\cong\\) : \\cong\n\\(\\unlhd\\) : \\unlhd\n\\(\\div\\) : \\div\n\\(\\nless\\) : \\nless\n\\(\\ngtr\\) : ngtr\n\\(\\emptyset\\) : \\emptyset\n\\(\\subseteq\\) : \\subseteq\n\\(a\\choose b\\) : a\\choose b\n\\(\\underset{i\\in I}U\\) : \\underset{i\\in I}U\n\\(\\Leftrightarrow\\) : \\Leftrightarrow\n\\(\\langle\\rangle\\) : \\langle\\rangle\n\\(\\overrightarrow{\\rm AB}\\) : \\overrightarrow{\\rm AB}\n\\(\\underline{\\text{Underline Text}}\\) : \\underline{\\text{Underline Text}}\n\\(\\mathbb{R}\\) : \\mathbb{R}\n\nbb : blackboard bold\n\n\\(\\mathcal{F}\\) : \\mathcal{F}\n\\(\\mathscr{F}\\) : \\mathscr{F}\n\n\n\nGreek :\n\n\\(\\tau\\) : \\tau\n\\(\\rho\\) : \\rho\n\\(\\alpha\\) : \\alpha\n\\(\\beta\\) : \\beta\n\\(\\Gamma\\) : \\Gamma\n\\(\\epsilon\\) : \\epsilon\n\\(\\mathcal{E}\\) : \\mathcal{E}\n\\(\\varepsilon\\) : \\varepsilon\n\\(\\varphi\\) : \\varphi\n\n\n\nInline :\nLimits above and below sums and integrals\n\n\\(\\sum\\limits_{n}^{i}\\int_0^1\\) : \\limits\n\nMatrices and Matrix Equations\n\n\\(\\begin{smallmatrix} 1 & 0 \\\\ 0 & 1\\end{smallmatrix}\\) : \\begin{smallmatrix} 1 & 0 \\\\ 0 & 1\\end{smallmatrix}\n\n\\(I=[\\begin{smallmatrix} 1 & 0 \\\\ 0 & 1\\end{smallmatrix}]\\)\n\\((\\begin{smallmatrix} 1 & 1 \\\\ 1 & 0\\end{smallmatrix})(\\begin{smallmatrix} 1 & 1 \\\\ 0 & 1\\end{smallmatrix})\\ne(\\begin{smallmatrix} 1 & 1 \\\\ 0 & 1\\end{smallmatrix})(\\begin{smallmatrix} 1 & 1 \\\\ 1 & 0\\end{smallmatrix})\\)\n\n\n\n\nMultiple Lines :\nFunction\n\n\\(F(x)=\\begin{cases}1 & x\\geq 0\\\\0 & \\text{otherwise}\\end{cases}\\) : F(x)=\\begin{cases} . . . \\end{cases}\n\n1 & x \\geq 0 \\\\\n0 & \\text{otherwise}\n\n\nMatrix\n\n\\(F(x)=\\begin{bmatrix}1\\\\2\\\\3\\\\4\\\\5\\\\6\\\\\\end{bmatrix}\\) : F(x)=\\begin{bmatrix}1\\\\2\\\\3\\\\4\\\\5\\\\6\\\\\\end{bmatrix}\n\nSeries of Equalities\n\n\\(\\begin{equation}\\label{a}\\begin{split}x &= a+b+c\\\\&=1+2+3\\\\&=6\\end{split}\\end{equation}\\)\n\n: \\begin{equation}\\{label}\\begin{split}... \\end{split}\\end{equation}\n\nx &= a+b+c \\\\\n&= 1+2+3\n&= 6\n\n\n\nPotential Errors :\nSpelling\n\nEx: \\overlien{AB} should be \\overline{AB}\n\nlabel , table\n\n\nMore than two backslashes\n\nEx: Equation will work but \\end{equation} will show at the end. One of the lines has more than two backslashes at the end of at least one of the lines.\n\nSpace before final $\n\nEx: $\\angle ABC $ should be $\\angle ABC$\n\nMore $ on one side of equation than the other\n\nEx: $A^2+B^2=C^2$$ should be $A^2+B^2=C^2$\n\nClosing {}\n\nEx: $\\int\\limits_{1}^{2$ should be $\\int\\limits_{1}^{2}$\n\nUnderset on the wrong side\n\nEx: U\\underset{i\\in I} should be \\underset{i\\in I}U\n\n\n\nAdvice :\nDetextify\n\nIf you donâ€™t know what a symbol is, draw it in Detextify here.\n\nGoogle Docs Equations Boxes\n\nMost latex backslashes work in google docâ€™s equation boxes. If I have to do a â€œquickâ€ homework, and dont want to spend a lot of time formatting a pdf in R, I will use google docs and latex in the equations boxes.\n\nNote: This is how I began learning latex.\nWhy learn Latex?\n\nGenerally speaking it looks nicer, especially on reports, projects, and presentations.\nA lot of my peers and professors who wrote math by hand would have problems in their dominate writing hand. Typing math with latex helps spread that tension out to two hands.\nIt saves time in the long run, since updating a line in a typed document is a lot easier than re-writing an entire problem by hand. Not to mention the ability to use copy paste."
  },
  {
    "objectID": "01_blog/2021_11_22_Skewness/index.html",
    "href": "01_blog/2021_11_22_Skewness/index.html",
    "title": "Skewness",
    "section": "",
    "text": "Physical Interpretation\nImagine your body is a symmetrical bell curve where your neck is your mode, waist is your median, hips are your mean, and are all stacked on top of each other to create a symmetrical bell curve as shown in the image below.\n\nWhen the hips are to the the right of your neck then you are creating a right skew. When you hips are to the left of your neck then your body bell curve is left skewed as shown in the diagram below.\n\nShakira famously said her hips donâ€™t lie, but my hips dictate skewness."
  },
  {
    "objectID": "01_blog/2021_11_29_Proof-Idempotent/index.html",
    "href": "01_blog/2021_11_29_Proof-Idempotent/index.html",
    "title": "Prove H and I-H are Idempotent",
    "section": "",
    "text": "Proof\nFor H to be Idempotent then \\(HH=H\\)\n\\[\\begin{equation}\\label{HH=H}\n\\begin{split}\nHH & =[X(X^TX)^{-1}X^T][X(X^TX)^{-1}X^T]\\\\\n& = X(X^TX)^{-1}X^TX(X^TX)^{-1}X^T\\quad\\quad(X^TX)^{-1}X^TX=1\\\\\n& = X(X^TX)^{-1}X^T\\\\\n& = H\n\\end{split}\n\\end{equation}\\]\nTherefore by the series of equalities H is idempotent.\nFor I-H to be idempotent then \\((I-H)(I-H)=I-H\\)\n\\[\\begin{equation}\\label{I-H}\n\\begin{split}\n(I-H)(I-H) & =II-HI-IH+HH\\quad\\quad II=I, HI=IH=H, HH=H\\\\\n& = I-H-H+H\\\\\n& = I-H\n\\end{split}\n\\end{equation}\\]\nTherefor by the series of equalities I-H is idempotent.\nQED."
  },
  {
    "objectID": "01_blog/2022_10_31_NBA-functions/index.html",
    "href": "01_blog/2022_10_31_NBA-functions/index.html",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "",
    "text": "In this tutorial I will be creating functions to scrape NBA data. The goal here is to prepare these functions to use in a package for future analysis."
  },
  {
    "objectID": "01_blog/2022_10_31_NBA-functions/index.html#about-the-data",
    "href": "01_blog/2022_10_31_NBA-functions/index.html#about-the-data",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "0_1. About-The-Data",
    "text": "0_1. About-The-Data\nI will be scrapping data from Basketball Reference which gets thier data updated regularly by a handful of contributors and sources. The main reasons I like using this data is because itâ€™s reliable, updated regularly, and similar sites exist for other non-NBA Sports (such as: WNBA, Baseball, Football, and others) if I wanted to expand my research outside the NBA."
  },
  {
    "objectID": "01_blog/2022_10_31_NBA-functions/index.html#package-installs",
    "href": "01_blog/2022_10_31_NBA-functions/index.html#package-installs",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "0_2. Package Installs",
    "text": "0_2. Package Installs\nThe packages I will be using are rvest to scrape the data and magrittr to pipe it. To install these packages, copy the code below and remove the first comment hash (command - shift - c).\n\n## install packages\n# install.packages(\"rvest\",  \"magrittr\")\n\nThen load:\n\n# load packages \nlibrary(rvest) \nlibrary(magrittr)"
  },
  {
    "objectID": "01_blog/2022_10_31_NBA-functions/index.html#team-statistics",
    "href": "01_blog/2022_10_31_NBA-functions/index.html#team-statistics",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "1_1. Team Statistics:",
    "text": "1_1. Team Statistics:\nThe first function Iâ€™m creating scrapes team statistics, which will need the user to input the teams url slug, the year that team attended or attends the NBA playoffs, and the stats_tb or statistics table that corresponds to what is shown on Basketball Reference. Currently not all tables work, but it should work for: #per_game, #totals, #per_36_minutes, and #advanced.\n\nscrape_team_data <- function(slug, year, stats_tb){\n    \"\n  A function that returns a data frame of team statistics. \n  \n  @param slug is string of three letters that represents the teams url. \n  @param year is a string that corresponds to the NBA finals.\n  @param stats_tb is a string that corresponds to the statistics table on BasketBall Reference such as #per_game, #totals, #per_36_minutes, and #advanced\n  \n  @return a df of team statistics\n  \"\n  # define team page URL\n  url <- base::paste0(\"https://www.basketball-reference.com/teams/\",\n                slug,\"/\", year, \".html\")\n  \n  # Read stats table\n  stats_tb <- url %>%\n  read_html %>%\n  html_node(stats_tb) %>% \n  html_table()\n  \n  # Rename Column 2 to Name \n  base::names(stats_tb)[2] <- \"Name\"\n  \n  # Replace NA values with 0 (for stat functions)\n  stats_tb[base::is.na(stats_tb)] <- 0\n  \n  # make data frame\n  df <- base::data.frame(stats_tb)\n  base::return(df)\n  }\n\n\nExamples\n\nA. Current Blazers Roster\n\nzers_roster <- scrape_team_data(\"POR\",\"2022\",\"#roster\")\nutils::head(zers_roster)\n\n  No.              Name Pos  Ht  Wt         Birth.Date Var.7 Exp\n1  21    Keljin Blevins  SF 6-4 200  November 24, 1995    us   1\n2   4    Greg Brown III  SF 6-9 205  September 1, 2001    us   R\n3  33  Robert Covington  PF 6-7 209  December 14, 1990    us   8\n4  34 Jarron Cumberland  SG 6-5 205 September 22, 1997    us   R\n5  18         Kris Dunn  PG 6-3 205     March 18, 1994    us   5\n6  16         CJ Elleby  SF 6-6 200      June 16, 2000    us   1\n                       College\n1 Southern Miss, Montana State\n2                        Texas\n3              Tennessee State\n4                   Cincinnati\n5                   Providence\n6             Washington State\n\n\n\n\nB. 1997 Chicago Bulls Total Statistics\n\nbulls_totals <- scrape_team_data(\"CHI\", \"1998\", \"#totals\")\nutils::head(bulls_totals)\n\n  Rk           Name Age  G GS   MP  FG  FGA   FG. X3P X3PA  X3P. X2P X2PA  X2P.\n1  1 Michael Jordan  34 82 82 3181 881 1893 0.465  30  126 0.238 851 1767 0.482\n2  2  Dennis Rodman  36 80 66 2856 155  360 0.431   4   23 0.174 151  337 0.448\n3  3     Ron Harper  34 82 82 2284 293  665 0.441  16   84 0.190 277  581 0.477\n4  4     Toni KukoÄ  29 74 52 2235 383  841 0.455  63  174 0.362 320  667 0.480\n5  5    Luc Longley  29 58 58 1703 277  609 0.455   0    0 0.000 277  609 0.455\n6  6 Scottie Pippen  32 44 44 1652 315  704 0.447  61  192 0.318 254  512 0.496\n   eFG.  FT FTA   FT. ORB DRB  TRB AST STL BLK TOV  PF  PTS\n1 0.473 565 721 0.784 130 345  475 283 141  45 185 151 2357\n2 0.436  61 111 0.550 421 780 1201 230  47  18 147 238  375\n3 0.453 162 216 0.750 107 183  290 241 108  48  91 181  764\n4 0.493 155 219 0.708 121 206  327 314  76  37 154 149  984\n5 0.455 109 148 0.736 113 228  341 161  34  62 130 206  663\n6 0.491 150 193 0.777  53 174  227 254  79  43 109 116  841\n\n\nHere we can see when Michael Jordan won his 6th ring with the Chicago Bulls he was also the leagues leading point scorer with 2,357 total points that season. Dennis Rodman was also a league leader that season in rebounds collecting a total of 1,201 rebounds."
  },
  {
    "objectID": "01_blog/2022_10_31_NBA-functions/index.html#player-statistics",
    "href": "01_blog/2022_10_31_NBA-functions/index.html#player-statistics",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "1_2. Player Statistics",
    "text": "1_2. Player Statistics\nThe second function will scrape player statistics. The user will need to input the players name, and the stats_tb or statistics table that corresponds to what is shown on Basketball Reference. Currently not all tables work, but it should work for: #per_game, #totals, #per_36_minutes, and #advanced.\n\nscrape_player_data <- function(name, stats_tb){\n  \"\n  A function that returns a data frame of player statistics. \n  \n  @param name is a string that represnets an NBA players name\n  @param stats_tb is a string that corresponds to the statistics table on BasketBall Reference such as #per_game, #totals, #per_36_minutes, and #advanced\n  \n  @return a df of player statistics\n  \"\n  # make name lower case\n  lower_case_name <- base::tolower(name)\n\n  # split name \n  split_name <- base::strsplit(lower_case_name, \" +\")[[1]]\n\n  # define first and last name\n  first_name <- split_name[[1]]\n  last_name <- split_name[[2]]\n  \n  # first letter of last name\n  letter <- base::substr(last_name, 1,1)\n  \n  # first five letters of last name \n  last_5 <- base::substr(last_name, 1, 5)\n  \n  # first two letters of first name\n  first_2 <- base::substr(first_name, 1,2)\n  \n  # define team page URL\n  url <- base::paste0(\"https://www.basketball-reference.com/players/\",letter ,\"/\",last_5,first_2,\"01.html\")\n  \n  # Read stats table\n  stats_tb <- url %>%\n  read_html %>%\n  html_node(stats_tb) %>% \n  html_table()\n  \n  # Rename Column 2 to Name \n  names(stats_tb)[2] <- \"Name\"\n  \n  # Replace NA values with 0 (for stat functions)\n  stats_tb[base::is.na(stats_tb)] <- 0\n  \n  # make list a dataframe\n  df <- base::data.frame(stats_tb)\n  \n  base::return(df)\n  }\n\n\nExamples\n\nC. Allen Iverson Per Game Stats\n\nai_per_game <- scrape_player_data(\"Allen Iverson\", \"#per_game\")\nhead(ai_per_game)\n\n   Season Name  Tm  Lg Pos  G GS   MP   FG  FGA  FG. X3P X3PA X3P. X2P X2PA\n1 1996-97   21 PHI NBA  PG 76 74 40.1  8.2 19.8 .416 2.0  6.0 .341 6.2 13.8\n2 1997-98   22 PHI NBA  PG 80 80 39.4  8.1 17.6 .461 0.9  2.9 .298 7.2 14.7\n3 1998-99   23 PHI NBA  SG 48 48 41.5  9.1 22.0 .412 1.2  4.1 .291 7.9 17.9\n4 1999-00   24 PHI NBA  SG 70 70 40.8 10.4 24.8 .421 1.3  3.7 .341 9.1 21.0\n5 2000-01   25 PHI NBA  SG 71 71 42.0 10.7 25.5 .420 1.4  4.3 .320 9.4 21.2\n6 2001-02   26 PHI NBA  SG 60 59 43.7 11.1 27.8 .398 1.3  4.5 .291 9.8 23.4\n  X2P. eFG.  FT  FTA  FT. ORB DRB TRB AST STL BLK TOV  PF  PTS\n1 .448 .467 5.0  7.2 .702 1.5 2.6 4.1 7.5 2.1 0.3 4.4 3.1 23.5\n2 .494 .486 4.9  6.7 .729 1.1 2.6 3.7 6.2 2.2 0.3 3.1 2.5 22.0\n3 .440 .439 7.4  9.9 .751 1.4 3.5 4.9 4.6 2.3 0.1 3.5 2.0 26.8\n4 .435 .446 6.3  8.9 .713 1.0 2.8 3.8 4.7 2.1 0.1 3.3 2.3 28.4\n5 .441 .447 8.2 10.1 .814 0.7 3.1 3.8 4.6 2.5 0.3 3.3 2.1 31.1\n6 .419 .422 7.9  9.8 .812 0.7 3.8 4.5 5.5 2.8 0.2 4.0 1.7 31.4\n\n\nNotice that when Allen Iverson won the NBAâ€™s MVP in 2001 he was putting up about 31 points a game.\n\n\nD. Kareem Abdul-Jabbar Totals\n\nkaj_totals <- scrape_player_data(\"Kareem Abdul-Jabbar\", \"#totals\")\nutils::head(kaj_totals)\n\n   Season Name  Tm  Lg Pos  G GS   MP   FG  FGA   FG. X3P X3PA X3P.  X2P X2PA\n1 1969-70   22 MIL NBA   C 82  0 3534  938 1810 0.518   0    0    0  938 1810\n2 1970-71   23 MIL NBA   C 82  0 3288 1063 1843 0.577   0    0    0 1063 1843\n3 1971-72   24 MIL NBA   C 81  0 3583 1159 2019 0.574   0    0    0 1159 2019\n4 1972-73   25 MIL NBA   C 76  0 3254  982 1772 0.554   0    0    0  982 1772\n5 1973-74   26 MIL NBA   C 81  0 3548  948 1759 0.539   0    0    0  948 1759\n6 1974-75   27 MIL NBA   C 65  0 2747  812 1584 0.513   0    0    0  812 1584\n   X2P.  eFG.  FT FTA   FT. ORB DRB  TRB AST STL BLK TOV  PF  PTS Var.31\n1 0.518 0.518 485 743 0.653   0   0 1190 337   0   0   0 283 2361      0\n2 0.577 0.577 470 681 0.690   0   0 1311 272   0   0   0 264 2596      0\n3 0.574 0.574 504 732 0.689   0   0 1346 370   0   0   0 235 2822      0\n4 0.554 0.554 328 460 0.713   0   0 1224 379   0   0   0 208 2292      0\n5 0.539 0.539 295 420 0.702 287 891 1178 386 112 283   0 238 2191      0\n6 0.513 0.513 325 426 0.763 194 718  912 264  65 212   0 205 1949      0\n  Trp.Dbl\n1       0\n2       1\n3       1\n4       2\n5       3\n6       1"
  },
  {
    "objectID": "01_blog/2022_10_31_NBA-functions/index.html#box-scores",
    "href": "01_blog/2022_10_31_NBA-functions/index.html#box-scores",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "1_3. Box Scores",
    "text": "1_3. Box Scores\nThe last function still needs a bit of work, but will pull box scores of all the NBA games on a given day. The user will need to enter the game_day or day of the games they want box scores for.\nNote: Ideally this function would return a list with each game being its own df, but for now it only prints one data frame that includes all games played on that date. There also seem to be issues when only one game is played, or it is the first game of the season (see examples below), but for now those issues are manageable.\n\nbox_scores <- function(game_day){\n  \"\n  A function that returns a data frame of box scores. \n  \n  @param game_day is a string that represents the date in the form Y-M-D\n  \n  @return a df of box scores from that day.\n  \"\n  # split by dash\n  split_date <- base::strsplit(game_day, \"-\")\n  \n  # year - month - day \n  year <- split_date[[1]][[1]]\n  month <- split_date[[1]][[2]]\n  day <- split_date[[1]][[3]]\n  \n  #url\n  url <- base::paste0(\"https://www.basketball-reference.com/boxscores/?month=\",\n                month ,\"&day=\", day,\"&year=\", year)\n  \n  # read url\n  html <- read_html(url)\n  \n  # extract all the 'div\" items from the html as tables\n  div <- html %>% \n    html_elements(\"div\") %>% \n    html_table()\n  \n  #remove empties\n  div <- div[base::sapply(div, function(i) dim(i)[1]) > 0]\n  \n  # only keep rows == 7\n  div <- div[base::sapply(div, function(i) nrow(i)[1]) == 7]\n  \n  # empty list\n  my_vec <- base::list()\n  \n  #for loop\n  for(i in 1:base::length(div)) {        \n  my_out <- div[[i]][3:5,] \n  my_vec <- c(my_vec, my_out)\n  df <- base::data.frame(my_vec)\n  }\n  \n  df <- df[-1,]\n  \n  base::return(df)\n}\n\n\nExample\n\nE. Box Scores for 10-19-2022 (works correctly)\n\noct_19 <- box_scores(\"2022-10-19\")\noct_19\n\n       X1 X2 X3 X4 X5        X1.1 X2.1 X3.1 X4.1 X5.1    X1.2 X2.2 X3.2 X4.2\n2 Houston 20 30 30 27 New Orleans   32   26   40   32 Orlando   28   27   28\n3 Atlanta 26 33 25 33    Brooklyn   14   36   28   30 Detroit   17   40   34\n  X5.2       X1.3 X2.3 X3.3 X4.3 X5.3     X1.4 X2.4 X3.4 X4.4 X5.4 X6    X1.5\n2   26 Washington   36   24   27   27 New York   23   23   33   29  4 Chicago\n3   22    Indiana   25   27   25   30  Memphis   25   36   24   23  7   Miami\n  X2.5 X3.5 X4.5 X5.5          X1.6 X2.6 X3.6 X4.6 X5.6    X1.7 X2.7 X3.7 X4.7\n2   28   31   37   20 Oklahoma City   22   30   35   21  Dallas   32   30   19\n3   33   26   27   22     Minnesota   35   30   22   28 Phoenix   24   21   31\n  X5.7       X1.8 X2.8 X3.8 X4.8 X5.8        X1.9 X2.9 X3.9 X4.9 X5.9     X1.10\n2   24   Portland   32   19   33   31   Charlotte   38   30   30   31 Cleveland\n3   31 Sacramento   23   32   29   24 San Antonio   22   25   28   27   Toronto\n  X2.10 X3.10 X4.10 X5.10  X1.11 X2.11 X3.11 X4.11 X5.11\n2    22    35    27    21 Denver    30    23    27    22\n3    28    23    25    32   Utah    37    38    19    29\n\n\n\n\nF. Box scores for the first day of the â€™22/â€™23 NBA season (issues)\n\noct_18 <- box_scores(\"2022-10-18\")\noct_18\n\n            X1 X2 X3 X4 X5         X1.1 X2.1 X3.1 X4.1 X5.1               X1.2\n2 Philadelphia 29 34 25 29    LA Lakers   22   30   19   38 Philadelphia 76ers\n3       Boston 24 39 35 28 Golden State   25   34   32   32 Western Conference\n  X2.2 X3.2 X4.2 X5.2    X6    X7   X8   X9 X10 X11 X12  X13 X14 X15  X16 X17\n2    0    1 .000  1.0 117.0 126.0 <NA> <NA>  NA  NA  NA <NA>  NA  NA <NA>  NA\n3    W    L W/L%   GB  PS/G  PA/G <NA> <NA>  NA  NA  NA <NA>  NA  NA <NA>  NA\n  X18 X19 X20 X21 X22  X23  X24  X25  X26  X27  X28  X29  X30  X31 X32 X33 X34\n2  NA  NA  NA  NA  NA <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>  NA  NA  NA\n3  NA  NA  NA  NA  NA <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>  NA  NA  NA\n   X35 X36 X37  X38 X39 X40 X41 X42 X43 X44\n2 <NA>  NA  NA <NA>  NA  NA  NA  NA  NA  NA\n3 <NA>  NA  NA <NA>  NA  NA  NA  NA  NA  NA\n\n\nIssue: For the first game of the season there is an are NA tables that are being pulled in.\nG. First game of the 1992 NBA Finals AKA Michael Jordanâ€™s famous Shrug (issues)\n\nfinals_92_g1 <- box_scores(\"1992-6-3\")\nfinals_92_g1\n\n        X1 X2 X3 X4 X5     X1.1 X2.1 X3.1 X4.1 X5.1\n2 Portland 30 21 17 21 Portland   30   21   17   21\n3  Chicago 33 33 38 18  Chicago   33   33   38   18\n\n\nIssue: For days where only one game is played the one game is printed twice in the data frame."
  },
  {
    "objectID": "01_blog/2022_10_24_P-logically-equivalent-neg-neg-P/index.html",
    "href": "01_blog/2022_10_24_P-logically-equivalent-neg-neg-P/index.html",
    "title": "Prove P is Logically Equivalent to the Negation of the Negation of P",
    "section": "",
    "text": "Solution 1\nConsider the truth table for P, \\(\\neg P\\), and \\(\\neg (\\neg P)\\), as shown below in Figure 1:\n\n\nFigure 1: Truth Table\n\n\nP\n\\(\\neg P\\)\n\\(\\neg (\\neg P)\\)\n\n\n\n\nT\nF\nT\n\n\nF\nT\nF\n\n\n\n\nSince the truth values for P and \\(\\neg (\\neg P)\\) are the same then P and \\(\\neg (\\neg P)\\) are logically equivalent.\n\n\nSolution 2\nSuppose by way of contradiction (BWOC) that P and \\(\\neg (\\neg P)\\) are not logically equivalent.\nLet P be true and then \\(\\neg (\\neg P)\\) would be false.\nIf P is true then \\(\\neg P\\) would be false, but \\(\\neg P\\) and \\(\\neg (\\neg P)\\) cannot both be false. Therefore BWOC \\(\\neg (\\neg P)\\equiv P\\).\n\\(\\square\\)"
  },
  {
    "objectID": "01_blog/2021_12_20_Transformations-and-Weighting-to-Correct-Model-Inadequacies/index.html",
    "href": "01_blog/2021_12_20_Transformations-and-Weighting-to-Correct-Model-Inadequacies/index.html",
    "title": "Transformations and Weighting to Correct Model Inadequacies",
    "section": "",
    "text": "1. Set Up\nFor this analysis I will be using four packages:\n\nmagrittr: for piping (%>%)\ndplyr: to arrange the data\nMASS: to use the boxcox function\nlatex2exp: to put latex on graphs\n\n\nlibrary(latex2exp) \nlibrary(magrittr) \nlibrary(dplyr) \nlibrary(MASS) \n\n\n\n2. Example 5.1: The Electric Utility Data\nAn electric utility company is interested in developing a model relating peak-hour demand \\((y)\\) to total energy usage during the month \\((x)\\).\nTo start lets look at the data.\n\nex51 <- utils::read.csv(\"../../00_data/ex5-1.csv\")\nex51\n\n    X Customer x_.kWh. y_.kW.\n1   1        1     679   0.79\n2   2        2     292   0.44\n3   3        3    1012   0.56\n4   4        4     493   0.79\n5   5        5     582   2.70\n6   6        6    1156   3.64\n7   7        7     997   4.73\n8   8        8    2189   9.50\n9   9        9    1097   5.34\n10 10       10    2078   6.85\n11 11       11    1818   5.84\n12 12       12    1700   5.21\n13 13       13     747   3.25\n14 14       14    2030   4.43\n15 15       15    1643   3.16\n16 16       16     414   0.50\n17 17       17     354   0.17\n18 18       18    1276   1.88\n19 19       19     745   0.77\n20 20       20     435   1.39\n21 21       21     540   0.56\n22 22       22     874   1.56\n23 23       23    1543   5.28\n24 24       24    1029   0.64\n25 25       25     710   4.00\n26 26       26    1434   0.31\n27 27       27     837   4.20\n28 28       28    1748   4.88\n29 29       29    1381   3.48\n30 30       30    1428   7.58\n31 31       31    1255   2.63\n32 32       32    1777   4.99\n33 33       33     370   0.59\n34 34       34    2316   8.19\n35 35       35    1130   4.79\n36 36       36     463   0.51\n37 37       37     770   1.74\n38 38       38     724   4.10\n39 39       39     808   3.94\n40 40       40     790   0.96\n41 41       41     783   3.29\n42 42       42     406   0.44\n43 43       43    1242   3.24\n44 44       44     658   2.14\n45 45       45    1746   5.71\n46 46       46     468   0.64\n47 47       47    1114   1.90\n48 48       48     413   0.51\n49 49       49    1787   8.33\n50 50       50    3560  14.94\n51 51       51    1495   5.11\n52 52       52    2221   3.85\n53 53       53    1526   3.93\n\n\nRight away we can see that for each customer there is a value x_.kWH for Kilowatt hour which corresponds to energy usage during the month, and y_.kW for kilowatt which would then be peak-hour demand. The plot of this is shown below.\n\nbase::plot(ex51$x_.kWh., \n           ex51$y_.kW.,\n           xlab = \"Usage\",\n           ylab = \"Demand\")\n\n\n\n\nScatter diagram of the energy demand (kW) versus energy usage (kWh)\n\n\n\n\nAs a starting point a simple linear regression model is assumed. Lets look at the summary to get an equation for the least-squares fit, and analyze variability.\n\nlm51 <- stats::lm(ex51$y_.kW. ~ ex51$x_.kWh., data = ex51)\nsummary(lm51)\n\n\nCall:\nstats::lm(formula = ex51$y_.kW. ~ ex51$x_.kWh., data = ex51)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.1399 -0.8275 -0.1934  1.2376  3.1522 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -0.8313037  0.4416121  -1.882   0.0655 .  \nex51$x_.kWh.  0.0036828  0.0003339  11.030 4.11e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.577 on 51 degrees of freedom\nMultiple R-squared:  0.7046,    Adjusted R-squared:  0.6988 \nF-statistic: 121.7 on 1 and 51 DF,  p-value: 4.106e-15\n\n\nFrom our summary our we can extrapolate our least-squares fit is: \\(\\hat y=-0.83130+0.00368x\\)\nFor this model \\(R^2=0.7046\\); that is about 70% of the variability in demand is accounted for by the straight-line fit to energy usage. The summary statistics do not reveal any obvious problems with this model.\nBelow this model is plotted with a red line.\n\nbase::plot(ex51$x_.kWh.,\n           ex51$y_.kW.,\n           xlab = \"Usage\",\n           ylab = \"Demand\")\ngraphics::abline(lm51, col = \"red\")\n\n\n\n\nScatter diagram of the energy demand (kW) versus energy usage (kWh) with Simple Linear Model\n\n\n\n\nFrom visual inspection we can see the points on the far left side of the graph are much closer to the best fit line than those in the middle and right side of the graph. We might want to apply a transformation to this model, so lets look at the Studentized Residual also known as r student.\n\nbase::plot(stats::fitted(lm51),\n           stats::rstudent(lm51),\n           ylab=latex2exp::TeX(r'($t_i$)'),\n           xlab=latex2exp::TeX(r'($\\hat{y}_i$)'),\n           pch = 16);graphics::abline(0, 0,lty = 2)\n\n\n\n\nPlot of R-Student vs.Â fitted values\n\n\n\n\nFrom this graph we can see that the residuals form an outward-opening funnel, indicating that the error variance is increasing as energy consumption increases. A transformation may be helpful in correcting this model inadequacy. To select the form of the transformation, note that the response variable y may be viewed as a â€œcountâ€ of the number of kilowatts used by a customer during a particular hour. The simplest probabilistic model for count data is the Poisson distribution. This suggests regressing \\(y^*=\\sqrt{y}\\) on x as a variance-stabilizing transformation.\n\nex51$ystar <- base::sqrt(ex51$y_.kW.)\nlm51T <- stats::lm(ex51$ystar ~ ex51$x_.kWh., data = ex51)\nbase::summary(lm51T)\n\n\nCall:\nstats::lm(formula = ex51$ystar ~ ex51$x_.kWh., data = ex51)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.39185 -0.30576 -0.03875  0.25378  0.81027 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  5.822e-01  1.299e-01   4.481 4.22e-05 ***\nex51$x_.kWh. 9.529e-04  9.824e-05   9.699 3.61e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.464 on 51 degrees of freedom\nMultiple R-squared:  0.6485,    Adjusted R-squared:  0.6416 \nF-statistic: 94.08 on 1 and 51 DF,  p-value: 3.614e-13\n\n\nThe resulting least-squares fit is: \\(\\hat y^*=0.5822+0.0009529x\\)\n\nbase::plot(stats::fitted(lm51T),\n           stats::rstudent(lm51T),\n           ylab=latex2exp::TeX(r'($t_i$)'),\n           xlab=latex2exp::TeX(r'($\\hat{y}^*_i$)'),\n           pch = 16);graphics::abline(0, 0,lty = 2)\n\n\n\n\nThe impression from examining this plot is that the variance is stable; consequently, we conclude that the transformed model is adequate.\nNote that there is one suspiciously large residual (customer 26) and one customer whose energy usage is somewhat large (customer 50). The effect of these two points on the fit should be studied further before the model is released for use.\n\n\n3. Example 5.2: The Windmill Data\nA research engineer is investigating the use of a windmill to generate electricity. He has collected data on the DC Output from his windmill and the corresponding wind velocity.\n\nex52 <- utils::read.csv(\"../../00_data/ex5-2.csv\")\nutils::head(ex52)\n\n  X ObservationNumber_i WindVelocity_xi_mph DCOutput_yi\n1 1                   1                 5.0       1.582\n2 2                   2                 6.0       1.822\n3 3                   3                 3.4       1.057\n4 4                   4                 2.7       0.500\n5 5                   5                10.0       2.236\n6 6                   6                 9.7       2.386\n\n\nThe data is plotted below.\n\nbase::plot(ex52$WindVelocity_xi_mph,\n           ex52$DCOutput_yi,\n           xlab = \"Wind Velocity, X\",\n           ylab = \"DC Output, Y\")\n\n\n\n\nInspection of the scatter diagram indicates that the relationship between DC output \\((y)\\) and wind velocity \\((x)\\) may be nonlinear. However, we initially fit a straight-line model to the data, and look at the summary statistics.\n\nlm52 <- stats::lm(ex52$DCOutput_yi ~ ex52$WindVelocity_xi_mph, data = ex52)\nbase::summary(lm52)\n\n\nCall:\nstats::lm(formula = ex52$DCOutput_yi ~ ex52$WindVelocity_xi_mph, \n    data = ex52)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.59869 -0.14099  0.06059  0.17262  0.32184 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)               0.13088    0.12599   1.039     0.31    \nex52$WindVelocity_xi_mph  0.24115    0.01905  12.659 7.55e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2361 on 23 degrees of freedom\nMultiple R-squared:  0.8745,    Adjusted R-squared:  0.869 \nF-statistic: 160.3 on 1 and 23 DF,  p-value: 7.546e-12\n\n\nThe summary statistics for this model are \\(R^2=0.8745\\), and \\(F_0=160.26\\) (the P-value is <0.0001), and he regression model is: \\(\\hat y=0.1309+0.2411x\\), shown in red below.\n\nbase::plot(ex52$WindVelocity_xi_mph,\n           ex52$DCOutput_yi,\n           xlab = \"Wind Velocity, x\",\n           ylab = \"DC Output, Y\")\ngraphics::abline(lm52, col = \"red\")\n\n\n\n\nBelow we can extract the fitted and residual values from our linear model, and then arrange them in order of increasing wind speed.\n\nex52$fitted <- stats::fitted(lm52)\nex52$resid <- stats::resid(lm52)\nex52 %>% dplyr::arrange(-dplyr::desc(ex52$WindVelocity_xi_mph)) \n\n    X ObservationNumber_i WindVelocity_xi_mph DCOutput_yi    fitted       resid\n1  25                  25                2.45       0.123 0.7216899 -0.59868986\n2   4                   4                2.70       0.500 0.7819771 -0.28197708\n3  11                  11                2.90       0.653 0.8302069 -0.17720685\n4   8                   8                3.05       0.558 0.8663792 -0.30837918\n5   3                   3                3.40       1.057 0.9507813  0.10621871\n6  16                  16                3.60       1.137 0.9990111  0.13798894\n7  24                  24                3.95       1.144 1.0834132  0.06058683\n8  23                  23                4.10       1.194 1.1195855  0.07441450\n9  13                  13                4.60       1.562 1.2401599  0.32184007\n10  1                   1                5.00       1.582 1.3366195  0.24538052\n11 20                  20                5.45       1.501 1.4451365  0.05586353\n12 14                  14                5.80       1.737 1.5295386  0.20746142\n13  2                   2                6.00       1.822 1.5777683  0.24423165\n14 10                  10                6.20       1.866 1.6259981  0.24000188\n15 12                  12                6.35       1.930 1.6621705  0.26782955\n16 19                  19                7.00       1.800 1.8189172 -0.01891722\n17 15                  15                7.40       2.088 1.9153768  0.17262323\n18 17                  17                7.85       2.179 2.0238938  0.15510624\n19  9                   9                8.15       2.166 2.0962384  0.06976158\n20 18                  18                8.80       2.112 2.2529852 -0.14098518\n21 21                  21                9.10       2.303 2.3253298 -0.02232985\n22  7                   7                9.55       2.294 2.4338468 -0.13984684\n23  6                   6                9.70       2.386 2.4700192 -0.08401917\n24  5                   5               10.00       2.236 2.5423638 -0.30636383\n25 22                  22               10.20       2.310 2.5905936 -0.28059360\n\n\nThe residuals show a distinct pattern, that is, they move systematically from negative to positive and back to negative again as wind speed increases.\n\nbase::plot(stats::fitted(lm52),\n           stats::resid(lm52),\n           ylab=TeX(r'($e_i$)'),\n           xlab=TeX(r'($\\hat{y}_i$)'),\n           pch = 16);graphics::abline(0, 0,lty = 2)\n\n\n\n\nThis residual plot indicates model inadequacy and implies that the linear relationship has not captured all of the information in the wind speed variable. Note that the curvature was apparent in the earlier scatter diagram, but is greatly amplified in the residual plot\nClearly some other model form must be considered. We might initially consider using a quadratic model such as: \\(y=\\beta_0+\\beta_1x+\\beta_2x^2+\\epsilon\\) to account for the curvature. However since the quadratic model will eventually bend downward as wind speed increases, it would not be appropriate for these data. A more reasonable model for windmill data that incorporates an upper asymptote would be: \\(y=\\beta_0+\\beta_1(\\frac{1}{x})+\\epsilon\\).\n\nex52$xstar <- 1/ex52$WindVelocity_xi_mph\nlm52T <- stats::lm(ex52$DCOutput_yi ~ ex52$xstar, data = ex52)\nbase::summary(lm52T)\n\n\nCall:\nstats::lm(formula = ex52$DCOutput_yi ~ ex52$xstar, data = ex52)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.20547 -0.04940  0.01100  0.08352  0.12204 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   2.9789     0.0449   66.34   <2e-16 ***\nex52$xstar   -6.9345     0.2064  -33.59   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.09417 on 23 degrees of freedom\nMultiple R-squared:   0.98, Adjusted R-squared:  0.9792 \nF-statistic:  1128 on 1 and 23 DF,  p-value: < 2.2e-16\n\n\nThe fitted regression model is \\(\\hat y=2.9789-6.9345x'\\)\nThe summary statistics for this model are \\(R^2=0.98\\), and \\(F_0=1128\\) (the p value is <0.0001).\n\nbase::plot(stats::fitted(lm52T),\n           stats::rstudent(lm52T),\n           ylab=TeX(r'($t_i$)'),\n           xlab=TeX(r'($\\hat{y}_i$)'),\n           pch = 16);graphics::abline(0, 0,lty = 2)\n\n\n\n\nThis plot does not reveal any serious problems.\n\n\n4. Example 5.3: The Electic Utility Data\nWe use the Box-Cox procedure to select a variance-stabilizing transformation. The values of \\(SS_{Res}(\\lambda)\\) for various values are shown in the table.\n\nboxcoxResult = MASS::boxcox(ex51$y_.kW. ~ ex51$x_.kWh., data = ex51, lambda = seq(-2,2,0.125))\n\n\n\n\nThe Box-Cox graph shows most of the data is below the 95% confidence interval.\n\nlambda <- boxcoxResult$x[which.max(boxcoxResult$y)]\nlambda\n\n[1] 0.5454545\n\n\nWhere \\(\\lambda\\approx\\) 0.5454545 could be used as an appropriate exponent to use to transform the data into a â€œnormal shape.â€"
  },
  {
    "objectID": "01_blog/2022_01_31_LearnGeom/index.html",
    "href": "01_blog/2022_01_31_LearnGeom/index.html",
    "title": "LearnGeom",
    "section": "",
    "text": "1. Set Up\nTo create coordinate planes, trianges, and line segments I will be using the LearnGeom package.\n\nlibrary(LearnGeom)\n\n\n\n2. Coordinate Plane\nTo create a coordinate plane I will first need to define x and y minimums and maximums, and then plot the planes with the CoordinatePlane() function.\n\nx_min <- 0\nx_max <- 10\ny_min <- 0\ny_max <- 10\nLearnGeom::CoordinatePlane(x_min, x_max, y_min, y_max)\n\n\n\n\nNULL\n\n\n\n\n3. Polygons\nTo create a triangle with labels:\n\nPrint the coordinate plane I just created.\nDefine three points of a triangle.\nUse CreatePolygon() function to create the polygon.\nUse the Draw() function to draw the polygon.\nDefine label = TRUE to show the points of a triangle.\n\n\nLearnGeom::CoordinatePlane(x_min, x_max, y_min, y_max)\n\nNULL\n\nP1 <- c(1,4)\nP2 <- c(3,7)\nP3 <- c(4, 1)\nPoly <- LearnGeom::CreatePolygon(P1, P2, P3)\n\n[1] \"Some of the inserted points are collinear. This could lead to a defective polygon.\"\n\nLearnGeom::Draw(Poly, c(\"pink\"), label = TRUE)\n\n\n\n\nTriangle\n\n\n\n\nNULL\n\n\nTo create a trapezoid:\n\nPrint the coordinate plane I just created.\nDefine four points of a trapezoid.\nUse CreatePolygon() function to create the polygon.\n\nNote: The order of points will matter.\n\nUse the Draw() function to draw the polygon.\n\n\nLearnGeom::CoordinatePlane(x_min, x_max, y_min, y_max)\n\nNULL\n\nP4 <- c(6, 3)\nP5 <- c(8, 3)\nP6 <- c(9, 8)\nP7 <- c(7, 8)\nPoly2 <- LearnGeom::CreatePolygon(P4, P5, P6, P7)\n\n[1] \"Some of the inserted points are collinear. This could lead to a defective polygon.\"\n\nLearnGeom::Draw(Poly2, c(\"light blue\"))\n\n\n\n\nTrapezoid\n\n\n\n\nNULL\n\n\nWe can also print both polygons on the same graph, shown below.\n\nLearnGeom::CoordinatePlane(x_min, x_max, y_min, y_max)\n\nNULL\n\nLearnGeom::Draw(Poly, c(\"pink\"), label = TRUE)\n\nNULL\n\nLearnGeom::Draw(Poly2, c(\"light blue\"))\n\n\n\n\nTriangle and Trapezoid\n\n\n\n\nNULL\n\n\n\n\n4. Angle and Point Line Segments\nTo create a Segment Angle:\n\nPrint the coordinate plane I just created.\nDefine a points where the line originates from.\nDefine the angle of the line.\nDefine the length of the line.\nUse CreateSegmentAngle() function to create the line segment.\nUse the Draw() function to draw the line.\n\n\nLearnGeom::CoordinatePlane(x_min, x_max, y_min, y_max)\n\nNULL\n\nP <- c(0,0)\nangle <- 30\nlen <- 10\nSegment <- LearnGeom::CreateSegmentAngle(P, angle, len)\nLearnGeom::Draw(Segment, \"blue\")\n\n\n\n\nNULL\n\n\nSegment Point\nTo create a Segment (with) Point(s):\n\nPrint the coordinate plane.\nDefine two endpoint.\nUse CreateSegmentPoint() function to create the line segment.\nUse the Draw() function to draw the line.\n\n\nLearnGeom::CoordinatePlane(x_min, x_max, y_min, y_max)\n\nNULL\n\nP1 <- c(2,8)\nP2 <- c(8,6)\nSegment <- LearnGeom::CreateSegmentPoints(P1, P2)\nLearnGeom::Draw(Segment, \"purple\")\n\n\n\n\nNULL"
  },
  {
    "objectID": "01_blog/2022_01_24-latex-hacks/index.html",
    "href": "01_blog/2022_01_24-latex-hacks/index.html",
    "title": "Latex",
    "section": "",
    "text": "Basic Symbols :\n\n\\(\\sim\\) : \\sim\n\\(\\circ\\) : \\circ\n\\(\\square\\) : \\square\n\\(\\equiv\\) : \\equiv\n\\(\\cong\\) : \\cong\n\\(\\unlhd\\) : \\unlhd\n\\(\\div\\) : \\div\n\\(\\nless\\) : \\nless\n\\(\\ngtr\\) : ngtr\n\\(\\emptyset\\) : \\emptyset\n\\(\\subseteq\\) : \\subseteq\n\\(a\\choose b\\) : a\\choose b\n\\(\\underset{i\\in I}U\\) : \\underset{i\\in I}U\n\\(\\Leftrightarrow\\) : \\Leftrightarrow\n\\(\\langle\\rangle\\) : \\langle\\rangle\n\\(\\overrightarrow{\\rm AB}\\) : \\overrightarrow{\\rm AB}\n\\(\\underline{\\text{Underline Text}}\\) : \\underline{\\text{Underline Text}}\n\\(\\mathbb{R}\\) : \\mathbb{R}\n\nbb : blackboard bold\n\n\\(\\mathcal{F}\\) : \\mathcal{F}\n\\(\\mathscr{F}\\) : \\mathscr{F}\n\n\n\nGreek :\n\n\\(\\tau\\) : \\tau\n\\(\\rho\\) : \\rho\n\\(\\alpha\\) : \\alpha\n\\(\\beta\\) : \\beta\n\\(\\Gamma\\) : \\Gamma\n\\(\\epsilon\\) : \\epsilon\n\\(\\mathcal{E}\\) : \\mathcal{E}\n\\(\\varepsilon\\) : \\varepsilon\n\\(\\varphi\\) : \\varphi\n\n\n\nInline :\nLimits above and below sums and integrals\n\n\\(\\sum\\limits_{n}^{i}\\int_0^1\\) : \\limits\n\nMatrices and Matrix Equations\n\n\\(\\begin{smallmatrix} 1 & 0 \\\\ 0 & 1\\end{smallmatrix}\\) : \\begin{smallmatrix} 1 & 0 \\\\ 0 & 1\\end{smallmatrix}\n\n\\(I=[\\begin{smallmatrix} 1 & 0 \\\\ 0 & 1\\end{smallmatrix}]\\)\n\\((\\begin{smallmatrix} 1 & 1 \\\\ 1 & 0\\end{smallmatrix})(\\begin{smallmatrix} 1 & 1 \\\\ 0 & 1\\end{smallmatrix})\\ne(\\begin{smallmatrix} 1 & 1 \\\\ 0 & 1\\end{smallmatrix})(\\begin{smallmatrix} 1 & 1 \\\\ 1 & 0\\end{smallmatrix})\\)\n\n\n\n\nMultiple Lines :\nFunction\n\n\\(F(x)=\\begin{cases}1 & x\\geq 0\\\\0 & \\text{otherwise}\\end{cases}\\) : F(x)=\\begin{cases} . . . \\end{cases}\n\n1 & x \\geq 0 \\\\\n0 & \\text{otherwise}\n\n\nMatrix\n\n\\(F(x)=\\begin{bmatrix}1\\\\2\\\\3\\\\4\\\\5\\\\6\\\\\\end{bmatrix}\\) : F(x)=\\begin{bmatrix}1\\\\2\\\\3\\\\4\\\\5\\\\6\\\\\\end{bmatrix}\n\nSeries of Equalities\n\n\\(\\begin{equation}\\label{a}\\begin{split}x &= a+b+c\\\\&=1+2+3\\\\&=6\\end{split}\\end{equation}\\)\n\n: \\begin{equation}\\{label}\\begin{split}... \\end{split}\\end{equation}\n\nx &= a+b+c \\\\\n&= 1+2+3\n&= 6\n\n\n\nPotential Errors :\nSpelling\n\nEx: \\overlien{AB} should be \\overline{AB}\n\nlabel , table\n\n\nMore than two backslashes\n\nEx: Equation will work but \\end{equation} will show at the end. One of the lines has more than two backslashes at the end of at least one of the lines.\n\nSpace before final $\n\nEx: $\\angle ABC $ should be $\\angle ABC$\n\nMore $ on one side of equation than the other\n\nEx: $A^2+B^2=C^2$$ should be $A^2+B^2=C^2$\n\nClosing {}\n\nEx: $\\int\\limits_{1}^{2$ should be $\\int\\limits_{1}^{2}$\n\nUnderset on the wrong side\n\nEx: U\\underset{i\\in I} should be \\underset{i\\in I}U\n\n\n\nAdvice :\nDetextify\n\nIf you donâ€™t know what a symbol is, draw it in Detextify here.\n\nGoogle Docs Equations Boxes\n\nMost latex backslashes work in google docâ€™s equation boxes. If I have to do a â€œquickâ€ homework, and dont want to spend a lot of time formatting a pdf in R, I will use google docs and latex in the equations boxes.\n\nNote: This is how I began learning latex.\nWhy learn Latex?\n\nGenerally speaking it looks nicer, especially on reports, projects, and presentations.\nA lot of my peers and professors who wrote math by hand would have problems in their dominate writing hand. Typing math with latex helps spread that tension out to two hands.\nIt saves time in the long run, since updating a line in a typed document is a lot easier than re-writing an entire problem by hand. Not to mention the ability to use copy paste.\n\n\n\nBonus:\nColors\n\n\\(\\color{red}\\text{colored text}\\) : \\color{red}\\text{colored text}"
  },
  {
    "objectID": "01_blog/2022_02_21_UO-ggplot2/index.html",
    "href": "01_blog/2022_02_21_UO-ggplot2/index.html",
    "title": "UO: ggplot2 Part 2",
    "section": "",
    "text": "1. Set Up\nFor this post we used the following packages:\n\nggplot2: to create nice looking plots.\nmagrittr: to pipe %>%.\ndplyr: to use filter().\nflametree: to make art.\nozmaps: to make Australian Maps.\nrmapshaper: to use ms_simplyfy to simplify polygons.\nplotly: to create interactive plots.\n\n\nlibrary(ggplot2)\nlibrary(magrittr)\nlibrary(dplyr)\nlibrary(flametree)\nlibrary(ozmaps)\nlibrary(rmapshaper)\nlibrary(plotly)\n\nAnd the following data sets:\n\ncars\nBOD(Biochemical Oxygen Demand)\n\n\ndata(\"cars\")\ndata (\"BOD\")\n\n\n\n2. ggplot2 Review\nTo start we made a simple point plot using the cars data set.\nNote: ggplot(data= <DATA>, mapping = aes(<MAPPING>))+ <GEOM FUNCTION>()\n\nggplot2::ggplot(data = mpg, mapping = ggplot2::aes(x = displ, y = hwy)) + \n  ggplot2::geom_point()\n\n\n\n\nWe can compare this to a simple plot in base R.\nNote : the $ is how we id the specific variable we are wanting to work with.\n\nbase::plot(mpg$displ, mpg$hwy)\n\n\n\n\n\n\n3. Line Graph\nStarting with base R:\nNote: help(pressure) is the same as ?pressure\n\nbase::plot(pressure$temperature, pressure$pressure, type = \"l\")\n# add points\ngraphics::points(pressure$temperature, pressure$pressure)\n# add lines (and points)\ngraphics::lines(pressure$temperature, pressure$pressure/2, col = \"red\")\ngraphics::points(pressure$temperature, pressure$pressure/2, col = \"red\")\n\n\n\n\nggplot:\n\nggplot2::ggplot(pressure, ggplot2::aes(x = temperature, y = pressure)) + \n  ggplot2::geom_line() + \n  ggplot2::geom_point() + \n  ggplot2::geom_line(ggplot2::aes(x = temperature, y = pressure/2), color = \"red\") + \n  ggplot2::geom_point(ggplot2::aes(x = temperature, y = pressure/2), color = \"red\") \n\n\n\n\n\n\n4. Bar Graphs\nBase R:\n\ngraphics::barplot(BOD$demand, names.arg = BOD$Time)\n\n\n\n\n\ngraphics::barplot(base::table(mtcars$cyl))\n\n\n\n\nggplot2:\n\nggplot2::ggplot(BOD, ggplot2::aes(x = base::factor(Time), y = demand)) + \n  ggplot2::geom_col()\n\n\n\n\nNotice that the 6 isnâ€™t there because of factor().\nNote : geom_bar does counts, but column has the height of the bar based on the data.\n\nggplot2::ggplot(mtcars, aes(x=cyl)) +\n  ggplot2::geom_bar()\n\n\n\n\n\n\n5. Histogram\nBase R:\n\ngraphics::hist(mtcars$mpg, breaks = 4)\n\n\n\n\nggplot2:\n\nggplot2::ggplot(mtcars, ggplot2::aes(x=mpg)) +\n  ggplot2::geom_histogram(binwidth = 4)\n\n\n\n\n\n\n6. Boxplot\nBase R:\n\nbase::plot(ToothGrowth$supp, ToothGrowth$len)\n\n\n\n\nBase R: Formula Syntax\n\nbase::plot(len ~ supp, data = ToothGrowth)\nbase::plot(len ~ supp + dose, data = ToothGrowth)\n\n\n\n\n\n\n\nggplot2:\n\nggplot2::ggplot(ToothGrowth, ggplot2::aes(x= supp, y = len)) +\n  ggplot2::geom_boxplot()\n\n\n\n\n\n\n7. Time Series\nggplot2 will automatically recognize the variable as a date as long as the variable is imported as a date.\nTo start create some dummy data:\n\ndata <- base::data.frame(\n  day = base::as.Date(\"2017-06-14\")-0:364,\n  value = stats::runif(365)\n)\nutils::head(data)\n\n         day     value\n1 2017-06-14 0.6035865\n2 2017-06-13 0.2421695\n3 2017-06-12 0.9796016\n4 2017-06-11 0.2389377\n5 2017-06-10 0.8995370\n6 2017-06-09 0.9711135\n\n\nThen plot it with ggplot2:\n\nggplot2::ggplot(data, ggplot2::aes(x = day, y = value)) +\n  ggplot2::geom_line()\n\n\n\n\nNow to make a plot with the economics data set which is included in ggplot2.\n\nggplot2::ggplot(data = economics, ggplot2::aes(x = date, y = pop)) +\n  ggplot2::geom_line()\n\n\n\n\nNext create a subset of the data from 2006 and beyond:\n\nsubset <- ggplot2::economics %>%\n  dplyr::filter(date>base::as.Date(\"2006-1-1\"))\n\nNow to create a different line graph of the subset data over time where the size of the line is based on the value of unemployment (which is the number of unemployment in thousands).\n\nggplot2::ggplot(economics, ggplot2::aes(x = date, y = pop)) +\n  ggplot2::geom_line(ggplot2::aes(size = unemploy), color = \"red\")\n\n\n\n\n\n\n8. Maps\nUsing map_data() get lat and long data for counties in Oregon:\n\nor_counties <- ggplot2::map_data(\"county\", \"oregon\") %>%\n  dplyr::select(lon = long, lat, group, id = subregion)\nutils::head(or_counties)\n\n        lon      lat group    id\n1 -117.2042 44.30683     1 baker\n2 -117.4907 44.30683     1 baker\n3 -117.4907 44.38704     1 baker\n4 -117.5366 44.42142     1 baker\n5 -117.5709 44.42142     1 baker\n6 -117.5996 44.43861     1 baker\n\n\nUsing or_counties data create a ggplot2 map:\n\nggplot2::ggplot(or_counties, ggplot2::aes(lon, lat, group = group))+\n  ggplot2::geom_polygon(fill = \"white\", color = \"grey\") +\n  ggplot2::coord_quickmap()\n\n\n\n\nUsing ozmap_states get the names of the different states in Australia.\n\noz_stats <- ozmaps::ozmap_states\noz_stats\n\nSimple feature collection with 9 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 105.5507 ymin: -43.63203 xmax: 167.9969 ymax: -9.229287\nGeodetic CRS:  GDA94\n# A tibble: 9 Ã— 2\n  NAME                                                                  geometry\n* <chr>                                                       <MULTIPOLYGON [Â°]>\n1 New South Wales              (((150.7016 -35.12286, 150.6611 -35.11782, 150.6â€¦\n2 Victoria                     (((146.6196 -38.70196, 146.6721 -38.70259, 146.6â€¦\n3 Queensland                   (((148.8473 -20.3457, 148.8722 -20.37575, 148.85â€¦\n4 South Australia              (((137.3481 -34.48242, 137.3749 -34.46885, 137.3â€¦\n5 Western Australia            (((126.3868 -14.01168, 126.3625 -13.98264, 126.3â€¦\n6 Tasmania                     (((147.8397 -40.29844, 147.8902 -40.30258, 147.8â€¦\n7 Northern Territory           (((136.3669 -13.84237, 136.3339 -13.83922, 136.3â€¦\n8 Australian Capital Territory (((149.2317 -35.222, 149.2346 -35.24047, 149.271â€¦\n9 Other Territories            (((167.9333 -29.05421, 167.9188 -29.0344, 167.93â€¦\n\n\nThen create a ggplot2 map of Australia:\n\nggplot2::ggplot(oz_stats)+\n  ggplot2::geom_sf() +\n  ggplot2::coord_sf()\n\n\n\n\nNext we remove the â€œOther territoriesâ€, and create a multi-polygon data set of Australian Bureau of Statistics.\n\noz_stats <- ozmaps::ozmap_states %>% \n  dplyr::filter(NAME != \"Other Territories\")\noz_votes <- rmapshaper::ms_simplify(ozmaps::abs_ced)\n\nThen create another map of Australian territories:\n\nggplot2::ggplot()+\n  ggplot2::geom_sf(data = oz_stats, mapping = ggplot2::aes(fill = NAME)) +\n  ggplot2::geom_sf(data = oz_votes, fill = NA) +\n  ggplot2::coord_sf()\n\n\n\n\n\n\n9. Plotly\nAn interactive graph of the iris data:\n\nfig <- plotly::plot_ly(data = iris, x = ~Sepal.Length, y = ~Petal.Length)\nfig\n\n\n\n\n\nAn interactive plot of the cars data set:\n\nmpg %>% plotly::plot_ly(x = ~displ, y = ~mpg, color = ~class)\n\n\n\n\n\nNote: you can double click on the legend to see a subset of the data.\nAnother plot with ggplot2:\n\nplot <- ggplot2::ggplot(mpg, ggplot2::aes(x = displ, y = hwy)) + \n  ggplot2::geom_point(mapping = aes(color = class)) +\n  ggplot2::geom_smooth()\nplot\n\n\n\n\nUse ggplotly to make it interactive:\n\nplotly::ggplotly(plot)\n\n\n\n\n\n\n\n10. Art\n\nshades <- c(\"blue\", \"green\", \"red\", \"orange\")\ndata <- flametree::flametree_grow(time = 10, trees = 10)\ndata %>% flametree::flametree_plot(\n  background = \"white\",\n  palette = shades,\n  style = \"nativeflora\"\n)\n\n\n\n\nPackage by Danielle Navarro. Check out her art."
  },
  {
    "objectID": "01_blog/2022_02_28_RStudio-building-a-blog-with-R/index.html",
    "href": "01_blog/2022_02_28_RStudio-building-a-blog-with-R/index.html",
    "title": "RStudio: Building a Blog with R",
    "section": "",
    "text": "1. About Isabella Velesquez\nEmail: isabella.velasquez@rstudio.com\n\nWorks at Posit.\nSeattle Lady Co-Organizer.\nFirst R-Ladies talk in 2018.\n\n\n\n2. Agenda\n\nWhy create a blog?\nDeciding on a topic.\nTools for building a blog.\n\n\n\n3. Why create a blog?\n\nWhen youâ€™re given the same advice 3 times, write a blog post.\nShare what youâ€™ve learned.\nWrite your opinions.\nShare updates, and news.\nExternal blogs (for business)\n\nPosit has 4 different external blogs:\n\nThe Posit Blog\nPosit AI Blog\nTidyverse\nR Views\n\n\nInternal blogs (for business)\n\nShare information more easily and effectively.\nImprove collaboration.\nServing as a bulletin board for projects.\n\n\n\n\n4. Types of Posts\n\nStandard lists\nHow Toâ€™s / tutorials\nNew posts\nProblem - and - solution\nFAQ\nCheat sheets\nChecklists\nInfo graphics\nPresentations\nDebates\nInspiration\nInterviews\n\n\n\n5. Seperating Posts\n\nTutorials (learning oriented)\nHow Toâ€™s (task oriented)\nExplanation (understanding oriented)\nReference (information oriented)\n\n\n\n6. Building a Blog with R\n\nKnowledge of R and R Markdown.\nVersion Control (Github)\nNetlify\n\n\n\n7. Overall Thoughts\nWhile this was called â€œBuilding a blogâ€, there wasnâ€™t a lot of blog building. Similar to other RStudio presentations it was very business and product information heavy.\n\n\n8. Recommended Blog (from chat)\nMachine Learning Mastery"
  },
  {
    "objectID": "01_blog/2022_03_21_Midterm-Prep-Modern-College-Geometry/index.html",
    "href": "01_blog/2022_03_21_Midterm-Prep-Modern-College-Geometry/index.html",
    "title": "Midterm Prep. Modern College Geometry",
    "section": "",
    "text": "Notes consists of logic, Euclidâ€™s 5th, Congruence and Length Theorem, Congruence and Angle Theorem, angles and parallel lines, and triangle congruence theorems."
  },
  {
    "objectID": "01_blog/2022_03_21_Midterm-Prep-Modern-College-Geometry/index.html#example",
    "href": "01_blog/2022_03_21_Midterm-Prep-Modern-College-Geometry/index.html#example",
    "title": "Midterm Prep. Modern College Geometry",
    "section": "Example",
    "text": "Example\nConditional Statement: If it is cloudy then it is raining.\nNegation: It could be cloudy and not raining.\nInverse: If it is not cloudy then it is not raining.\nContrapositive: If it is not raining then it is not cloudy.\nConverse. If it is rainy, then it is cloudy."
  },
  {
    "objectID": "01_blog/2022_03_21_Midterm-Prep-Modern-College-Geometry/index.html#example-1",
    "href": "01_blog/2022_03_21_Midterm-Prep-Modern-College-Geometry/index.html#example-1",
    "title": "Midterm Prep. Modern College Geometry",
    "section": "Example",
    "text": "Example\nWhen proving supplementary angles add to \\(180^\\circ\\) we were able to use Euclids 5th element to say that the supplementary interior angles added up to \\(\\geq 180^\\circ\\) because the lines are parallel (and donâ€™t intersect)."
  },
  {
    "objectID": "01_blog/2022_03_21_Midterm-Prep-Modern-College-Geometry/index.html#proof-points",
    "href": "01_blog/2022_03_21_Midterm-Prep-Modern-College-Geometry/index.html#proof-points",
    "title": "Midterm Prep. Modern College Geometry",
    "section": "Proof Points",
    "text": "Proof Points\n\nâ€œBecause \\(\\triangle ABC\\cong \\triangle DEF\\) then there is an isometry f that superimposes angle ABC on angle DEF. Isometries preserve angle measure, so angles ABC and DEF must have had the same measure.â€\nâ€œSuppose angles ABC and DEF have the same measure.â€ Then explain isometry needed to move angle ABC to angle DEF. â€œTranslation, rotation, and reflection are all isometries, so weâ€™ve shown angles ABC and DEF are congruent.â€"
  },
  {
    "objectID": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html",
    "href": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html",
    "title": "Midterm Prep. Group Theory",
    "section": "",
    "text": "Notes consist of Sets, Subsets, Operations, Group, Abelian Group, Subgroups, and Homework 1 and 2 questions."
  },
  {
    "objectID": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#examples",
    "href": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#examples",
    "title": "Midterm Prep. Group Theory",
    "section": "Examples",
    "text": "Examples\n\n\\(\\mathbb{N}=\\{1,2,3,...\\}\\) : they exist naturally\n\\(\\mathbb{Z}=\\{...,-3,-2,-1,0,1,2,3,...\\}\\) : includes zero and negatives\n\\(\\mathbb{Q}=\\{\\frac{m}{n}|m,n\\in \\mathbb{Z}\\text{ and }n\\ne 0\\}\\) : integer fractions\n\\(\\mathbb{R}\\) : includes square roots and pie, real analysis starts with \\(\\sqrt{2}\\)\n\\(\\mathbb{C}\\) : includes imaginary numbers\nAsterisk in the superscript means delete zero\nPlus sign in the superscript means only positive values (>0)"
  },
  {
    "objectID": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#properties",
    "href": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#properties",
    "title": "Midterm Prep. Group Theory",
    "section": "Properties",
    "text": "Properties\n\n* is commutative if \\(a\\ne b\\), \\(a*b=b*a\\) \\(\\forall\\) a,b \\(\\in A\\).\n\n+ and \\(\\cdot\\) are commutative\n- , \\(\\div\\) , funtion composition and matrix multiplication are not commutative\n\n* is associative if \\((a*b)*c=a*(b*c)\\) \\(\\forall\\) a,b,c, \\(\\in A\\).\n\naddition is associative, subtraction is not associative\n\nIf \\(\\exists\\) \\(e\\in A\\) \\(\\Rightarrow\\) \\(e*a=a*e=a\\) \\(\\forall\\) \\(a\\in A\\), the we call e the identity element in A w.r.t. *.\n\n0=e w.r.t. addition\n1=e w.r.t. multiplication\n\nIf \\(e\\in A\\) is the identity w.r.t. * and \\(a,b\\in A\\Rightarrow\\) \\(a*b=b*a=e\\) we call a and b inverses of one another.\n\nthe inverse of \\(a\\in \\mathbb{R}\\) w.r.t. addition is -a since \\(a+(-a)=(-a)+a=0\\)\nthe inverse of \\(a\\in\\mathbb{R}^*\\) w.r.t. multiplication is \\(\\frac{1}{a}\\) since \\(a(\\frac{1}{a})=(\\frac{1}{a})a=1\\)"
  },
  {
    "objectID": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#proof-outlines",
    "href": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#proof-outlines",
    "title": "Midterm Prep. Group Theory",
    "section": "Proof Outlines",
    "text": "Proof Outlines\n\nCommutative:\n\\(\\underline{\\text{No}}\\): Give an example, â€œLet a = 1, and b =2â€, and then show \\(a*b\\ne b*a\\).\n\\(\\underline{\\text{Yes}}\\): â€œFor any a,b in the setâ€ and then show \\(a*b=b*a\\).\nAssociative\n\\(\\underline{\\text{No}}\\): Give an example, â€œLet a=1, b=2, c=3â€ and then show \\(a*(b*c)\\ne (a*b)*c\\).\n\\(\\underline{\\text{Yes}}\\): â€œFor any a,b,c in the setâ€ and then show \\(a*(b*c)=(a*b)*c\\).\nIdentity\n\\(\\underline{\\text{No}}\\): Suppose that \\(e\\in\\) the given set \\(\\Rightarrow\\) \\(a*e=a\\) \\(\\forall a\\in\\) the given set. Then show \\(a*e=a\\) by plugging e in for b and solving for e. â€œSince the identity element must be a constant then there is no identiy w.r.t.â€ the given set. (canâ€™t involve variables)\n\\(\\underline{\\text{Yes}}\\): State what the identity element is w.r.t. the orperation and show that \\(a*e=a\\) and \\(e*a=a\\).\nInverses\n\\(\\underline{\\text{No}}\\): Given an example of an element who doesnâ€™t have an inverse.\nNote: If there is not identity element then there is no inverse.\n\\(\\underline{\\text{Yes}}\\): â€œSuppose b=\\(a^{-1}\\). Then \\(a*b=e\\)â€ (where e is the identity found in 3), and then try to solve the eqation for b. Then check \\(b*a=e\\) as well.\nNote: Do not need to check \\(b*a=e\\) if we know * is commutative."
  },
  {
    "objectID": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#proposition-1",
    "href": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#proposition-1",
    "title": "Midterm Prep. Group Theory",
    "section": "Proposition 1",
    "text": "Proposition 1\nLet G be a group, then G has exactly one identity element."
  },
  {
    "objectID": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#proposition-2",
    "href": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#proposition-2",
    "title": "Midterm Prep. Group Theory",
    "section": "Proposition 2",
    "text": "Proposition 2\nEvery element of G has exactly one inverse."
  },
  {
    "objectID": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#theorem-1-cancellation-law",
    "href": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#theorem-1-cancellation-law",
    "title": "Midterm Prep. Group Theory",
    "section": "Theorem 1 (Cancellation Law)",
    "text": "Theorem 1 (Cancellation Law)\nLet G be a group and let \\(a,b,c\\in G\\), then \\(ab=ac\\Rightarrow b=c\\) and \\(ba=ca\\Rightarrow b=c\\)."
  },
  {
    "objectID": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#theorem-2",
    "href": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#theorem-2",
    "title": "Midterm Prep. Group Theory",
    "section": "Theorem 2",
    "text": "Theorem 2\nLet G be a group and let \\(a,b\\in G\\). If \\(ab=e\\), then a and b are inverses, i.e.Â \\(a=b^{-1}\\) and \\(b=a^{-1}\\)."
  },
  {
    "objectID": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#theorem-3",
    "href": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#theorem-3",
    "title": "Midterm Prep. Group Theory",
    "section": "Theorem 3",
    "text": "Theorem 3\nLet G be a group and let \\(a,b\\in G\\) then \\((ab)^{-1}=b^{-1}a^{-1}\\) and \\((a^{-1})^{-1}=a\\).\n\nto show a and b are inverses, show their product is e."
  },
  {
    "objectID": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#klein-4-group",
    "href": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#klein-4-group",
    "title": "Midterm Prep. Group Theory",
    "section": "Klein 4 Group",
    "text": "Klein 4 Group\n(for fintie groups) : \\(a^2=b^2=c^2=e\\)"
  },
  {
    "objectID": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#example",
    "href": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#example",
    "title": "Midterm Prep. Group Theory",
    "section": "Example",
    "text": "Example\nAddition:\n\n\\(0\\in H\\).\n\\(\\forall\\) a,b \\(\\in H\\) \\(a+b=H\\).\n\\(\\forall\\) \\(a\\in H\\) , \\(-a\\in H\\)."
  },
  {
    "objectID": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#proof-outlines-two-step-subgroup-test",
    "href": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#proof-outlines-two-step-subgroup-test",
    "title": "Midterm Prep. Group Theory",
    "section": "Proof Outlines (Two-Step Subgroup Test)",
    "text": "Proof Outlines (Two-Step Subgroup Test)\n\n\\(e\\in H\\)\nfor all a,b \\(\\in H\\), \\(ab^{-1}\\in H\\).\n\nProve something is a subgroup of G.\n\nâ€œSupposeâ€ then show e is 0 or 1 for the subgroup in a short series of equalities, â€œthe additive or multiplicative element 0 or 1 is inâ€ the subgroup.\nâ€œNow take any a,b \\(\\in\\) the subgroup.â€ Then define a and b potentially for some other integers. Then show \\(ab^{-1}=\\) something identifiable in the subgroup.\n\nâ€œTherefore weâ€™ve shown thatâ€ our subgroup â€œcontains the identity element and for all a,b \\(\\in H\\) , \\(ab^{-1}\\in\\)â€ our subgroup. Thus our subgroup is a subgroup of G."
  },
  {
    "objectID": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#example-1",
    "href": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#example-1",
    "title": "Midterm Prep. Group Theory",
    "section": "Example",
    "text": "Example\nAddition:\n\n\\(0\\in H\\).\nfor all \\(a,b\\in H\\), \\(a+(-b)=a-b\\in H\\)."
  },
  {
    "objectID": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#added-notes",
    "href": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#added-notes",
    "title": "Midterm Prep. Group Theory",
    "section": "Added Notes",
    "text": "Added Notes\n\nIf G is abelian, then \\((ab)^n=a^nb^n\\) for all \\(n\\in \\mathbb{N}\\).\nIn any group \\((a^{-1})^n=(a^n)^{-1}\\) for all \\(n\\in \\mathbb{N}\\).\nIn any group \\(e^{-1}=e\\)."
  },
  {
    "objectID": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#two-step-subgroup-test",
    "href": "01_blog/2022_03_28_Midterm-Prep-Group-Theory/index.html#two-step-subgroup-test",
    "title": "Midterm Prep. Group Theory",
    "section": "Two-step subgroup test",
    "text": "Two-step subgroup test\nLet G be a group. A subset H \\(\\subseteq G\\) is a subgroup of G if\n\n\\(e\\in H\\)\n\n\naddition: show 0 \\(\\in H\\)\n\n\n\\(\\forall a,b,\\in H\\), \\(ab^{-1}\\in H\\).\n\n\naddition: \\(\\forall\\) a,b \\(\\in H\\), \\(a+(-b)=a-b\\in H\\)"
  },
  {
    "objectID": "01_blog/2022_04_18_Tidy-Spice/index.html",
    "href": "01_blog/2022_04_18_Tidy-Spice/index.html",
    "title": "Tidy Spice",
    "section": "",
    "text": "This post is my reproduction of Julia Silgeâ€™s blogpost Topic Modeling for #TidyTuesday Spice Girls Lyrics, with some added inspiration from a blogpost by Ariane Aumaitre called Tutorial: Text analysis and data visualization with Taylor Swift songs."
  },
  {
    "objectID": "01_blog/2022_04_18_Tidy-Spice/index.html#gamma-matrix",
    "href": "01_blog/2022_04_18_Tidy-Spice/index.html#gamma-matrix",
    "title": "Tidy Spice",
    "section": "Gamma Matrix",
    "text": "Gamma Matrix\nGamma Matricies\n\nsong_topics <- tidytext::tidy(topic_model,\n                              matrix = \"gamma\",\n                              document_names = base::rownames(lyrics_sparse)\n)\nsong_topics\n\n# A tibble: 124 Ã— 3\n   document                   topic    gamma\n   <chr>                      <int>    <dbl>\n 1 2 Become 1                     1 0.932   \n 2 Denying                        1 0.00154 \n 3 Do It                          1 0.996   \n 4 Get Down With Me               1 0.300   \n 5 Goodbye                        1 0.000971\n 6 Holler                         1 0.00155 \n 7 If U Can't Dance               1 0.000896\n 8 If You Wanna Have Some Fun     1 0.0171  \n 9 Last Time Lover                1 0.140   \n10 Let Love Lead the Way          1 0.00178 \n# â€¦ with 114 more rows\n\n\n\nsong_topics %>%\n  dplyr::mutate(\n    song_name = fct_reorder(document, gamma),\n    topic = base::factor(topic)\n  ) %>%\n  ggplot2::ggplot(ggplot2::aes(gamma, topic, fill = topic)) +\n  ggplot2::geom_col(show.legend = FALSE) +\n  ggplot2::facet_wrap(vars(song_name), ncol = 4) +\n  ggplot2::scale_x_continuous(expand = c(0, 0)) +\n  ggplot2::labs(x = base::expression(gamma), y = \"Topic\")"
  },
  {
    "objectID": "01_blog/2022_04_25_PDX-R-Aggregate-Making-Tables-with-gt/index.html",
    "href": "01_blog/2022_04_25_PDX-R-Aggregate-Making-Tables-with-gt/index.html",
    "title": "Portland R User Group: Aggregate making tables with gt packag",
    "section": "",
    "text": "Ted Landeras led this event for Portland R user Group where we watched Rich Lannone|| Making Beautiful Tables with {gt}|| RStudio as a group on Youtube, and then went through some other examples."
  },
  {
    "objectID": "01_blog/2022_04_25_PDX-R-Aggregate-Making-Tables-with-gt/index.html#example-1",
    "href": "01_blog/2022_04_25_PDX-R-Aggregate-Making-Tables-with-gt/index.html#example-1",
    "title": "Portland R User Group: Aggregate making tables with gt packag",
    "section": "Example 1",
    "text": "Example 1\n\nhead(rock)\n\n  area    peri     shape perm\n1 4990 2791.90 0.0903296  6.3\n2 7002 3892.60 0.1486220  6.3\n3 7558 3930.66 0.1833120  6.3\n4 7352 3869.32 0.1170630  6.3\n5 7943 3948.54 0.1224170 17.1\n6 7979 4010.15 0.1670450 17.1\n\n\n\nrock %>% # Get 'rock' data\n  head(5) %>% # First 5 lines only\n  gt() # Make a table, it just works.\n\n\n\n\n\n  \n  \n    \n      area\n      peri\n      shape\n      perm\n    \n  \n  \n    4990\n2791.90\n0.0903296\n6.3\n    7002\n3892.60\n0.1486220\n6.3\n    7558\n3930.66\n0.1833120\n6.3\n    7352\n3869.32\n0.1170630\n6.3\n    7943\n3948.54\n0.1224170\n17.1"
  },
  {
    "objectID": "01_blog/2022_04_25_PDX-R-Aggregate-Making-Tables-with-gt/index.html#example-2",
    "href": "01_blog/2022_04_25_PDX-R-Aggregate-Making-Tables-with-gt/index.html#example-2",
    "title": "Portland R User Group: Aggregate making tables with gt packag",
    "section": "Example 2",
    "text": "Example 2\n\nhead(BOD)\n\n  Time demand\n1    1    8.3\n2    2   10.3\n3    3   19.0\n4    4   16.0\n5    5   15.6\n6    7   19.8\n\n\n\nBOD %>% # Get the data...\ngt() %>% # use 'gt' to make an awesome table...\n  tab_header( \n    title = \"BOD Table Woooooo!\", # ...with this title\n    subtitle = \"Hooray gt!\") %>% # and this subtitle\n  fmt_number( # A column (numeric data)\n    columns = vars(Time), # What column variable? BOD$Time\n    decimals = 2 # With two decimal places\n    ) %>% \n  fmt_number( # Another column (also numeric data)\n    columns = vars(demand), # What column variable? BOD$demand\n    decimals = 1 # I want this column to have one decimal place\n  ) %>% \n  cols_label(Time = \"Time (hours)\", demand = \"Demand (mg/L)\") # Update labels\n\n\n\n\n\n  \n    \n      BOD Table Woooooo!\n    \n    \n      Hooray gt!\n    \n  \n  \n    \n      Time (hours)\n      Demand (mg/L)\n    \n  \n  \n    1.00\n8.3\n    2.00\n10.3\n    3.00\n19.0\n    4.00\n16.0\n    5.00\n15.6\n    7.00\n19.8"
  },
  {
    "objectID": "01_blog/2022_04_25_PDX-R-Aggregate-Making-Tables-with-gt/index.html#example-3",
    "href": "01_blog/2022_04_25_PDX-R-Aggregate-Making-Tables-with-gt/index.html#example-3",
    "title": "Portland R User Group: Aggregate making tables with gt packag",
    "section": "Example 3",
    "text": "Example 3\n\nBOD %>% # Get the data...\ngt() %>% # use 'gt' to make an awesome table...\n  tab_header( \n    title = \"BOD Table Woooooo!\", # ...with this title\n    subtitle = \"Hooray gt!\") %>% # and this subtitle\n  fmt_number( # A column (numeric data)\n    columns = vars(Time), # What column variable? BOD$Time\n    decimals = 2 # With two decimal places\n    ) %>% \n  fmt_number( # Another column (also numeric data)\n    columns = vars(demand), # What column variable? BOD$demand\n    decimals = 1 # I want this column to have one decimal place\n  ) %>% \n  cols_label(Time = \"Time (hours)\", demand = \"Demand (mg/L)\") # Update labels\n\n\n\n\n\n  \n    \n      BOD Table Woooooo!\n    \n    \n      Hooray gt!\n    \n  \n  \n    \n      Time (hours)\n      Demand (mg/L)\n    \n  \n  \n    1.00\n8.3\n    2.00\n10.3\n    3.00\n19.0\n    4.00\n16.0\n    5.00\n15.6\n    7.00\n19.8"
  },
  {
    "objectID": "01_blog/2022_04_25_PDX-R-Aggregate-Making-Tables-with-gt/index.html#example-4",
    "href": "01_blog/2022_04_25_PDX-R-Aggregate-Making-Tables-with-gt/index.html#example-4",
    "title": "Portland R User Group: Aggregate making tables with gt packag",
    "section": "Example 4",
    "text": "Example 4\n\ntooth_length <- ToothGrowth %>% \n  group_by(supp, dose) %>% \n  summarize(\n    mean_len = mean(len)\n  ) %>% \n  as_tibble() \n\n# A gt table: \ntooth_length %>% # Take tooth_length\n  gt() %>% # Make a gt table with it\n  tab_header(\n    title = \"A title just like that\", # Add a title\n    subtitle = \"(with something below it!)\" # And a subtitle\n  ) %>%\n  fmt_passthrough( # Not sure about this but it works...\n    columns = vars(supp) # First column: supp (character)\n  ) %>% \n  fmt_number(\n    columns = vars(mean_len), # Second column: mean_len (numeric)\n    decimals = 2 # With 4 decimal places\n  ) %>% \n  fmt_number(\n    columns = vars(dose), # Third column: dose (numeric)\n    decimals = 2 # With 2 decimal places\n  ) %>% \n  data_color( # Update cell colors...\n    columns = vars(supp), # ...for supp column!\n    colors = scales::col_factor( # <- bc it's a factor\n      palette = c(\n        \"green\",\"cyan\"), # Two factor levels, two colors\n      domain = c(\"OJ\",\"VC\")# Levels\n  )\n  ) %>% \n  data_color( # Update cell colors...\n    columns = vars(dose), # ...for dose column \n    colors = scales::col_numeric( # <- bc it's numeric\n      palette = c(\n        \"yellow\",\"orange\"), # A color scheme (gradient)\n      domain = c(0.5,2) # Column scale endpoints\n  )\n  ) %>% \n  data_color( # Update cell colors...\n    columns = vars(mean_len), # ...for mean_len column\n    colors = scales::col_numeric(\n      palette = c(\n        \"red\", \"purple\"), # Overboard colors! \n      domain = c(7,27) # Column scale endpoints\n  )\n  ) %>% \n  cols_label(supp = \"Supplement\", dose = \"Dosage (mg/d)\", mean_len = \"Mean Tooth Length\") %>% # Make the column headers\n  tab_footnote(\n    footnote = \"Baby footnote test\", # This is the footnote text\n    locations = cells_column_labels(\n      columns = vars(supp) # Associated with column 'supp'\n      )\n    ) %>% \n    tab_footnote(\n    footnote = \"A second footnote\", # Another line of footnote text\n    locations = cells_column_labels( \n      columns = vars(dose) # Associated with column 'dose'\n      )\n    )\n\n\n\n\n\n  \n    \n      A title just like that\n    \n    \n      (with something below it!)\n    \n  \n  \n    \n      Supplement1\n      Dosage (mg/d)2\n      Mean Tooth Length\n    \n  \n  \n    OJ\n0.50\n13.23\n    OJ\n1.00\n22.70\n    OJ\n2.00\n26.06\n    VC\n0.50\n7.98\n    VC\n1.00\n16.77\n    VC\n2.00\n26.14\n  \n  \n  \n    \n      1 Baby footnote test\n    \n    \n      2 A second footnote"
  },
  {
    "objectID": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html",
    "href": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html",
    "title": "Final Prep. Group Theory",
    "section": "",
    "text": "Notes consist of order, cyclic groups, counting cosets, homomorphisms, normal subgroups, quotient groups, and the Fundamental Homomorphism Theorem."
  },
  {
    "objectID": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html#theorems",
    "href": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html#theorems",
    "title": "Final Prep. Group Theory",
    "section": "Theorems",
    "text": "Theorems\nTheorem 3: Let G be a group and let \\(a\\in G\\) have order \\(n<\\infty\\). Then every power of a is equal to exactly one \\(e,a,a^2,a^3,...,a^{n-1}\\)\nCorollary: Let ord(a)=\\(n<\\infty\\). Then the cyclic group generated by a has n elements. \\(\\langle a\\rangle=\\{...,a^{-2},a^{-1},e,a,a^2,a^3\\}=\\{e,a,a^2,...,a^{n-1}\\}\\).\nTheorem 4: Let ord(a)=\\(\\infty\\). Then for all \\(i,j\\in\\mathbb{Z}\\), if \\(i\\in j\\) then \\(a^i\\ne a^j\\).\n(No power of a gives the identity, and no power of a is the same.)\nCorollary: If ord(a)=\\(\\infty\\), the cyclic group generated by a has infintely many elements: \\(\\langle a\\rangle =\\{...,a^{-2},a^{-1},e,a,a^{2},...\\}\\)\nTheorem 5: Let \\(a\\in G\\) have order \\(n<\\infty\\). Then \\(a^m=e\\) if and only if m is a multiple of n."
  },
  {
    "objectID": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html#facts-about-cyclic-groups",
    "href": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html#facts-about-cyclic-groups",
    "title": "Final Prep. Group Theory",
    "section": "Facts about Cyclic Groups",
    "text": "Facts about Cyclic Groups\nLet \\(G=\\langle a\\rangle=\\{e,a,a^2,a^3,...,a^{n-1}\\}\\) be a cyclic group of size n.Â \n\nG is abelian (Since \\(a^ia^j=a^{i+j}=a^{j}a^{i}\\))\nLet \\(k\\geq 1\\) be a positive divisor of \\(|G|=n\\). Then G has exactly one subgroup of size k.\nThe subgroup of G of size 1 is \\(\\langle e\\rangle =\\{e\\}\\). If \\(k>1\\) is a divisor of n, the subgorup of size k is \\(\\langle a^{n/k}\\rangle\\)"
  },
  {
    "objectID": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html#definitions",
    "href": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html#definitions",
    "title": "Final Prep. Group Theory",
    "section": "Definitions",
    "text": "Definitions\ncoset: Let G be a group and H a subgroup of G. For any \\(a\\in G\\), the set \\(Ha=\\{ha|h\\in H\\}.\\) This is a (right) \\(\\underline{\\text{coset}}\\) of H in G.\nindex: The number of cosets of H in G, n, is called the \\(\\underline{\\text{index}}\\) of H in G."
  },
  {
    "objectID": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html#facts-about-cosets",
    "href": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html#facts-about-cosets",
    "title": "Final Prep. Group Theory",
    "section": "Facts about Cosets",
    "text": "Facts about Cosets\n\nAll cosets have the same size as H.\nDistinct cosets donâ€™t overlap.\nEvery element of G is in some coset of H.\nHow should we choose a so that we donâ€™t get repeated cosets? Choose a to be an element of G that hasnâ€™t yet appeared in a coset.\nHow do we know when weâ€™ve listed all cosets? Weâ€™re done when every element of G has appeared in a coset."
  },
  {
    "objectID": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html#theorems-1",
    "href": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html#theorems-1",
    "title": "Final Prep. Group Theory",
    "section": "Theorems",
    "text": "Theorems\nLemma: Distinct cosets donâ€™t overlap.\nCorollary: If \\(a\\in Hb\\) then \\(Ha=Hb\\).\nTheorem 1: The set \\(\\{Ha|a\\in G\\}\\) of all cosets of H is a partiion of G.\nCorollary: Define a relation \\(\\sim\\) on G by \\(a\\sim b\\) iff a and b are in the same coset of H.\nTheorem 2: Every coset of H in G has the same size as H.\nLagrangeâ€™s Theorem: Let G be a finite group and H be a subgroup of G. Then the size of H divides the size of G.\nTheorem 4: Let \\(p\\in\\mathbb{Z}\\) be prime. If \\(|G|=p\\), then \\(G\\cong\\mathbb{Z}_p\\).\nTheorem 5: Let G be a finite group and \\(a\\in G\\). Then ord(a) divides \\(|G|\\)."
  },
  {
    "objectID": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html#definitions-1",
    "href": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html#definitions-1",
    "title": "Final Prep. Group Theory",
    "section": "Definitions",
    "text": "Definitions\nHomomorphism: Let \\(G_1\\) and \\(G_2\\) be groups. A \\(\\underline{\\text{homomorphism}}\\) is a function \\(f:G_1\\rightarrow G_2\\) such that for all \\(a,b\\in G_1\\), \\(f(ab)=f(a)f(b)\\).\nHomomorphic Image: If \\(f:G_1\\rightarrow G_2\\) is an onto homomorphism, we call \\(G_2\\) a \\(\\underline{\\text{homomorphic image}}\\) of \\(G_1\\).\nKernel: Let \\(f:G_1\\rightarrow G_2\\) be a homomorphism. The \\(\\underline{\\text{kernel}}\\) of f is the set of all elements in \\(G_1\\) that get sent to \\(e_2\\in G_2\\): \\(\\text{ker}(f)=\\{x\\in G_1|f(x)=e_2\\}.\\)\nConjugate: Let G be a group and \\(g_1x\\in G\\). The element \\(gxg^{-1}\\) is called the \\(\\underline{\\text{conjugate}}\\) of x by g. Going from x to \\(gxg^{-1}\\) is called \\(\\underline{\\text{conjugation by g}}\\).\nNormal: Let H be a subgroup of G. We call H a \\(\\underline{\\text{normal}}\\) subgroup of G if for all \\(g\\in G\\) and \\(h\\in H\\), the conjugate \\(ghg^{-1}\\) is in H. Notation: \\(H \\unlhd G\\)\nNormal Subgroup: A subgroup H of G is called a \\(\\underline{\\text{normal subgroup}}\\) if for all \\(g\\in G\\) and \\(h\\in H\\). \\(ghg^{-1}\\in H\\)."
  },
  {
    "objectID": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html#theorems-2",
    "href": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html#theorems-2",
    "title": "Final Prep. Group Theory",
    "section": "Theorems",
    "text": "Theorems\nTheorem 1: Let \\(f:G_1\\rightarrow G_2\\) be a homomorphism. Then\n\n\\(f(e_1)=e_2\\)\n\\(f(a^{-1})=[f(a)]^{-1}\\forall a\\in G_1\\)\n\nTheorem: Let \\(f:G_1\\rightarrow G_2\\) be a homomorphism. Then f is one-to-one if and only if ker(f)=\\(\\{e_1\\}\\).\nTheorem: If G is abelian, every subgroup of G is normal.\nTheorem: Let H be a subgroup of G. Then H is normal in G if and only if \\(aH=Ha\\) for all \\(a\\in G\\).\nTheorem: A subgroup H of G is normal in G iff \\(aH=Ha\\forall a\\in G\\).\nTheorem 2: Let \\(f:G_1\\rightarrow G_2\\) be a homomorphism.\n\nran(f)=\\(\\{f(x)|x\\in G_1\\}\\) is a subgroup of \\(G_2\\)\nker(f) is a normal subgroup of \\(G_1\\)."
  },
  {
    "objectID": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html#theorems-3",
    "href": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html#theorems-3",
    "title": "Final Prep. Group Theory",
    "section": "Theorems",
    "text": "Theorems\nTheorem 2: Let H be a normal subgroup of G. If \\(Ha=Hc\\) and \\(Hb=Hd\\), then \\(H(ab)=H(cd)\\).\nTheorem 3: Let H be a normal subgroup of G. The set \\(G/H=\\{Ha|a\\in G\\}\\)\nTheorem 4: Let H be a normal subgroup of G. The function \\(f:G\\rightarrow G/H\\) define by \\[f(a)=Ha\\] is a surjective homomorphsim with kernel H.\nTheorem 5: Let H be a subgroup of G.\n\n\\(Ha=Hb\\) if and only if \\(ab^{-1}\\in H\\).\n\\(Ha=H\\) if and only if \\(a\\in H\\)."
  },
  {
    "objectID": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html#theorems-4",
    "href": "01_blog/2022_05_23_Final-Prep-Group-Theory/index.html#theorems-4",
    "title": "Final Prep. Group Theory",
    "section": "Theorems",
    "text": "Theorems\nTheorem 1: Let \\(f:G\\rightarrow H\\) be a homomorphism with kernel K. Then \\(f(a)=f(b) \\Leftrightarrow Ka=Kb\\).\nTheorem 2: Let \\(f:G\\rightarrow H\\) be a surjective (onto) homomorphism with kernel K. Then \\(G/K\\cong H\\)."
  },
  {
    "objectID": "01_blog/2022_05_30_Final-Prep-Geometry/index.html",
    "href": "01_blog/2022_05_30_Final-Prep-Geometry/index.html",
    "title": "Final Prep. Modern College Geometry",
    "section": "",
    "text": "1. Euclidean Geometry\n\nEuclidâ€™s 5th Axiom\nTriangle Congruence: SAS, ASA, SSS, AAS\nAngles and Parallel Lines\n\nvertical angels are congruent\ncorresponding angles are congruent\nalternate interior angles are congruent\nsupplementary angles add to \\(180^\\circ\\)\n\n\nQuadrilaterals: 4 sided figure in the plane, where the edges are straight lines.\nParallelogram: Both pairs of opposite sides are parallel.\nTrapezoid: At least 1 pair of opposite sides are parallel.\nRhombus: Parallelogram, all sides are same length.\nRectangle: Parallelogram whose internal angles are all right angles.\nSquare: Rectangle whose sides are all equal length.\nParallelogram Theorem: Let ABCD be a parallelogram. Then the following are equivalent:\n\nABCD is a parallelogram. (opposite sides are parallel)\n\\(\\angle DAB \\cong \\angle BCD\\) and \\(\\angle ABC\\cong \\angle CDA\\) (angles that are across from each other are congruent)\n\\(AB=CD\\) and \\(BC=DA\\) (opposite sides have equal measure)\n\\(\\overline{AC}\\) and \\(\\overline{BD}\\) bisect each other. (diagnals bisect each other)\n\nAxioms of Area:\n\nTo every polygonal region (space enclosed by straight lines in the plane) there corresponds a unique positive number called \\(\\underline{area}\\).\nIf 2 tirangles are congruent their areas are equal.\nIf \\(R=R_1\\cup R_2\\) and \\(R_1\\cap R_2\\) is a finite number of segments or points, then the area of \\(R\\) is the sum of the areas of \\(R_1+R_2\\).\nThe area of a rectangle is its base times its height.\n\n\n\n2. Similarity\nDilation: shrink or expand by a scaling factor, k, from a center point, P.\nSimilarity: 2 figures are similar if one can be superimposed on the other by a dilation and a sequence of isometries.\n\nAA, SAS\n\n\n\n3. Circles\nCircle: center, radius\nPoints on circle have distance r from the center point O.\nUnit Circle: radius length 1.\nArc: a connected subset of the points on circle.\nChord: line segment connecting 2 points on circle.\nCentral Angle: vertex is center of circle, rays intersect in 2 different points. (pie slice)\nInscribed Angles vertex is on circle, rays intersect circle in 2 points.\nInscribed: verities on circle.\nFor an inscribed square, all four points of a square are on the circle.\nTangent Line: Line that intersects circle at only 1 point.\nRadian: measure of the central angle in a unit circle with arc length of 1.\nInscribed Angle Theorem: An inscribed angle is half of a centeral angle that subtends the same arc.\nCorollary: Any two inscribed angles have the same arc on the circle are congruent.\nPower of the Point Theorem 1: If \\(\\overline{AB}\\) and \\(\\overline{CD}\\) are chords of circle intersecting in x inside a circle. Then \\(Ax\\cdot xB=Cx\\cdot xD\\)\nPower of the Point Theorem 2: LEt P be a point outside a given circle. Suppose we draw two rays from the point P: one ray intersects the circle at points A and B (in that order), and the other intersects the circle at the points C and D (in that order). Then \\(PA\\cdot PB=PC\\cdot PD\\)\n\n\n4. Isometries and Symmetries\nThe set of isometries with composition is a group:\n\nClosure\nAssociativity\nIdentity\nInverses\n\nSymmetry A symmetry is an isometry that sends a geometric figure to itself.\n\n6 symmetries of an equilateral triangle\n8 symmetries of a square\n2n symmetries of a regular polygon\n\n\n\n5. Taxicab Geometry\nEuclidean Distance: \\(d_E(A,B)=\\sqrt{(x_B-x_A)^2+(y_B-y_A)^2}\\)\n\n\\(\\pi\\approx 3.14\\)\n\nTaxicab Distance: \\(d_T=|x_B-x_A|+|y_B-y_A|\\)\n\n\\(\\pi = 4\\)\n\nIsometries for taxicab (traingles):\n\ntranslations\nrotations by \\(90^\\circ k\\) where k is an integer\ncombinations\n\n\n\n6. Spherical Geometry\nNo parallel may be drawn through a point not on a given line.\nEquation of a Sphere: \\(S^2=\\{(x,y,z)\\in\\mathbb{R}^3|x^2+y^2+z^2=\\rho^2\\}\\)\n\ngreat circles are straight lines (equator and longitudes)\n\nDistance of a Sphere: \\(d_s(A,B)=\\rho\\cdot\\text{arc cos}(\\frac{A\\cdot B}{\\rho ^2})\\)\nTriangle Angle Measurements\n\nCan have three right angles\nAll three angles added together will be greater than \\(180^\\circ\\)\n\nArea of a Sphere: \\(\\rho^2\\cdot E\\) (where the excess \\(E=\\alpha+\\beta+\\gamma-180^\\circ\\))\nConsider the surface area of a sphere to be \\(4\\pi\\rho^2\\), then the area of a triangle on a sphere will be a proportion of that.\n\n\n7. Hyperbolic Geometry\nMore than one parallel may be drawn through a point not on a given line.\nInversions about a circle\n\npreserve angles (conformal)\n\nCross Ratio: Given four distinct points (A,B,C,D) in the plane, the cross ratio is define \\((A,B;C,D)=\\frac{AC\\cdot BD}{BC\\cdot AD}\\)"
  },
  {
    "objectID": "01_blog/2022_12_12_Data-Science-Interview-Questions-P1/index.html",
    "href": "01_blog/2022_12_12_Data-Science-Interview-Questions-P1/index.html",
    "title": "Data Science Interview Questions - Part 1",
    "section": "",
    "text": "1. What is the difference between supervised and unsupervised learning?\nSupervised Learning: Uses labeled data for prediction. (Logistical Regression, Linear Regression, Decision Tree)\nUnsupervised Learning: Uses unlabeled data for analysis such as identifying hidden patterns in clustering, association, and anomalies or errors. (K-means clustering, hierarchical clustering)\n\n\n2. What is the difference between univariate, bivariate, and multivariate analysis?\nUnivariate: Looks at only one variable at a time.\nBivariate: Compares two variables.\nMultivariate: Compares more than two variables.\n\n\n3. What is the difference between wide format data and long format data?\nWide Format Data: Has a column for each variable.\nLong Format Data: Has a column for possible variable types, and a value for each of those variables.\n\n\n4. What is the difference between normalization and stadardization?\nNormalization: Rescales the values into a range of [0,1].\nStandardization: Rescales data to have a mean of 0 and a standard deviation of 1.\n\n\n5. What is variance?\nVariance: \\(s^2=\\frac{\\sum(x_i-\\bar{x})}{n-1}\\) is a measure of spread within the data.\n\n\n6. What is a normal distribution?\nNormal distribution: (Gaussian distribution or bell curve) is a probability distribution that is symmetrical about the mean.\n\n\n7. What is the law of large numbers?\nLaw of Large Numbers: if an experiment is repeated independently a large number of times then the average results of the obtained results should be close to the expected value.\n\n\n8. What is the goal of A/B testing?\nTo determine which experiment A or B preformed better.\n\n\n9. You are given a dataset consisting of variables with more than 30 percent missing values. How do you deal with them?\n\nDelete rows or columns with missing values. This can be problematic if it means loosing valuable data.\nFill in the missing values with an approximation of the average of the other values in the column.\n\n\n\n10. For the given points how do you calculate the Euclidean distance in Python?\npoint 1 = (2,3) and point 2 = (1,1)\n\nimport numpy as np\n \n# initializing points in numpy arrays\npoint1 = np.array((1, 2, 3))\npoint2 = np.array((1, 1, 1))\n \n# calculating Euclidean distance using linalg.norm()\ndist = np.linalg.norm(point1 - point2)\n \n# printing Euclidean distance\nprint(dist)\n\n2.23606797749979\n\n\nNote: Check out the distance package I created to solve this same problem using R.\n\n\n11. How do you find RMSE and MSE in a linear regression model?\nRoot Mean Square Error (RMSE): \\(\\text{RMSE}=\\sqrt{\\text{MSE}}=\\sqrt\\frac{\\sum{(y_i-\\hat{y_i})^2}}{n}\\)\nMean Square Error (MSE): \\(\\text{MSE}=\\frac{\\sum{(\\text{observed}-\\text{predicted})^2}}{n}=\\frac{\\sum{(y_i-\\hat{y_i})^2}}{n}\\)\nNote: The values are squared is to prevent negative values, and to increase the impact of of larger errors.\n\n\n12. What is the significance of p-value?\nThe p value is the probability that the null hypothesis is true. Meaning there is no statistical significance that exists between variables.\nWhen p is \\(\\leq\\) 0.05 then we can reject the null hypothesis.\nWhen p is > 0.05 then we fail to reject the null hypothesis aka accept it."
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html",
    "href": "01_blog/2022_12_05_python-beg/index.html",
    "title": "Python Basics",
    "section": "",
    "text": "This post covers topics from Lillian Piersonâ€™s Linkedin Learning course Python for Data Sciene Training Part 1. Topics include Series, Data Frames, Data Visuals, Math and Statistics."
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#extracting",
    "href": "01_blog/2022_12_05_python-beg/index.html#extracting",
    "title": "Python Basics",
    "section": "1.1 Extracting",
    "text": "1.1 Extracting\n\n1.1.1 Select row 7\n\nseries_obj['row 7']\n\n6\n\n\n\n\n1.1.2 Select Elements at Position 0 and 7\n\nseries_obj[[0,7]]\n\nrow 1    0\nrow 8    7\ndtype: int64"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#slicing",
    "href": "01_blog/2022_12_05_python-beg/index.html#slicing",
    "title": "Python Basics",
    "section": "1.2 Slicing",
    "text": "1.2 Slicing\nSelect every row between 3 and 7.\n\nseries_obj['row 3':'row 7']\n\nrow 3    2\nrow 4    3\nrow 5    4\nrow 6    5\nrow 7    6\ndtype: int64"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#scalars",
    "href": "01_blog/2022_12_05_python-beg/index.html#scalars",
    "title": "Python Basics",
    "section": "1.3 Scalars",
    "text": "1.3 Scalars\n\n1.3.1 Print values greater than 5.\n\nseries_obj[series_obj>5]\n\nrow 7    6\nrow 8    7\ndtype: int64\n\n\n\n\n1.3.2 Set row 1 to the value 8.\n\nseries_obj['row 1'] = 8\nseries_obj\n\nrow 1    8\nrow 2    1\nrow 3    2\nrow 4    3\nrow 5    4\nrow 6    5\nrow 7    6\nrow 8    7\ndtype: int64"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#missing-values",
    "href": "01_blog/2022_12_05_python-beg/index.html#missing-values",
    "title": "Python Basics",
    "section": "1.4 Missing Values",
    "text": "1.4 Missing Values\n\n1.4.1 Create a variable of missing values using np.nan\n\nnp.nan: numpy function, not a number (nan)\n\n\nmissing = np.nan\nmissing\n\nnan\n\n\n\n\n1.4.2 Create a new series object with missing values for row 3 and 7.\n\nseries_obj2 = Series(['row 1', 'row 2', missing , 'row 5', 'row 6', missing, 'row 8'])\nseries_obj2\n\n0    row 1\n1    row 2\n2      NaN\n3    row 5\n4    row 6\n5      NaN\n6    row 8\ndtype: object\n\n\n\n\n1.4.3 Find what values are missing using .isnull()\n\nisnull(): pandas function that returns t/f if null\n\n\nseries_obj2.isnull()\n\n0    False\n1    False\n2     True\n3    False\n4    False\n5     True\n6    False\ndtype: bool"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#rename-data",
    "href": "01_blog/2022_12_05_python-beg/index.html#rename-data",
    "title": "Python Basics",
    "section": "1.5 Rename Data",
    "text": "1.5 Rename Data\n\n1.5.1 Name series object.\n\nseries_obj.name =\"added_variable\"\nseries_obj\n\nrow 1    8\nrow 2    1\nrow 3    2\nrow 4    3\nrow 5    4\nrow 6    5\nrow 7    6\nrow 8    7\nName: added_variable, dtype: int64"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#extracting-1",
    "href": "01_blog/2022_12_05_python-beg/index.html#extracting-1",
    "title": "Python Basics",
    "section": "2.1 Extracting",
    "text": "2.1 Extracting\n\n2.1.1 Select values from row 2, row 5, column 5, and column 2.\n\nDF_obj.loc[['row 2', 'row 5'], ['column 5', 'column 2']]\n\n\n\n\n\n  \n    \n      \n      column 5\n      column 2\n    \n  \n  \n    \n      row 2\n      0.402366\n      0.437611\n    \n    \n      row 5\n      0.421004\n      0.559053"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#scalars-1",
    "href": "01_blog/2022_12_05_python-beg/index.html#scalars-1",
    "title": "Python Basics",
    "section": "2.2 Scalars",
    "text": "2.2 Scalars\n\n2.2.1 Return a true or false for all values less than .2\n\nDF_obj < .2\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n      column 4\n      column 5\n      column 6\n    \n  \n  \n    \n      row 1\n      False\n      False\n      False\n      True\n      False\n      True\n    \n    \n      row 2\n      False\n      False\n      False\n      False\n      False\n      True\n    \n    \n      row 3\n      False\n      False\n      True\n      False\n      False\n      False\n    \n    \n      row 4\n      False\n      False\n      False\n      False\n      False\n      False\n    \n    \n      row 5\n      False\n      False\n      True\n      False\n      False\n      False\n    \n    \n      row 6\n      False\n      False\n      False\n      False\n      False\n      False"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#missing-values-1",
    "href": "01_blog/2022_12_05_python-beg/index.html#missing-values-1",
    "title": "Python Basics",
    "section": "2.3 Missing Values",
    "text": "2.3 Missing Values\n\n2.3.1 Set the values in rows 4-5 of column 1, and rows 2-4 of column 6 to missing.\n\niloc: python function used to select a particular cell of the dataset.\n\n\nDF_obj.iloc[3:5, 0] = missing\nDF_obj.iloc[1:4, 5] = missing\nDF_obj\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n      column 4\n      column 5\n      column 6\n    \n  \n  \n    \n      row 1\n      0.870124\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n      0.117376\n    \n    \n      row 2\n      0.684969\n      0.437611\n      0.556229\n      0.367080\n      0.402366\n      NaN\n    \n    \n      row 3\n      0.447031\n      0.585445\n      0.161985\n      0.520719\n      0.326051\n      NaN\n    \n    \n      row 4\n      NaN\n      0.836375\n      0.481343\n      0.516502\n      0.383048\n      NaN\n    \n    \n      row 5\n      NaN\n      0.559053\n      0.034450\n      0.719930\n      0.421004\n      0.436935\n    \n    \n      row 6\n      0.281701\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n      0.525819\n    \n  \n\n\n\n\n\n\n2.3.2 Replace non values with 0.\n\nfillna: pandas function used to replace missing values.\n\n\n# fill NaN values with 0\nfilled_DF = DF_obj.fillna(0)\nfilled_DF\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n      column 4\n      column 5\n      column 6\n    \n  \n  \n    \n      row 1\n      0.870124\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n      0.117376\n    \n    \n      row 2\n      0.684969\n      0.437611\n      0.556229\n      0.367080\n      0.402366\n      0.000000\n    \n    \n      row 3\n      0.447031\n      0.585445\n      0.161985\n      0.520719\n      0.326051\n      0.000000\n    \n    \n      row 4\n      0.000000\n      0.836375\n      0.481343\n      0.516502\n      0.383048\n      0.000000\n    \n    \n      row 5\n      0.000000\n      0.559053\n      0.034450\n      0.719930\n      0.421004\n      0.436935\n    \n    \n      row 6\n      0.281701\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n      0.525819\n    \n  \n\n\n\n\n\n\n2.3.3 Count the number of missing values in each column.\n\nDF_obj.isnull().sum()\n\ncolumn 1    2\ncolumn 2    0\ncolumn 3    0\ncolumn 4    0\ncolumn 5    0\ncolumn 6    3\ndtype: int64\n\n\n\n\n2.3.4 Filter out rows with missing values.\n\ndropna(): pandas function that removes rows with missing values.\n\n\nDF_no_NaN_rows = DF_obj.dropna()\nDF_no_NaN_rows\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n      column 4\n      column 5\n      column 6\n    \n  \n  \n    \n      row 1\n      0.870124\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n      0.117376\n    \n    \n      row 6\n      0.281701\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n      0.525819\n    \n  \n\n\n\n\n\n\n2.3.5 Filter out columns with missing values.\n\nDF_no_NaN_columns = DF_obj.dropna(axis=1)\nDF_no_NaN_columns\n\n\n\n\n\n  \n    \n      \n      column 2\n      column 3\n      column 4\n      column 5\n    \n  \n  \n    \n      row 1\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n    \n    \n      row 2\n      0.437611\n      0.556229\n      0.367080\n      0.402366\n    \n    \n      row 3\n      0.585445\n      0.161985\n      0.520719\n      0.326051\n    \n    \n      row 4\n      0.836375\n      0.481343\n      0.516502\n      0.383048\n    \n    \n      row 5\n      0.559053\n      0.034450\n      0.719930\n      0.421004\n    \n    \n      row 6\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n    \n  \n\n\n\n\n\n\n2.3.6 Fill the missing values with the method ffill.\n\nffill: pandas function fill forward which fills in the lass non-null value in DF.\n\n\nfill_DF = DF_obj.fillna(method='ffill')\nfill_DF\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n      column 4\n      column 5\n      column 6\n    \n  \n  \n    \n      row 1\n      0.870124\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n      0.117376\n    \n    \n      row 2\n      0.684969\n      0.437611\n      0.556229\n      0.367080\n      0.402366\n      0.117376\n    \n    \n      row 3\n      0.447031\n      0.585445\n      0.161985\n      0.520719\n      0.326051\n      0.117376\n    \n    \n      row 4\n      0.447031\n      0.836375\n      0.481343\n      0.516502\n      0.383048\n      0.117376\n    \n    \n      row 5\n      0.447031\n      0.559053\n      0.034450\n      0.719930\n      0.421004\n      0.436935\n    \n    \n      row 6\n      0.281701\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n      0.525819"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#duplicates",
    "href": "01_blog/2022_12_05_python-beg/index.html#duplicates",
    "title": "Python Basics",
    "section": "2.4 Duplicates",
    "text": "2.4 Duplicates\n\n2.4.1 Create a new data frame object.\n\nDF_obj2 = DataFrame({'column 1':[1,1,2,2,3,3,3],\n                   'column 2' :['a', 'a', 'b', 'b', 'c','c','c'],\n                   'column 3': ['A','A','B','B','C','C','C']})\nDF_obj2\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n    \n  \n  \n    \n      0\n      1\n      a\n      A\n    \n    \n      1\n      1\n      a\n      A\n    \n    \n      2\n      2\n      b\n      B\n    \n    \n      3\n      2\n      b\n      B\n    \n    \n      4\n      3\n      c\n      C\n    \n    \n      5\n      3\n      c\n      C\n    \n    \n      6\n      3\n      c\n      C\n    \n  \n\n\n\n\n\n\n2.4.2 Show which rows have duplicates.\n\nduplicated(): pandas function that returns t/f for rows with duplicate values.\n\n\nDF_obj2.duplicated()\n\n0    False\n1     True\n2    False\n3     True\n4    False\n5     True\n6     True\ndtype: bool\n\n\n\n\n2.4.3 Drop duplicates rows.\n\ndrop_duplicates()\n\n\nDF_obj2_row_drop  = DF_obj2.drop_duplicates()\nDF_obj2_row_drop\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n    \n  \n  \n    \n      0\n      1\n      a\n      A\n    \n    \n      2\n      2\n      b\n      B\n    \n    \n      4\n      3\n      c\n      C\n    \n  \n\n\n\n\n\n\n2.4.4 Drop duplicate from column 3.\n\nDF_obj2_c3_drop = DF_obj2.drop_duplicates(['column 3'])\nDF_obj2_c3_drop\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n    \n  \n  \n    \n      0\n      1\n      a\n      A\n    \n    \n      2\n      2\n      b\n      B\n    \n    \n      4\n      3\n      c\n      C"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#adding-data",
    "href": "01_blog/2022_12_05_python-beg/index.html#adding-data",
    "title": "Python Basics",
    "section": "2.5 Adding data",
    "text": "2.5 Adding data\n\n2.5.1 Slice the first 6 rows of series object.\n\nnew_series_obj = series_obj['row 0':'row 6']\nnew_series_obj\n\nrow 1    8\nrow 2    1\nrow 3    2\nrow 4    3\nrow 5    4\nrow 6    5\nName: added_variable, dtype: int64\n\n\n\n\n2.5.2 Add new_series_obj to the end of DF_obj\n\nvariable_added = DataFrame.join(DF_obj, series_obj)\nvariable_added\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n      column 4\n      column 5\n      column 6\n      added_variable\n    \n  \n  \n    \n      row 1\n      0.870124\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n      0.117376\n      8\n    \n    \n      row 2\n      0.684969\n      0.437611\n      0.556229\n      0.367080\n      0.402366\n      NaN\n      1\n    \n    \n      row 3\n      0.447031\n      0.585445\n      0.161985\n      0.520719\n      0.326051\n      NaN\n      2\n    \n    \n      row 4\n      NaN\n      0.836375\n      0.481343\n      0.516502\n      0.383048\n      NaN\n      3\n    \n    \n      row 5\n      NaN\n      0.559053\n      0.034450\n      0.719930\n      0.421004\n      0.436935\n      4\n    \n    \n      row 6\n      0.281701\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n      0.525819\n      5\n    \n  \n\n\n\n\n\n\n2.5.3 Use append to add data table to itself retaining index values.\n\nadded_datatable = variable_added.append(variable_added, ignore_index=False)\nadded_datatable\n\n/var/folders/90/4rtssdj16dl23f_f66qj0t3w0000gn/T/ipykernel_22703/426574045.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  added_datatable = variable_added.append(variable_added, ignore_index=False)\n\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n      column 4\n      column 5\n      column 6\n      added_variable\n    \n  \n  \n    \n      row 1\n      0.870124\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n      0.117376\n      8\n    \n    \n      row 2\n      0.684969\n      0.437611\n      0.556229\n      0.367080\n      0.402366\n      NaN\n      1\n    \n    \n      row 3\n      0.447031\n      0.585445\n      0.161985\n      0.520719\n      0.326051\n      NaN\n      2\n    \n    \n      row 4\n      NaN\n      0.836375\n      0.481343\n      0.516502\n      0.383048\n      NaN\n      3\n    \n    \n      row 5\n      NaN\n      0.559053\n      0.034450\n      0.719930\n      0.421004\n      0.436935\n      4\n    \n    \n      row 6\n      0.281701\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n      0.525819\n      5\n    \n    \n      row 1\n      0.870124\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n      0.117376\n      8\n    \n    \n      row 2\n      0.684969\n      0.437611\n      0.556229\n      0.367080\n      0.402366\n      NaN\n      1\n    \n    \n      row 3\n      0.447031\n      0.585445\n      0.161985\n      0.520719\n      0.326051\n      NaN\n      2\n    \n    \n      row 4\n      NaN\n      0.836375\n      0.481343\n      0.516502\n      0.383048\n      NaN\n      3\n    \n    \n      row 5\n      NaN\n      0.559053\n      0.034450\n      0.719930\n      0.421004\n      0.436935\n      4\n    \n    \n      row 6\n      0.281701\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n      0.525819\n      5\n    \n  \n\n\n\n\n\n\n2.5.4 Use append to add data table to itself, resetting index values.\n\nadded_datatable = variable_added.append(variable_added, ignore_index=True)\nadded_datatable\n\n/var/folders/90/4rtssdj16dl23f_f66qj0t3w0000gn/T/ipykernel_22703/4230768127.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  added_datatable = variable_added.append(variable_added, ignore_index=True)\n\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n      column 4\n      column 5\n      column 6\n      added_variable\n    \n  \n  \n    \n      0\n      0.870124\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n      0.117376\n      8\n    \n    \n      1\n      0.684969\n      0.437611\n      0.556229\n      0.367080\n      0.402366\n      NaN\n      1\n    \n    \n      2\n      0.447031\n      0.585445\n      0.161985\n      0.520719\n      0.326051\n      NaN\n      2\n    \n    \n      3\n      NaN\n      0.836375\n      0.481343\n      0.516502\n      0.383048\n      NaN\n      3\n    \n    \n      4\n      NaN\n      0.559053\n      0.034450\n      0.719930\n      0.421004\n      0.436935\n      4\n    \n    \n      5\n      0.281701\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n      0.525819\n      5\n    \n    \n      6\n      0.870124\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n      0.117376\n      8\n    \n    \n      7\n      0.684969\n      0.437611\n      0.556229\n      0.367080\n      0.402366\n      NaN\n      1\n    \n    \n      8\n      0.447031\n      0.585445\n      0.161985\n      0.520719\n      0.326051\n      NaN\n      2\n    \n    \n      9\n      NaN\n      0.836375\n      0.481343\n      0.516502\n      0.383048\n      NaN\n      3\n    \n    \n      10\n      NaN\n      0.559053\n      0.034450\n      0.719930\n      0.421004\n      0.436935\n      4\n    \n    \n      11\n      0.281701\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n      0.525819\n      5\n    \n  \n\n\n\n\n\n\n2.5.5 Create a 6x6 data frame with values arraged from 0-35, and another 3x5 data frame with values arranged from 0-14.\n\nDF_obj3 = pd.DataFrame(np.arange(36).reshape(6,6))\nDF_obj3\n\nDF_obj4 = pd.DataFrame(np.arange(15).reshape(5,3))\nDF_obj4\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n    \n      2\n      6\n      7\n      8\n    \n    \n      3\n      9\n      10\n      11\n    \n    \n      4\n      12\n      13\n      14\n    \n  \n\n\n\n\n\n\n2.5.6 Concatenate by adding columns.\n\npd.concat([DF_obj3, DF_obj4], axis = 1)\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n      4\n      5\n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n      3\n      4\n      5\n      0.0\n      1.0\n      2.0\n    \n    \n      1\n      6\n      7\n      8\n      9\n      10\n      11\n      3.0\n      4.0\n      5.0\n    \n    \n      2\n      12\n      13\n      14\n      15\n      16\n      17\n      6.0\n      7.0\n      8.0\n    \n    \n      3\n      18\n      19\n      20\n      21\n      22\n      23\n      9.0\n      10.0\n      11.0\n    \n    \n      4\n      24\n      25\n      26\n      27\n      28\n      29\n      12.0\n      13.0\n      14.0\n    \n    \n      5\n      30\n      31\n      32\n      33\n      34\n      35\n      NaN\n      NaN\n      NaN\n    \n  \n\n\n\n\n\n\n2.5.7 Concatenate by adding rows.\n\npd.concat([DF_obj3, DF_obj4])\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n      4\n      5\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n      3.0\n      4.0\n      5.0\n    \n    \n      1\n      6\n      7\n      8\n      9.0\n      10.0\n      11.0\n    \n    \n      2\n      12\n      13\n      14\n      15.0\n      16.0\n      17.0\n    \n    \n      3\n      18\n      19\n      20\n      21.0\n      22.0\n      23.0\n    \n    \n      4\n      24\n      25\n      26\n      27.0\n      28.0\n      29.0\n    \n    \n      5\n      30\n      31\n      32\n      33.0\n      34.0\n      35.0\n    \n    \n      0\n      0\n      1\n      2\n      NaN\n      NaN\n      NaN\n    \n    \n      1\n      3\n      4\n      5\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      6\n      7\n      8\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      9\n      10\n      11\n      NaN\n      NaN\n      NaN\n    \n    \n      4\n      12\n      13\n      14\n      NaN\n      NaN\n      NaN"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#grouping-and-aggregating-data",
    "href": "01_blog/2022_12_05_python-beg/index.html#grouping-and-aggregating-data",
    "title": "Python Basics",
    "section": "2.6 Grouping and Aggregating Data",
    "text": "2.6 Grouping and Aggregating Data\n\n2.6.1 Read cars csv with python.\n\naddress = '../../00_data/mtcars.csv'\ncars = pd.read_csv(address)\n# assign column names\ncars.columns = ['car_names', 'mpg', 'cyl', 'disp', 'hp', 'drat', 'wt', 'qsec', 'vs', 'am', 'gear', 'carb']\ncars.head()\n\n\n\n\n\n  \n    \n      \n      car_names\n      mpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n  \n  \n    \n      0\n      Mazda RX4\n      21.0\n      6\n      160.0\n      110\n      3.90\n      2.620\n      16.46\n      0\n      1\n      4\n      4\n    \n    \n      1\n      Mazda RX4 Wag\n      21.0\n      6\n      160.0\n      110\n      3.90\n      2.875\n      17.02\n      0\n      1\n      4\n      4\n    \n    \n      2\n      Datsun 710\n      22.8\n      4\n      108.0\n      93\n      3.85\n      2.320\n      18.61\n      1\n      1\n      4\n      1\n    \n    \n      3\n      Hornet 4 Drive\n      21.4\n      6\n      258.0\n      110\n      3.08\n      3.215\n      19.44\n      1\n      0\n      3\n      1\n    \n    \n      4\n      Hornet Sportabout\n      18.7\n      8\n      360.0\n      175\n      3.15\n      3.440\n      17.02\n      0\n      0\n      3\n      2\n    \n  \n\n\n\n\n\n\n2.6.2 Group by cyl and find mean values.\n\ncars_groups = cars.groupby(cars['cyl'])\ncars_groups.mean()\n\n/var/folders/90/4rtssdj16dl23f_f66qj0t3w0000gn/T/ipykernel_22703/3858733335.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n  cars_groups.mean()\n\n\n\n\n\n\n  \n    \n      \n      mpg\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n    \n      cyl\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      4\n      26.663636\n      105.136364\n      82.636364\n      4.070909\n      2.285727\n      19.137273\n      0.909091\n      0.727273\n      4.090909\n      1.545455\n    \n    \n      6\n      19.742857\n      183.314286\n      122.285714\n      3.585714\n      3.117143\n      17.977143\n      0.571429\n      0.428571\n      3.857143\n      3.428571\n    \n    \n      8\n      15.100000\n      353.100000\n      209.214286\n      3.229286\n      3.999214\n      16.772143\n      0.000000\n      0.142857\n      3.285714\n      3.500000\n    \n  \n\n\n\n\n\n\n2.6.3 Group by am and find mean values.\n\ncars_trans_group = cars.groupby(cars['am'])\ncars_trans_group.mean()\n\n/var/folders/90/4rtssdj16dl23f_f66qj0t3w0000gn/T/ipykernel_22703/564591146.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n  cars_trans_group.mean()\n\n\n\n\n\n\n  \n    \n      \n      mpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      gear\n      carb\n    \n    \n      am\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      0\n      17.147368\n      6.947368\n      290.378947\n      160.263158\n      3.286316\n      3.768895\n      18.183158\n      0.368421\n      3.210526\n      2.736842\n    \n    \n      1\n      24.392308\n      5.076923\n      143.530769\n      126.846154\n      4.050000\n      2.411000\n      17.360000\n      0.538462\n      4.384615\n      2.923077"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#line-chart",
    "href": "01_blog/2022_12_05_python-beg/index.html#line-chart",
    "title": "Python Basics",
    "section": "3.1 Line Chart",
    "text": "3.1 Line Chart\n\n3.1.1 Plot a line chart with matplotlib.\n\nx = range(1,10)\ny = [1,2,3,4,0,4,3,2,1]\nplt.plot(x,y)\n\n\n\n\n\n\n3.1.2 Plot a line chart with Pandas\nUsing the cars dataset from 2.6.1:\n\n# select mpg variable\nmpg = cars['mpg']\n\n# print plot\nmpg.plot()\n\n<AxesSubplot: >"
  },
  {
    "objectID": "01_blog/2022_06_20_Final-Prep-Statistics/index.html",
    "href": "01_blog/2022_06_20_Final-Prep-Statistics/index.html",
    "title": "Final Prep. Statistics",
    "section": "",
    "text": "1. Method of Distribution Function (CDF)\n\nGiven the density function \\(f(y)\\) the distribution function \\[F_Y(y)=\\int_{\\text{lower}}^{y}f(t)dt=F_Y(t)|_{t=\\text{lower}}^{t=y}=F_Y(y)\\]\nFor \\(U=\\color{red}\\text{FUNCTION WITH Y}\\) , when y = lower, u = \\(\\color{yellow}\\text{MIN}\\) and when y = upper, u = \\(\\color{orange}\\text{MAX}\\).\nBy definition of the CDF, the CDF of U is,\n\n\\(\\begin{equation}\\label{a}\\begin{split}F_U(u) &= P(U\\leq u)\\\\&=P(\\color{red}\\text{FUNCTION WITH Y}\\color{black}\\leq u)\\\\&=P(Y\\leq\\color{blue}\\text{FUNCTION WITH u}\\color{black})\\\\&= F_Y(\\color{blue}\\text{FUNCTION WITH u}\\color{black})\\\\&=\\color{purple}\\text{NEW FUNCTION WITH u}\\end{split}\\end{equation}\\)\n\\(F_U(u)=\\begin{cases}0 & u<\\text{MIN}\\\\ \\color{purple}\\text{NEW FUNCTION WITH u}\\color{black} & \\color{yellow}\\text{MIN}\\color{black}\\leq u\\leq \\color{orange}\\text{MAX}\\color{black}\\\\1 & \\color{orange}\\text{MAX}\\color{black}\\leq u\\end{cases}\\)\n\nSince \\(f_U(u)=F'_U(u)\\),\n\n\\(f_U(u)=\\frac{d}{du}(F_U(u))=\\color{green}\\text{DERIVATIVE OF NEW FUNCTION WITH u}\\)\nThe complete pdf of U is,\n\\[f_U(u)=\\begin{cases}\\color{green}\\text{DERIVATIVE OF NEW FUNCTION WITH u}\\color{black} & \\color{yellow}\\text{MIN}\\color{black}<u<\\color{orange}\\text{MAX}\\color{black}\\\\0 & \\text{otherwise}\\end{cases}\\]\n\n\n2. Jacobian (Univariate)\n\nGraph U (Y,u) to verify g is monotone and increasing.\n\\(U=g(Y)\\) where \\(g(y)=U\\). Since g is a monotinc increasing function we can apply the Transformation Method.\nThe inverse of g is \\(h(u)=g^{-1}(y)=\\)ðŸ¥š for \\(\\color{yellow}\\text{MIN}\\) \\(\\leq u\\leq\\) \\(\\color{orange}\\text{MAX}\\), and \\(h'(u)=\\) ðŸ¤.\nThe pdf of U is then, \\(f_U(u)=f_Y(h(u))\\cdot |h'(u)|=f_Y(\\)ðŸ¥š\\()\\cdot|\\)ðŸ¤\\(|=\\color{white}\\text{A Solution}\\)\n\nAnd the complete pdf is,\n\\[f_U(u)=\\begin{cases}\\color{white}\\text{A Solution}\\color{black} & \\color{yellow}\\text{MIN}\\color{black}<u<\\color{orange}\\text{MAX}\\color{black}\\\\0 & \\text{otherwise}\\end{cases}\\]\nNote:\n\n\\(y^2\\) is monotonic on \\(0\\leq y\\)\n\n\n\n3. MGF\n\n\nThe mgf of Y is \\(M_Y(t)=\\color{white}\\text{Moment Generating Function of Y}\\color{black}=E_Y(t)=E(e^{ty})\\).\nBy definition of the mgf, the mgf of U is,\n\n\\(\\begin{equation}\\label{b}\\begin{split}M_U(t) &= E(e^{tU})\\\\&=\\text{something with the form of }E(e^{ty})\\\\&=\\color{white}\\text{something similar to known distribution}\\end{split}\\end{equation}\\)\n\nTherefore, mgf U has the form of \\(\\underline{\\text{a known distribution}}\\) with parameters \\(\\color{yellow}\\text{Parameter}\\) and \\(\\color{orange}\\text{Parameter}\\).\n\nNote: (For Bivariate)\n\nLet \\(Y_i\\) be the ith \\(\\underline{\\quad\\quad\\quad}\\) for \\(i=1,2\\).\n\n\n\n4. Jacobian (bivariate)\n\nThe pdf of \\(Y_1\\) is \\(f(y_1)=\\)ðŸŒ— and the pdf of \\(Y_2\\) is \\(f(y_2)=\\)ðŸŒ“.\nSince \\(Y_1\\) and \\(Y_2\\) are independent, their joint pdf is \\(f_{Y_1,Y_2}(y_1,y_2)=f(y_1)f(y_2)=\\)ðŸŒ—ðŸŒ“=ðŸŒ\nLet \\(U_1=\\)ðŸƒ\\(=h_1(y_1,y_2)\\) and \\(U_2=\\)ðŸŒŽ\\(=h_2(y_1,y_2)\\). Then, \\(y_1=...=\\)â›µ\\(=h_1^{-1}(u_1,u_2)\\) and \\(y_2=...=\\)ðŸŒŠ\\(=h_2^{-1}(u_1,u_2)\\).\nThen the Jacobian is, \\(J=\\text{det}\\begin{bmatrix}\\frac{\\partial y_1}{\\partial u_1} & \\frac{\\partial y_1}{\\partial u_2}\\\\ \\frac{\\partial y_2}{\\partial u_1} & \\frac{\\partial y_2}{\\partial u_2}\\end{bmatrix}=\\) âš“\nRecall: det\\(|\\begin{smallmatrix}a & b \\\\ c & d\\end{smallmatrix}|=(ad)-(bc)\\)\nTherefore the joint pdf of \\(U_1\\) and \\(U_2\\) is \\(f_{U_1,U_2}=(u_1,u_2)=f_{Y_1,Y_2}(h_1^{-1}(u_1,u_2),h_2^{-1}(u_1,u_2))\\times|J|=\\)ðŸŒœâ›µðŸŒŠðŸŒ›\\(\\times\\)|âš“|\n\n\n\n5. Normal Sample\nFind the probability that the sample of \\(n=\\)ðŸ will be within X=ðŸ¯ of the population mean. Given \\(\\mu=\\)ðŸŒ» and \\(\\sigma^2=\\)ðŸŒ¿\n\nLet \\(\\overline{Y}\\) be the mean of \\(\\underline{\\quad\\text{     }\\quad}\\) of ðŸ \\(\\underline{\\quad\\text{     }\\quad}\\).\nWe want to find \\(P(|\\overline{Y}-\\mu|\\leq X)=P(|\\overline{Y}-\\)ðŸŒ»\\(|\\leq\\)ðŸ¯\\()=P(-\\)ðŸ¯\\(\\leq \\overline{Y}-\\)ðŸŒ»\\(\\leq\\)ðŸ¯\\()\\).\nSince the population is normally distributed with mean \\(=\\mu\\) and variance \\(\\frac{\\sigma^2}{\\sqrt{n}}=\\)ðŸŒ¿/\\(\\sqrt{}\\)ðŸ=ðŸŒ¾.\n\nThen, \\(P(-Z\\leq\\overline{Y}-\\mu\\leq Z)=P(\\)-ðŸ¯/ðŸŒ¾\\(\\leq [\\overline{Y}\\)-ðŸŒ»]/ðŸŒ¾\\(\\leq\\)ðŸ¯/ðŸŒ¾)=P(ðŸ„\\(\\leq Z\\leq\\) ðŸŒ¸)\n\nOn Ti Calculator normalcdf(ðŸ„,ðŸŒ¸,0,1)\n\nNote:\n\nVariance = 4 \\(\\rightarrow\\sqrt{4}=\\sigma^2\\)\nStandard Deviation = 4 \\(\\rightarrow 4=\\sigma^2\\)\n\\(Z=\\frac{\\overline{Y}-\\mu}{\\frac{\\sigma^2}{\\sqrt{n}}}=\\frac{\\sqrt{n}(\\overline{Y}-\\mu)}{\\sigma^2}\\)"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#line-charts",
    "href": "01_blog/2022_12_05_python-beg/index.html#line-charts",
    "title": "Python Basics",
    "section": "3.1 Line Charts",
    "text": "3.1 Line Charts\n\n3.1.1 Plot a line chart with matplotlib.\n\nx = range(1,10)\ny = [1,2,3,4,0,4,3,2,1]\nplt.plot(x,y)\n\n\n\n\n\n\n3.1.2 Defining axes, limits, and tick marks\n\n# gerate a figure\nfig = plt.figure()\n\n# add axis\nax = fig.add_axes([.1,.1,1,1]) \n\n# add limits \nax.set_xlim([1,9])\nax.set_ylim([0,5])\n\n# set tick marks\nax.set_xticks([0,1,2,4,5,6,8,9,10])\nax.set_yticks([0,1,2,3,4,5])\n\n# plot\nax.plot(x,y)\n\n\n\n\n\n\n3.1.3 Add Grid\n\n# gerate a figure\nfig = plt.figure()\n\n# add axis\nax = fig.add_axes([.1,.1,1,1])\n\n# add limits \nax.set_xlim([1,9])\nax.set_ylim([0,5])\n\n# add grid\nax.grid()\n\n# plot\nax.plot(x,y)\n\n\n\n\n\n\n3.1.4 Create A plot with two lines\n\n# create new variables\nx1 = range(0,10)\ny1 = [10,9,8,7,6,5,4,3,2,1]\n\n# make line plot with two lines\nplt.plot(x,y)\nplt.plot(x1,y1)\n\n\n\n\n\n\n3.1.5 Customizing Line Styles\n\n# make line plot with two lines with style\nplt.plot(x,y, ds ='steps', lw=5)\nplt.plot(x1,y1, ls='--', lw=10)\n\n\n\n\n\n\n3.1.6 Customizing Markers\n\n# make line plot with two lines with markers\nplt.plot(x,y, marker='1', mew='20')\nplt.plot(x1,y1, marker='+', mew=15)\n\n\n\n\n\n\n3.1.7 Generating Multiple Plots\n\n# generate a figure\nfig = plt.figure()\n\n# create a tuple equal to the subplots function defined as 1 row with 2 columns\nfig,(ax1, ax2) = plt.subplots(1,2)\n\n# defining axes\nax1.plot(x)\nax2.plot(x,y)\n\n<Figure size 672x480 with 0 Axes>\n\n\n\n\n\n\n\n3.1.8 Plot a line chart with Pandas\nUsing the cars data set from 2.6.1:\n\n# select mpg variable\nmpg = cars['mpg']\n\n# print plot\nmpg.plot()\n\n<AxesSubplot: >\n\n\n\n\n\n\n\n3.1.9 Plot 3 Variables\n\ndf = cars[['cyl','wt','mpg']]\ndf.plot()\n\n<AxesSubplot: >\n\n\n\n\n\n\n\n3.1.10 Define Color\n\n# color\ncolor_theme = ['darkgray', 'lightsalmon', 'powderblue']\n\n# pass in color theme\ndf.plot(color=color_theme)\n\n<AxesSubplot: >\n\n\n\n\n\n\n\n3.1.11 Add Labels (Object Oriented Method)\nNote: Car names are numbers because of the data set I am using.\n\n# create a figure\nfig = plt.figure()\n\n# add axis \nax = fig.add_axes([.1,.1,1,1])\n\n# call plot method\nmpg.plot()\n\n# add tick marks\nax.set_xticks(range(32))\n\n# add lables with 60 degree rotaion\nax.set_xticklabels(cars.car_names, rotation=60, fontsize='medium')\n\n# set title\nax.set_title('Miles per Gallon of Cars in mtcars Dataset')\n\n# set x and y lables\nax.set_xlabel('car names')\nax.set_ylabel('mpg')\n\nText(0, 0.5, 'mpg')\n\n\n\n\n\n\n\n3.1.12 Add Legend (Object Oriented Method)\n\n# create a figure\nfig = plt.figure()\n\n# add axis \nax = fig.add_axes([.1,.1,1,1])\n\n# call plot method\nmpg.plot()\n\n# add tick marks\nax.set_xticks(range(32))\n\n# add lables with 60 degree rotaion\nax.set_xticklabels(cars.car_names, rotation=60, fontsize='medium')\n\n# set title\nax.set_title('Miles per Gallon of Cars in mtcars Dataset')\n\n# set x and y lables\nax.set_xlabel('car names')\nax.set_ylabel('mpg')\n\n# add legend\nax.legend(loc='best')\n\n<matplotlib.legend.Legend at 0x7ff59f4c21c0>\n\n\n\n\n\n\n\n3.1.13 Annotating\n\n# create a figure\nfig = plt.figure()\n\n# add axis \nax = fig.add_axes([.1,.1,1,1])\n\n# call plot method\nmpg.plot()\n\n# add tick marks\nax.set_xticks(range(32))\n\n# add lables with 60 degree rotaion\nax.set_xticklabels(cars.car_names, rotation=60, fontsize='medium')\n\n# set title\nax.set_title('Miles per Gallon of Cars in mtcars Dataset')\n\n# set x and y lables\nax.set_xlabel('car names')\nax.set_ylabel('mpg')\n\n# add legend\nax.legend(loc='best')\n\n# set y limit\nax.set_ylim([0,45])\n\n# create annotation at (19,33.9) with text at (21,35) of an arrow\nax.annotate('Toyota Corolla', xy=(19,33.9), xytext=(21,35), \n            arrowprops=dict(facecolor='black', shrink=0.05))\n\nText(21, 35, 'Toyota Corolla')"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#bar-charts",
    "href": "01_blog/2022_12_05_python-beg/index.html#bar-charts",
    "title": "Python Basics",
    "section": "3.2 Bar Charts",
    "text": "3.2 Bar Charts\n\n3.2.1 Create a bar chart from a list\n\nplt.bar(x,y)\n\n<BarContainer object of 9 artists>\n\n\n\n\n\n\n\n3.2.2 Define bar width and plot color\n\n# widths to adjust default bar width\nwide = [.5,.5,.5,.9,.9,.9,.5,.5,.5]\n\n# change color\ncolor = ['salmon']\n\n# format barchart with adjustments\nplt.bar(x,y, width=wide, color=color, align='center')\n\n<BarContainer object of 9 artists>\n\n\n\n\n\n\n\n3.2.3 Create a bar chart from Pandas object\n\nmpg.plot(kind=\"bar\")\n\n<AxesSubplot: >\n\n\n\n\n\n\n\n3.2.4 Create a horizontal bar chart\n\nmpg.plot(kind=\"barh\")\n\n<AxesSubplot: >\n\n\n\n\n\n\n\n3.2.5 Add labels\n\n# create variables\nx = range(1,10)\ny = [1,2,3,4,.5,4,3,2,1]\n\n# generate barchart \nplt.bar(x,y)\n\n# add labels\nplt.xlabel('your x-axis label')\nplt.ylabel('your y-axis label')\n\nText(0, 0.5, 'your y-axis label')"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#import-packages",
    "href": "01_blog/2022_12_05_python-beg/index.html#import-packages",
    "title": "Python Basics",
    "section": "0.0.1 Import Packages",
    "text": "0.0.1 Import Packages\n\nimport numpy as np\nimport pandas as pd\n\nfrom pandas import Series, DataFrame"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#print-working-directory",
    "href": "01_blog/2022_12_05_python-beg/index.html#print-working-directory",
    "title": "Python Basics",
    "section": "0.0.2 Print Working Directory",
    "text": "0.0.2 Print Working Directory\n\n%pwd\n\n'/Users/randi/Desktop/2022/rbolt22/blog/01_blog/2022_12_05_python-beg'"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#pie-charts",
    "href": "01_blog/2022_12_05_python-beg/index.html#pie-charts",
    "title": "Python Basics",
    "section": "3.3 Pie Charts",
    "text": "3.3 Pie Charts\n\n3.3.1 Create a pie chart.\n\nx = [1,2,3,4,0.5]\n\n# create pie chart\nplt.pie(x)\n\n# show pie chart\nplt.show()\n\n\n\n\n\n\n3.3.2 Define Color\n\n# create color theme with RGB code\ncolor_theme = ['#A9A9A9', '#FFA07A', '#B0E0E6', '#FFE4C4', '#BDB76B']\n\n# call pie function\nplt.pie(x, colors=color_theme)\n\n# show pie chart\nplt.show()\n\n\n\n\n\n\n3.3.3 Add labels (Functional Method)\n\n# create variable\nz = [1,2,3,4,.5]\nveh_type = ['bicycle', 'motorbike', 'car', 'van', 'stroller']\n\n# generate pie chart\nplt.pie(z, labels=veh_type)\n\n# plot pie chart\nplt.show()\n\n\n\n\n\n\n3.3.4 Add Legend\n\n# create pie chart\nplt.pie(x)\n\n# create a legend located in the best location\nplt.legend(veh_type, loc='best')\n\n# show pot\nplt.show()\n\n\n\n\n\n\n3.3.5Saving a pie chart\n\nplt.pie(x)\nplt.savefig('../../00_figs/pie-chart.png')\nplt.show()"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#time-series",
    "href": "01_blog/2022_12_05_python-beg/index.html#time-series",
    "title": "Python Basics",
    "section": "3.4 Time Series",
    "text": "3.4 Time Series\n\n3.4.0 Load Data\n\n# address\naddress = '../../00_data/Superstore-Sales.csv'\n# create a dataframe of csv file\ndf = pd.read_csv(address, index_col='Order Date', encoding='cp1252', parse_dates=True)\n\n# look at first 5 records\ndf.head()\n\n\n\n\n\n  \n    \n      \n      Row ID\n      Order ID\n      Order Priority\n      Order Quantity\n      Sales\n      Discount\n      Ship Mode\n      Profit\n      Unit Price\n      Shipping Cost\n      Customer Name\n      Province\n      Region\n      Customer Segment\n      Product Category\n      Product Sub-Category\n      Product Name\n      Product Container\n      Product Base Margin\n      Ship Date\n    \n    \n      Order Date\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2010-10-13\n      1\n      3\n      Low\n      6\n      261.5400\n      0.04\n      Regular Air\n      -213.25\n      38.94\n      35.00\n      Muhammed MacIntyre\n      Nunavut\n      Nunavut\n      Small Business\n      Office Supplies\n      Storage & Organization\n      Eldon Base for stackable storage shelf, platinum\n      Large Box\n      0.80\n      10/20/2010\n    \n    \n      2012-10-01\n      49\n      293\n      High\n      49\n      10123.0200\n      0.07\n      Delivery Truck\n      457.81\n      208.16\n      68.02\n      Barry French\n      Nunavut\n      Nunavut\n      Consumer\n      Office Supplies\n      Appliances\n      1.7 Cubic Foot Compact \"Cube\" Office Refrigera...\n      Jumbo Drum\n      0.58\n      10/2/2012\n    \n    \n      2012-10-01\n      50\n      293\n      High\n      27\n      244.5700\n      0.01\n      Regular Air\n      46.71\n      8.69\n      2.99\n      Barry French\n      Nunavut\n      Nunavut\n      Consumer\n      Office Supplies\n      Binders and Binder Accessories\n      Cardinal Slant-DÂ® Ring Binder, Heavy Gauge Vinyl\n      Small Box\n      0.39\n      10/3/2012\n    \n    \n      2011-07-10\n      80\n      483\n      High\n      30\n      4965.7595\n      0.08\n      Regular Air\n      1198.97\n      195.99\n      3.99\n      Clay Rozendal\n      Nunavut\n      Nunavut\n      Corporate\n      Technology\n      Telephones and Communication\n      R380\n      Small Box\n      0.58\n      7/12/2011\n    \n    \n      2010-08-28\n      85\n      515\n      Not Specified\n      19\n      394.2700\n      0.08\n      Regular Air\n      30.94\n      21.78\n      5.94\n      Carlos Soltero\n      Nunavut\n      Nunavut\n      Consumer\n      Office Supplies\n      Appliances\n      Holmes HEPA Air Purifier\n      Medium Box\n      0.50\n      8/30/2010\n    \n  \n\n\n\n\n\n\n3.4.1 Use Sample Method to Create Line Chart\n\n# use sample method\ndf2 = df.sample(n=100, random_state=25, axis=0)\n\n# add labels\nplt.xlabel('Order Date')\nplt.ylabel('Order Quantity')\n\n# add title\nplt.title('Superstore Sales')\n\n# select Order Quantity and plot\ndf2['Order Quantity'].plot()\n\n<AxesSubplot: title={'center': 'Superstore Sales'}, xlabel='Order Date', ylabel='Order Quantity'>"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#statistical-plots",
    "href": "01_blog/2022_12_05_python-beg/index.html#statistical-plots",
    "title": "Python Basics",
    "section": "3.5 Statistical Plots",
    "text": "3.5 Statistical Plots\n\n3.5.1 Scatterplot\n\n# create a scatterplot with darkgray dots of size 150\ncars.plot(kind='scatter', x='hp', y='mpg', c=['darkgray'], s=150)\n\n<AxesSubplot: xlabel='hp', ylabel='mpg'>\n\n\n\n\n\n\n\n3.5.2 Boxplots\n\n# create 2 boxplots with matplotlib\ncars.boxplot(column='mpg', by='am')\ncars.boxplot(column='wt', by='am')\n\n<AxesSubplot: title={'center': 'wt'}, xlabel='am'>"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#arrays",
    "href": "01_blog/2022_12_05_python-beg/index.html#arrays",
    "title": "Python Basics",
    "section": "4.1 Arrays",
    "text": "4.1 Arrays\n\n4.1.1 Creating Arrays\n\na = np.array([1,2,3,4,5,6])\nb = np.array([6,5,4,3,2,1])\na\nb\n\narray([6, 5, 4, 3, 2, 1])\n\n\n\n\n4.1.2 Array Arithimetic\n\na*10\na+b\na-b\na*b\na/b\n\narray([0.16666667, 0.4       , 0.75      , 1.33333333, 2.5       ,\n       6.        ])"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#matricies",
    "href": "01_blog/2022_12_05_python-beg/index.html#matricies",
    "title": "Python Basics",
    "section": "4.2 Matricies",
    "text": "4.2 Matricies\n\n4.2.1 Creating Matricies\n\naa = np.array([[2,3,6],[1,3,5],[10,20,30]])\nbb = np.array([[0,1,2],[3,4,5],[6,7,8]])\naa\nbb\n\narray([[0, 1, 2],\n       [3, 4, 5],\n       [6, 7, 8]])\n\n\n\n\n4.2.2 Multiplying Matricies\n\naa*bb\n\narray([[  0,   3,  12],\n       [  3,  12,  25],\n       [ 60, 140, 240]])\n\n\n\n\n4.2.3 Dot Product of Matricies\n\nnp.dot(aa,bb)\n\narray([[ 45,  56,  67],\n       [ 39,  48,  57],\n       [240, 300, 360]])"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#summary-statistics",
    "href": "01_blog/2022_12_05_python-beg/index.html#summary-statistics",
    "title": "Python Basics",
    "section": "4.3 Summary Statistics",
    "text": "4.3 Summary Statistics\n\n4.3.1 Sum of Column values\n\ncars.sum()\n\ncar_names    Mazda RX4Mazda RX4 WagDatsun 710Hornet 4 Drive...\nmpg                                                      642.9\ncyl                                                        198\ndisp                                                    7383.1\nhp                                                        4694\ndrat                                                    115.09\nwt                                                     102.952\nqsec                                                    571.16\nvs                                                          14\nam                                                          13\ngear                                                       118\ncarb                                                        90\ndtype: object\n\n\n\n\n4.3.2 Sum of Row values\n\ncars.sum(axis=1)\n\n/var/folders/90/4rtssdj16dl23f_f66qj0t3w0000gn/T/ipykernel_22703/1808080884.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n  cars.sum(axis=1)\n\n\n0     328.980\n1     329.795\n2     259.580\n3     426.135\n4     590.310\n5     385.540\n6     656.920\n7     270.980\n8     299.570\n9     350.460\n10    349.660\n11    510.740\n12    511.500\n13    509.850\n14    728.560\n15    726.644\n16    725.695\n17    213.850\n18    195.165\n19    206.955\n20    273.775\n21    519.650\n22    506.085\n23    646.280\n24    631.175\n25    208.215\n26    272.570\n27    273.683\n28    670.690\n29    379.590\n30    694.710\n31    288.890\ndtype: float64\n\n\n\n\n4.3.3 Median\n\ncars.median()\n\n/var/folders/90/4rtssdj16dl23f_f66qj0t3w0000gn/T/ipykernel_22703/2356643283.py:1: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n  cars.median()\n\n\nmpg      19.200\ncyl       6.000\ndisp    196.300\nhp      123.000\ndrat      3.695\nwt        3.325\nqsec     17.710\nvs        0.000\nam        0.000\ngear      4.000\ncarb      2.000\ndtype: float64\n\n\n\n\n4.3.4 Mean\n\ncars.mean()\n\n/var/folders/90/4rtssdj16dl23f_f66qj0t3w0000gn/T/ipykernel_22703/1764053374.py:1: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n  cars.mean()\n\n\nmpg      20.090625\ncyl       6.187500\ndisp    230.721875\nhp      146.687500\ndrat      3.596563\nwt        3.217250\nqsec     17.848750\nvs        0.437500\nam        0.406250\ngear      3.687500\ncarb      2.812500\ndtype: float64\n\n\n\n\n4.3.5 Max\n\ncars.max()\n\ncar_names    Volvo 142E\nmpg                33.9\ncyl                   8\ndisp              472.0\nhp                  335\ndrat               4.93\nwt                5.424\nqsec               22.9\nvs                    1\nam                    1\ngear                  5\ncarb                  8\ndtype: object\n\n\n\n\n4.3.6 Find index value for row with max value\n\nmpg = cars.mpg\nmpg.idxmax()\n\n19\n\n\n\n\n4.3.7 Standard Deviation\n\ncars.std()\n\n/var/folders/90/4rtssdj16dl23f_f66qj0t3w0000gn/T/ipykernel_22703/2703001680.py:1: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n  cars.std()\n\n\nmpg       6.026948\ncyl       1.785922\ndisp    123.938694\nhp       68.562868\ndrat      0.534679\nwt        0.978457\nqsec      1.786943\nvs        0.504016\nam        0.498991\ngear      0.737804\ncarb      1.615200\ndtype: float64\n\n\n\n\n4.3.8 Variance\n\ncars.var()\n\n/var/folders/90/4rtssdj16dl23f_f66qj0t3w0000gn/T/ipykernel_22703/2053581105.py:1: FutureWarning: The default value of numeric_only in DataFrame.var is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n  cars.var()\n\n\nmpg        36.324103\ncyl         3.189516\ndisp    15360.799829\nhp       4700.866935\ndrat        0.285881\nwt          0.957379\nqsec        3.193166\nvs          0.254032\nam          0.248992\ngear        0.544355\ncarb        2.608871\ndtype: float64\n\n\n\n\n4.3.9 Counts\n\ngear = cars.gear\ngear.value_counts()\n\n3    15\n4    12\n5     5\nName: gear, dtype: int64\n\n\n\n\n4.3.10 Descriptive Statistics\n\ncars.describe()\n\n\n\n\n\n  \n    \n      \n      mpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n  \n  \n    \n      count\n      32.000000\n      32.000000\n      32.000000\n      32.000000\n      32.000000\n      32.000000\n      32.000000\n      32.000000\n      32.000000\n      32.000000\n      32.0000\n    \n    \n      mean\n      20.090625\n      6.187500\n      230.721875\n      146.687500\n      3.596563\n      3.217250\n      17.848750\n      0.437500\n      0.406250\n      3.687500\n      2.8125\n    \n    \n      std\n      6.026948\n      1.785922\n      123.938694\n      68.562868\n      0.534679\n      0.978457\n      1.786943\n      0.504016\n      0.498991\n      0.737804\n      1.6152\n    \n    \n      min\n      10.400000\n      4.000000\n      71.100000\n      52.000000\n      2.760000\n      1.513000\n      14.500000\n      0.000000\n      0.000000\n      3.000000\n      1.0000\n    \n    \n      25%\n      15.425000\n      4.000000\n      120.825000\n      96.500000\n      3.080000\n      2.581250\n      16.892500\n      0.000000\n      0.000000\n      3.000000\n      2.0000\n    \n    \n      50%\n      19.200000\n      6.000000\n      196.300000\n      123.000000\n      3.695000\n      3.325000\n      17.710000\n      0.000000\n      0.000000\n      4.000000\n      2.0000\n    \n    \n      75%\n      22.800000\n      8.000000\n      326.000000\n      180.000000\n      3.920000\n      3.610000\n      18.900000\n      1.000000\n      1.000000\n      4.000000\n      4.0000\n    \n    \n      max\n      33.900000\n      8.000000\n      472.000000\n      335.000000\n      4.930000\n      5.424000\n      22.900000\n      1.000000\n      1.000000\n      5.000000\n      8.0000"
  },
  {
    "objectID": "01_blog/2022_12_05_python-beg/index.html#summarizing-categorical-data",
    "href": "01_blog/2022_12_05_python-beg/index.html#summarizing-categorical-data",
    "title": "Python Basics",
    "section": "4.4 Summarizing Categorical Data",
    "text": "4.4 Summarizing Categorical Data\n\n4.4.1 Count Carborators of Each Car\n\ncarb = cars.carb\ncarb.value_counts()\n\n4    10\n2    10\n1     7\n3     3\n6     1\n8     1\nName: carb, dtype: int64\n\n\n\n\n4.4.2 Group By Gear\n\n# subset data\ncars_cat = cars[['cyl', 'vs', 'am', 'gear', 'carb']]\n# Group by gear\ngears_group = cars_cat.groupby('gear')\ngears_group.describe()\n\n\n\n\n\n  \n    \n      \n      cyl\n      vs\n      ...\n      am\n      carb\n    \n    \n      \n      count\n      mean\n      std\n      min\n      25%\n      50%\n      75%\n      max\n      count\n      mean\n      ...\n      75%\n      max\n      count\n      mean\n      std\n      min\n      25%\n      50%\n      75%\n      max\n    \n    \n      gear\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      3\n      15.0\n      7.466667\n      1.187234\n      4.0\n      8.0\n      8.0\n      8.0\n      8.0\n      15.0\n      0.200000\n      ...\n      0.0\n      0.0\n      15.0\n      2.666667\n      1.175139\n      1.0\n      2.0\n      3.0\n      4.0\n      4.0\n    \n    \n      4\n      12.0\n      4.666667\n      0.984732\n      4.0\n      4.0\n      4.0\n      6.0\n      6.0\n      12.0\n      0.833333\n      ...\n      1.0\n      1.0\n      12.0\n      2.333333\n      1.302678\n      1.0\n      1.0\n      2.0\n      4.0\n      4.0\n    \n    \n      5\n      5.0\n      6.000000\n      2.000000\n      4.0\n      4.0\n      6.0\n      8.0\n      8.0\n      5.0\n      0.200000\n      ...\n      1.0\n      1.0\n      5.0\n      4.400000\n      2.607681\n      2.0\n      2.0\n      4.0\n      6.0\n      8.0\n    \n  \n\n3 rows Ã— 32 columns\n\n\n\n\n\n4.4.3 Transforming Variables to Categorical Data type\n\n# create new column\ncars['group'] = pd.Series(cars.gear, dtype = 'category')\n# look at new variable \ncars['group'].dtypes\n# look at distribution\ncars['group'].value_counts()\n\n3    15\n4    12\n5     5\nName: group, dtype: int64\n\n\n\n\n4.4.4 Describe Categorical Data with Crosstabs\n\npd.crosstab(cars['am'], cars['gear'])\n\n\n\n\n\n  \n    \n      gear\n      3\n      4\n      5\n    \n    \n      am\n      \n      \n      \n    \n  \n  \n    \n      0\n      15\n      4\n      0\n    \n    \n      1\n      0\n      8\n      5"
  },
  {
    "objectID": "01_blog/2022_12_19_Weapons-of-Math-Destruction/index.html",
    "href": "01_blog/2022_12_19_Weapons-of-Math-Destruction/index.html",
    "title": "Weapons of Math Desctruction",
    "section": "",
    "text": "1. Bomb Parts: What is a Model?\nThis chapter compares baseball models to that of a family diet plan, and a questionnaire given to inmates that categorizes their recidivism.\nNote: WMD stands for Weapons of Math Destruction (like the title of the book).\n\nâ€œBaseball is an ideal home for predictive mathematical modelingâ€¦ and it serves as a useful contrast to the toxic models, or WMDâ€™s that are popping up in so many areas of our lives. Baseball models are fair, in part because they are transparent. Everyone has access to the stats and can understand more or less how theyâ€™re interpretedâ€¦ Baseball also has strict rigor. Its gurus have an immense data set at hand, almost all of it directly related to the performance of players in the game. Moreover, their data is highly relevant to the outcomes they are trying to predictâ€¦ Most crucially, that data is constantly pouring in, with new statisticsâ€¦ Whatever they learn, they can feed back into the model, refining it. Thatâ€™s how trustworthy models operate. They maintain a constant back-and-forth with whatever in the world theyâ€™re trying to understand or predict. Conditions change, and so must the model.â€\nâ€œA model, after all, is nothing more than an abstract representation of some process.â€\nâ€œThere would always be mistakes, however, because models are, by their very nature, simplifications. No Model can include all of the real worldâ€™s complexity or the nuance of human communication.â€\nâ€œA modelâ€™s blind spots reflect the judgments and priorities of its creators.â€\nâ€œWhether or not a model works is also a matter of opinion. After all, a key component of every model, whether formal or informal, is its definition of success.â€\nâ€œRacism, at the individual level, can be seen as a predictive model whirring away in billions of humans minds around the world. It is built from faulty, incomplete, or generalized dataâ€¦ Needless to say, racist donâ€™t spend a lot of time hunting down reliable data to train their twisted models. And once their model morphs into a belief, it becomes hardwired. It generates poisonous assumptions, yet rarely tests them, settling instead for data that seems to confirm and fortify them. Consequently, racism is the the most slovenly of predictive models. It is powered by haphazard data gathering and spurious correlations, reinforced by institutional inequalities, and polluted by confirmation bias.â€\nâ€œRegardless of whether the issue of race comes up explicitly at trial, it has long been a major factor in sentencing. A University of Maryland study showed that in Harris County, which includes Houston, prosecutes were three times more likely to seek the death penalty for African Americans, and four times more likely to seek the death penalty for Hispanics, than for whites convicted of the same charges. That pattern isnâ€™t unique to Texas. According to the American Civil Liberties Union, sentences imposed on black men in the federal system are nearly 20 percent longer than those for whites convicted of similar crimes. And though they make up only 13 percent of the population, blacks fill up 40 percent of Americaâ€™s prison cells.â€\nâ€œThe question, however, is whether weâ€™ve eliminated human bias or simply camouflaged it with technology.â€\nâ€œA 2013 study by the New York Civil Liberties Union found that while black and Latino males between the ages of fourteen and twenty-four made up only 4.7 percent of the the cityâ€™s population, they accounted for 40.6 percent of the stop-and-frisk check by police.â€\nâ€œThe LSI-R questionnaire has been given to thousand of inmates since its invention in 1995. Statisticians have used those results to devise a system in which answers highly correlated to recidivism weigh more heavily and count for more points. After answering the questionnaire, convicts are categorized as high, medium, and low risk on the basis of the number of points they accumulate. In some states, such as Rhode Island, these tests are used only to target those with high-risk scores for anti recidivism programs while incarcerated. But in others, including Idaho and Colorado, judges use the scores to guide their sentencing. This is unjust. The questionnaire includes circumstances of a criminalâ€™s birth and upbringing, including their family, neighborhood, and friends. These details should not be relevant to a criminal case or to the sentencingâ€¦ the model itself contributes to a toxic cycle and helps to sustain it. Thatâ€™s a signature quality of a WMD.â€\nâ€œ[Healthy models] are transparent and continuously updated, with both the assumptions and the conclusions clear for all to see.â€\nâ€œSo to sum up, these are the three elements of a WMD: opacity, scale, and damage.â€\nâ€œAnd hereâ€™s one more thing about algorithms: they can leap from one field to the next, and they often do. Research in epidemiology can hold insights for box office predictions; spam filters are being retooled to identify the AIDS virus.â€\n\n\n\n2. Shell Shocked: My Journey of Disillusionment\nMost of this chapter covers the 2008 housing market crash.\n\nâ€œSummers had troubles with faculty, though. And professors had risen up against him in part because he suggested that the low numbers of women in math the hard sciences might be due to gender inferiority - what he called the unequal distribution ofâ€intrinsic aptitudeâ€. After Summers left the Harvard presidency, he landed at Shaw. And I remember that when it came time for our founder, David Shaw, to address the prestigious trio, he joked that Summers move from Harvard to Shaw had been a â€œpromotionâ€.â€\nâ€œIf you want a metaphor one commonly used in this field comes from sausages. Think of morgages as little pieces of meat of varying quality, and think of the mortgage-backed securities as bundles of the sausage that result from throwing everything together and adding a bunch of strong spices. Of course, sausages can vary in quality, and itâ€™s hard to tell from the outside what went into them, but since they have a stamp from the USDA saying theyâ€™re safe to eat, our worries are put asideâ€¦ The strategy was simply to write unsustainable mortages, snarf up the fees, and then unload the resulting securities - the sausage - into the booming mortage securtiy market.â€\nâ€œIn one notorious case, a strawberry picker named Alberto Ramirez, who made $14,000 a year, managed to finance a $720,000 house in Rancho Grande, California. His broker apparently told him that he could refinance in a few months and later flip the house and make a tidy profit. Months later, he defaulted on the loan.â€\nâ€œIn a federal lawsuit, Baltimore officials charged Wells Fargo with targeting black neighborhoods for so-called ghetto loands. The bankâ€™sâ€emerging marketsâ€ unit, according to a former bank loan officer, Beth Jacobson, focused on black churches. The idea was that trusted pastors would steer their congregants toward loans. These turned out to be subprime loans carrying the highest interest rates. The bank sold these even to borrowers with rock-solid credit, who should have qualified for loans with far better terms. By the time Baltimore filed the suit, in 2009, more than half of the properties subject to foreclosure on Well Fargo loans were empty, and 71 percent of them were in largely African American neighborhoods. (In 2012, Wells Fargo settled the suit, agreeing to pay $174 million to thirty thousand victims around the country.)â€\nâ€œThe first false assumption was that crack mathematicians in all of these companies were crunching the numbers and ever so carefully balancing the riskâ€¦ Unfortunately, this just wasnâ€™t the case. As with so many WMDs., the math was directed against the consumer as a smoke screenâ€¦ Even rigoruous mathematicians - and there were a few - were working with numbers provided by people carrying out wide-scale fraud.â€\nâ€œI was espeially diappointed in the part that mathematics had played. I was forced to confront the ugly truth: people had deliberately wielded formulas to impress rather thanclarigy.â€\nâ€œThroughout my time at the hotline, I got the sense taht the people warning about risk were viewed as party poopers or, worse, a threat to the bankâ€™s bottom line. This was true even after the cataclysmic crash of 2008, and itâ€™s not hard to understand why. If they survived that one - because they were too big to fail - why were they going to fret over risk in their portfolio now?â€\nâ€œMy challenge was to design an algorithm that would distinguish window shoppers from buyers. There were a few obvious signals. Were they logged into the service? Had they bought there before? But I also scoured for other hints. What time of day was it, and what day of the year? Certain weeks are hot for buyersâ€¦ My algorithm would place a higher value on shoppers during these periods, since theyr were more likely to buy.â€\nâ€œA young suburbanite with every advantage - the prep school education, the exhaustive coaching for college admission tests, the overseas semester in Paris or Shanghai - still flatters themselves it is their skill, hard work, and prodigious problem-solving abilities that have lifted them into a world of privilege. Money vindicates all doubts. And the rest of their circle plays along, forming a mutual admiration society.â€\nâ€œâ€¦ a false sense of security was leading to widespread use of imperfect models, self-serving definitions of success, and growing feedback loops.â€\nâ€œThe algorithms would make sure that those deemed losers would remain that wayâ€¦ I could barely keep up with all the ways I was hearing of people being manipulated, controlled, and intimidated by algorithms.â€\n\n\n\n3. Arms Race: Going to College\nThis chapter discuses U.S. Newâ€™s college ranking, and what schools, studnets, and entrepenuers do to get a leg up.\n\nâ€œâ€¦ editors of U.S. News tried to figure out what they could measure. This is how many models start out, with a series of hunches. The process is not scientific and has scant grounding in statistical analysis. In this case, it was just people wondering what matters most in education, then figuring out which of those variables they could count, and finally deciding how much weight to give each of them in the formulaâ€¦ The trouble was that the rankings were self-reinforcingâ€¦ If Harvard, Standford, Princeton, and Yale came out on top, it would seem to validate their model, replicating the informal models that they and their customers carried in their own heads. To build such a model, they simply had to look at those top universities and count what made them so specialâ€¦ Now, if they incorporated the cost of education into the formula, strange things might happen to the results. Cheap universities could barge into the excellence hierarchy. This could create surprises and sow doubts. The public might receive the U.S. News rankings as something less than the word of God. It was much safer to start with the venerable champions on top. Of course they cost a lot. But maybe that was the price of excellence. By leaving cost out of the formula, it was as if U.S. news had handed college presidents a gilded checkbook. They had commandment to maximize performance in fifteen areas, and keeping cost low wasnâ€™t one of them. In fact if they raised prices theyâ€™d have more resources for addressing the areas where they were being measured.â€\nâ€œAs colleges position themselves to move up the U.S. News charts, they manage their student populations almost like investment portfolio.â€\nâ€œStudents in the Chinese city of Zhongxiang had a reputation for acing the national standardized test, or gaokao, and winning places in Chinaâ€™s top universities. They did so well, in fact that authorities began to suspect they were cheatingâ€¦ The next year, as students in Zhonqxiang arrived to take the exam, they were dimayed to be funneled through metal detectors and forced to relinquish their mobile phonesâ€¦ The response to this crackdown on cheating was volvanic. Some two thousand stone-throwing protester gathered in the street outside the school. They chanted,â€We want fairness. There is no fairness if you donâ€™t let us cheat.â€ It sounds like a joke, but they were absolutely serious. The stakes for the students were sky high. As they saw it, they faced a chance either to pursue an elite education and a prosperous career or to stay stuck in their provincial city, a relative backwater.â€\n\n\n\n4. Propaganda Machnie: Online Advertising\n\n\n5. Civilian Casualties: Justice in the Age of Big Data\n\n\n6. Ineligible to Serve: Getting a Job\n\n\n7. Sweating Bullets: On the Job\n\n\n8. Collateral Damage: Landing Credit\n\n\n9. No Safe Zone: Getting Insurance\n\n\n10. The Target Citizen: Civic Life"
  },
  {
    "objectID": "01_blog/2022_11_07_NBA-functions/index.html",
    "href": "01_blog/2022_11_07_NBA-functions/index.html",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "",
    "text": "In this tutorial I will be creating functions to scrape NBA data. The goal here is to prepare these functions to use in a package for future analysis."
  },
  {
    "objectID": "01_blog/2022_11_07_NBA-functions/index.html#about-the-data",
    "href": "01_blog/2022_11_07_NBA-functions/index.html#about-the-data",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "0_1. About-The-Data",
    "text": "0_1. About-The-Data\nI will be scrapping data from Basketball Reference which gets thier data updated regularly by a handful of contributors and sources. The main reasons I like using this data is because itâ€™s reliable, updated regularly, and similar sites exist for other non-NBA Sports (such as: WNBA, Baseball, Football, and others) if I wanted to expand my research outside the NBA."
  },
  {
    "objectID": "01_blog/2022_11_07_NBA-functions/index.html#package-installs",
    "href": "01_blog/2022_11_07_NBA-functions/index.html#package-installs",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "0_2. Package Installs",
    "text": "0_2. Package Installs\nThe packages I will be using are rvest to scrape the data and magrittr to pipe it. To install these packages, copy the code below and remove the first comment hash (command - shift - c).\n\n## install packages\n# install.packages(\"rvest\",  \"magrittr\")\n\nThen load:\n\n# load packages \nlibrary(rvest) \nlibrary(magrittr)"
  },
  {
    "objectID": "01_blog/2022_11_07_NBA-functions/index.html#team-statistics",
    "href": "01_blog/2022_11_07_NBA-functions/index.html#team-statistics",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "1_1. Team Statistics:",
    "text": "1_1. Team Statistics:\nThe first function Iâ€™m creating scrapes team statistics, which will need the user to input the teams url slug, the year that team attended or attends the NBA playoffs, and the stats_tb or statistics table that corresponds to what is shown on Basketball Reference. Currently not all tables work, but it should work for: #per_game, #totals, #per_36_minutes, and #advanced.\n\nscrape_team_data <- function(slug, year, stats_tb){\n    \"\n  A function that returns a data frame of team statistics. \n  \n  @param slug is string of three letters that represents the teams url. \n  @param year is a string that corresponds to the NBA finals.\n  @param stats_tb is a string that corresponds to the statistics table on BasketBall Reference such as #per_game, #totals, #per_36_minutes, and #advanced\n  \n  @return a df of team statistics\n  \"\n  # define team page URL\n  url <- base::paste0(\"https://www.basketball-reference.com/teams/\",\n                slug,\"/\", year, \".html\")\n  \n  # Read stats table\n  stats_tb <- url %>%\n  read_html %>%\n  html_node(stats_tb) %>% \n  html_table()\n  \n  # Rename Column 2 to Name \n  base::names(stats_tb)[2] <- \"Name\"\n  \n  # Replace NA values with 0 (for stat functions)\n  stats_tb[base::is.na(stats_tb)] <- 0\n  \n  # make data frame\n  df <- base::data.frame(stats_tb)\n  base::return(df)\n  }\n\n\nExamples\n\nA. Current Blazers Roster\n\nzers_roster <- scrape_team_data(\"POR\",\"2022\",\"#roster\")\nutils::head(zers_roster)\n\n  No.              Name Pos  Ht  Wt         Birth.Date Var.7 Exp\n1  21    Keljin Blevins  SF 6-4 200  November 24, 1995    us   1\n2   4    Greg Brown III  SF 6-9 205  September 1, 2001    us   R\n3  33  Robert Covington  PF 6-7 209  December 14, 1990    us   8\n4  34 Jarron Cumberland  SG 6-5 205 September 22, 1997    us   R\n5  18         Kris Dunn  PG 6-3 205     March 18, 1994    us   5\n6  16         CJ Elleby  SF 6-6 200      June 16, 2000    us   1\n                       College\n1 Southern Miss, Montana State\n2                        Texas\n3              Tennessee State\n4                   Cincinnati\n5                   Providence\n6             Washington State\n\n\n\n\nB. 1997 Chicago Bulls Total Statistics\n\nbulls_totals <- scrape_team_data(\"CHI\", \"1998\", \"#totals\")\nutils::head(bulls_totals)\n\n  Rk           Name Age  G GS   MP  FG  FGA   FG. X3P X3PA  X3P. X2P X2PA  X2P.\n1  1 Michael Jordan  34 82 82 3181 881 1893 0.465  30  126 0.238 851 1767 0.482\n2  2  Dennis Rodman  36 80 66 2856 155  360 0.431   4   23 0.174 151  337 0.448\n3  3     Ron Harper  34 82 82 2284 293  665 0.441  16   84 0.190 277  581 0.477\n4  4     Toni KukoÄ  29 74 52 2235 383  841 0.455  63  174 0.362 320  667 0.480\n5  5    Luc Longley  29 58 58 1703 277  609 0.455   0    0 0.000 277  609 0.455\n6  6 Scottie Pippen  32 44 44 1652 315  704 0.447  61  192 0.318 254  512 0.496\n   eFG.  FT FTA   FT. ORB DRB  TRB AST STL BLK TOV  PF  PTS\n1 0.473 565 721 0.784 130 345  475 283 141  45 185 151 2357\n2 0.436  61 111 0.550 421 780 1201 230  47  18 147 238  375\n3 0.453 162 216 0.750 107 183  290 241 108  48  91 181  764\n4 0.493 155 219 0.708 121 206  327 314  76  37 154 149  984\n5 0.455 109 148 0.736 113 228  341 161  34  62 130 206  663\n6 0.491 150 193 0.777  53 174  227 254  79  43 109 116  841\n\n\nHere we can see when Michael Jordan won his 6th ring with the Chicago Bulls he was also the leagues leading point scorer with 2,357 total points that season. Dennis Rodman was also a league leader that season in rebounds collecting a total of 1,201 rebounds."
  },
  {
    "objectID": "01_blog/2022_11_07_NBA-functions/index.html#player-statistics",
    "href": "01_blog/2022_11_07_NBA-functions/index.html#player-statistics",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "1_2. Player Statistics",
    "text": "1_2. Player Statistics\nThe second function will scrape player statistics. The user will need to input the players name, and the stats_tb or statistics table that corresponds to what is shown on Basketball Reference. Currently not all tables work, but it should work for: #per_game, #totals, #per_36_minutes, and #advanced.\n\nscrape_player_data <- function(name, stats_tb){\n  \"\n  A function that returns a data frame of player statistics. \n  \n  @param name is a string that represnets an NBA players name\n  @param stats_tb is a string that corresponds to the statistics table on BasketBall Reference such as #per_game, #totals, #per_36_minutes, and #advanced\n  \n  @return a df of player statistics\n  \"\n  # make name lower case\n  lower_case_name <- base::tolower(name)\n\n  # split name \n  split_name <- base::strsplit(lower_case_name, \" +\")[[1]]\n\n  # define first and last name\n  first_name <- split_name[[1]]\n  last_name <- split_name[[2]]\n  \n  # first letter of last name\n  letter <- base::substr(last_name, 1,1)\n  \n  # first five letters of last name \n  last_5 <- base::substr(last_name, 1, 5)\n  \n  # first two letters of first name\n  first_2 <- base::substr(first_name, 1,2)\n  \n  # define team page URL\n  url <- base::paste0(\"https://www.basketball-reference.com/players/\",letter ,\"/\",last_5,first_2,\"01.html\")\n  \n  # Read stats table\n  stats_tb <- url %>%\n  read_html %>%\n  html_node(stats_tb) %>% \n  html_table()\n  \n  # Rename Column 2 to Name \n  names(stats_tb)[2] <- \"Name\"\n  \n  # Replace NA values with 0 (for stat functions)\n  stats_tb[base::is.na(stats_tb)] <- 0\n  \n  # make list a dataframe\n  df <- base::data.frame(stats_tb)\n  \n  base::return(df)\n  }\n\n\nExamples\n\nC. Allen Iverson Per Game Stats\n\nai_per_game <- scrape_player_data(\"Allen Iverson\", \"#per_game\")\nhead(ai_per_game)\n\n   Season Name  Tm  Lg Pos  G GS   MP   FG  FGA  FG. X3P X3PA X3P. X2P X2PA\n1 1996-97   21 PHI NBA  PG 76 74 40.1  8.2 19.8 .416 2.0  6.0 .341 6.2 13.8\n2 1997-98   22 PHI NBA  PG 80 80 39.4  8.1 17.6 .461 0.9  2.9 .298 7.2 14.7\n3 1998-99   23 PHI NBA  SG 48 48 41.5  9.1 22.0 .412 1.2  4.1 .291 7.9 17.9\n4 1999-00   24 PHI NBA  SG 70 70 40.8 10.4 24.8 .421 1.3  3.7 .341 9.1 21.0\n5 2000-01   25 PHI NBA  SG 71 71 42.0 10.7 25.5 .420 1.4  4.3 .320 9.4 21.2\n6 2001-02   26 PHI NBA  SG 60 59 43.7 11.1 27.8 .398 1.3  4.5 .291 9.8 23.4\n  X2P. eFG.  FT  FTA  FT. ORB DRB TRB AST STL BLK TOV  PF  PTS\n1 .448 .467 5.0  7.2 .702 1.5 2.6 4.1 7.5 2.1 0.3 4.4 3.1 23.5\n2 .494 .486 4.9  6.7 .729 1.1 2.6 3.7 6.2 2.2 0.3 3.1 2.5 22.0\n3 .440 .439 7.4  9.9 .751 1.4 3.5 4.9 4.6 2.3 0.1 3.5 2.0 26.8\n4 .435 .446 6.3  8.9 .713 1.0 2.8 3.8 4.7 2.1 0.1 3.3 2.3 28.4\n5 .441 .447 8.2 10.1 .814 0.7 3.1 3.8 4.6 2.5 0.3 3.3 2.1 31.1\n6 .419 .422 7.9  9.8 .812 0.7 3.8 4.5 5.5 2.8 0.2 4.0 1.7 31.4\n\n\nNotice that when Allen Iverson won the NBAâ€™s MVP in 2001 he was putting up about 31 points a game.\n\n\nD. Kareem Abdul-Jabbar Totals\n\nkaj_totals <- scrape_player_data(\"Kareem Abdul-Jabbar\", \"#totals\")\nutils::head(kaj_totals)\n\n   Season Name  Tm  Lg Pos  G GS   MP   FG  FGA   FG. X3P X3PA X3P.  X2P X2PA\n1 1969-70   22 MIL NBA   C 82  0 3534  938 1810 0.518   0    0    0  938 1810\n2 1970-71   23 MIL NBA   C 82  0 3288 1063 1843 0.577   0    0    0 1063 1843\n3 1971-72   24 MIL NBA   C 81  0 3583 1159 2019 0.574   0    0    0 1159 2019\n4 1972-73   25 MIL NBA   C 76  0 3254  982 1772 0.554   0    0    0  982 1772\n5 1973-74   26 MIL NBA   C 81  0 3548  948 1759 0.539   0    0    0  948 1759\n6 1974-75   27 MIL NBA   C 65  0 2747  812 1584 0.513   0    0    0  812 1584\n   X2P.  eFG.  FT FTA   FT. ORB DRB  TRB AST STL BLK TOV  PF  PTS Var.31\n1 0.518 0.518 485 743 0.653   0   0 1190 337   0   0   0 283 2361      0\n2 0.577 0.577 470 681 0.690   0   0 1311 272   0   0   0 264 2596      0\n3 0.574 0.574 504 732 0.689   0   0 1346 370   0   0   0 235 2822      0\n4 0.554 0.554 328 460 0.713   0   0 1224 379   0   0   0 208 2292      0\n5 0.539 0.539 295 420 0.702 287 891 1178 386 112 283   0 238 2191      0\n6 0.513 0.513 325 426 0.763 194 718  912 264  65 212   0 205 1949      0\n  Trp.Dbl\n1       0\n2       1\n3       1\n4       2\n5       3\n6       1"
  },
  {
    "objectID": "01_blog/2022_11_07_NBA-functions/index.html#box-scores",
    "href": "01_blog/2022_11_07_NBA-functions/index.html#box-scores",
    "title": "Creating Functions in R to Scrape NBA Data",
    "section": "1_3. Box Scores",
    "text": "1_3. Box Scores\nThe last function still needs a bit of work, but will pull box scores of all the NBA games on a given day. The user will need to enter the game_day or day of the games they want box scores for.\nNote: Ideally this function would return a list with each game being its own df, but for now it only prints one data frame that includes all games played on that date. There also seem to be issues when only one game is played, or it is the first game of the season (see examples below), but for now those issues are manageable.\n\nbox_scores <- function(game_day){\n  \"\n  A function that returns a data frame of box scores. \n  \n  @param game_day is a string that represents the date in the form Y-M-D\n  \n  @return a df of box scores from that day.\n  \"\n  # split by dash\n  split_date <- base::strsplit(game_day, \"-\")\n  \n  # year - month - day \n  year <- split_date[[1]][[1]]\n  month <- split_date[[1]][[2]]\n  day <- split_date[[1]][[3]]\n  \n  #url\n  url <- base::paste0(\"https://www.basketball-reference.com/boxscores/?month=\",\n                month ,\"&day=\", day,\"&year=\", year)\n  \n  # read url\n  html <- read_html(url)\n  \n  # extract all the 'div\" items from the html as tables\n  div <- html %>% \n    html_elements(\"div\") %>% \n    html_table()\n  \n  #remove empties\n  div <- div[base::sapply(div, function(i) dim(i)[1]) > 0]\n  \n  # only keep rows == 7\n  div <- div[base::sapply(div, function(i) nrow(i)[1]) == 7]\n  \n  # empty list\n  my_vec <- base::list()\n  \n  #for loop\n  for(i in 1:base::length(div)) {        \n  my_out <- div[[i]][3:5,] \n  my_vec <- c(my_vec, my_out)\n  df <- base::data.frame(my_vec)\n  }\n  \n  df <- df[-1,]\n  \n  base::return(df)\n}\n\n\nExample\n\nE. Box Scores for 10-19-2022 (works correctly)\n\noct_19 <- box_scores(\"2022-10-19\")\noct_19\n\n       X1 X2 X3 X4 X5        X1.1 X2.1 X3.1 X4.1 X5.1    X1.2 X2.2 X3.2 X4.2\n2 Houston 20 30 30 27 New Orleans   32   26   40   32 Orlando   28   27   28\n3 Atlanta 26 33 25 33    Brooklyn   14   36   28   30 Detroit   17   40   34\n  X5.2       X1.3 X2.3 X3.3 X4.3 X5.3     X1.4 X2.4 X3.4 X4.4 X5.4 X6    X1.5\n2   26 Washington   36   24   27   27 New York   23   23   33   29  4 Chicago\n3   22    Indiana   25   27   25   30  Memphis   25   36   24   23  7   Miami\n  X2.5 X3.5 X4.5 X5.5          X1.6 X2.6 X3.6 X4.6 X5.6    X1.7 X2.7 X3.7 X4.7\n2   28   31   37   20 Oklahoma City   22   30   35   21  Dallas   32   30   19\n3   33   26   27   22     Minnesota   35   30   22   28 Phoenix   24   21   31\n  X5.7       X1.8 X2.8 X3.8 X4.8 X5.8        X1.9 X2.9 X3.9 X4.9 X5.9     X1.10\n2   24   Portland   32   19   33   31   Charlotte   38   30   30   31 Cleveland\n3   31 Sacramento   23   32   29   24 San Antonio   22   25   28   27   Toronto\n  X2.10 X3.10 X4.10 X5.10  X1.11 X2.11 X3.11 X4.11 X5.11\n2    22    35    27    21 Denver    30    23    27    22\n3    28    23    25    32   Utah    37    38    19    29\n\n\n\n\nF. Box scores for the first day of the â€™22/â€™23 NBA season (issues)\n\noct_18 <- box_scores(\"2022-10-18\")\noct_18\n\n            X1 X2 X3 X4 X5         X1.1 X2.1 X3.1 X4.1 X5.1               X1.2\n2 Philadelphia 29 34 25 29    LA Lakers   22   30   19   38 Philadelphia 76ers\n3       Boston 24 39 35 28 Golden State   25   34   32   32 Western Conference\n  X2.2 X3.2 X4.2 X5.2    X6    X7   X8   X9 X10 X11 X12  X13 X14 X15  X16 X17\n2    0    1 .000  1.0 117.0 126.0 <NA> <NA>  NA  NA  NA <NA>  NA  NA <NA>  NA\n3    W    L W/L%   GB  PS/G  PA/G <NA> <NA>  NA  NA  NA <NA>  NA  NA <NA>  NA\n  X18 X19 X20 X21 X22  X23  X24  X25  X26  X27  X28  X29  X30  X31 X32 X33 X34\n2  NA  NA  NA  NA  NA <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>  NA  NA  NA\n3  NA  NA  NA  NA  NA <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>  NA  NA  NA\n   X35 X36 X37  X38 X39 X40 X41 X42 X43 X44\n2 <NA>  NA  NA <NA>  NA  NA  NA  NA  NA  NA\n3 <NA>  NA  NA <NA>  NA  NA  NA  NA  NA  NA\n\n\nIssue: For the first game of the season there is an are NA tables that are being pulled in.\nG. First game of the 1992 NBA Finals AKA Michael Jordanâ€™s famous Shrug (issues)\n\nfinals_92_g1 <- box_scores(\"1992-6-3\")\nfinals_92_g1\n\n        X1 X2 X3 X4 X5     X1.1 X2.1 X3.1 X4.1 X5.1\n2 Portland 30 21 17 21 Portland   30   21   17   21\n3  Chicago 33 33 38 18  Chicago   33   33   38   18\n\n\nIssue: For days where only one game is played the one game is printed twice in the data frame."
  },
  {
    "objectID": "01_blog/2022_10_31_P-logically-equivalent-neg-neg-P/index.html",
    "href": "01_blog/2022_10_31_P-logically-equivalent-neg-neg-P/index.html",
    "title": "Prove P is Logically Equivalent to the Negation of the Negation of P",
    "section": "",
    "text": "Solution 1\nConsider the truth table for P, \\(\\neg P\\), and \\(\\neg (\\neg P)\\), as shown below in Figure 1:\n\n\nFigure 1: Truth Table\n\n\nP\n\\(\\neg P\\)\n\\(\\neg (\\neg P)\\)\n\n\n\n\nT\nF\nT\n\n\nF\nT\nF\n\n\n\n\nSince the truth values for P and \\(\\neg (\\neg P)\\) are the same then P and \\(\\neg (\\neg P)\\) are logically equivalent.\n\n\nSolution 2\nSuppose by way of contradiction (BWOC) that P and \\(\\neg (\\neg P)\\) are not logically equivalent.\nLet P be true and then \\(\\neg (\\neg P)\\) would be false.\nIf P is true then \\(\\neg P\\) would be false, but \\(\\neg P\\) and \\(\\neg (\\neg P)\\) cannot both be false. Therefore BWOC \\(\\neg (\\neg P)\\equiv P\\).\n\\(\\square\\)"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html",
    "href": "01_blog/2022_11_28_python-beg/index.html",
    "title": "Python Basics",
    "section": "",
    "text": "This post covers topics from Lillian Piersonâ€™s Linkedin Learning course Python for Data Sciene Training Part 1. Topics include Series, Data Frames, Data Visuals, Math and Statistics."
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#import-packages",
    "href": "01_blog/2022_11_28_python-beg/index.html#import-packages",
    "title": "Python Basics",
    "section": "0.0.1 Import Packages",
    "text": "0.0.1 Import Packages\n\nimport numpy as np\nimport pandas as pd\n\nfrom pandas import Series, DataFrame"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#print-working-directory",
    "href": "01_blog/2022_11_28_python-beg/index.html#print-working-directory",
    "title": "Python Basics",
    "section": "0.0.2 Print Working Directory",
    "text": "0.0.2 Print Working Directory\n\n%pwd\n\n'/Users/randi/Desktop/2022/rbolt22/blog/01_blog/2022_11_28_python-beg'"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#extracting",
    "href": "01_blog/2022_11_28_python-beg/index.html#extracting",
    "title": "Python Basics",
    "section": "1.1 Extracting",
    "text": "1.1 Extracting\n\n1.1.1 Select row 7\n\nseries_obj['row 7']\n\n6\n\n\n\n\n1.1.2 Select Elements at Position 0 and 7\n\nseries_obj[[0,7]]\n\nrow 1    0\nrow 8    7\ndtype: int64"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#slicing",
    "href": "01_blog/2022_11_28_python-beg/index.html#slicing",
    "title": "Python Basics",
    "section": "1.2 Slicing",
    "text": "1.2 Slicing\nSelect every row between 3 and 7.\n\nseries_obj['row 3':'row 7']\n\nrow 3    2\nrow 4    3\nrow 5    4\nrow 6    5\nrow 7    6\ndtype: int64"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#scalars",
    "href": "01_blog/2022_11_28_python-beg/index.html#scalars",
    "title": "Python Basics",
    "section": "1.3 Scalars",
    "text": "1.3 Scalars\n\n1.3.1 Print values greater than 5.\n\nseries_obj[series_obj>5]\n\nrow 7    6\nrow 8    7\ndtype: int64\n\n\n\n\n1.3.2 Set row 1 to the value 8.\n\nseries_obj['row 1'] = 8\nseries_obj\n\nrow 1    8\nrow 2    1\nrow 3    2\nrow 4    3\nrow 5    4\nrow 6    5\nrow 7    6\nrow 8    7\ndtype: int64"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#missing-values",
    "href": "01_blog/2022_11_28_python-beg/index.html#missing-values",
    "title": "Python Basics",
    "section": "1.4 Missing Values",
    "text": "1.4 Missing Values\n\n1.4.1 Create a variable of missing values using np.nan\n\nnp.nan: numpy function, not a number (nan)\n\n\nmissing = np.nan\nmissing\n\nnan\n\n\n\n\n1.4.2 Create a new series object with missing values for row 3 and 7.\n\nseries_obj2 = Series(['row 1', 'row 2', missing , 'row 5', 'row 6', missing, 'row 8'])\nseries_obj2\n\n0    row 1\n1    row 2\n2      NaN\n3    row 5\n4    row 6\n5      NaN\n6    row 8\ndtype: object\n\n\n\n\n1.4.3 Find what values are missing using .isnull()\n\nisnull(): pandas function that returns t/f if null\n\n\nseries_obj2.isnull()\n\n0    False\n1    False\n2     True\n3    False\n4    False\n5     True\n6    False\ndtype: bool"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#rename-data",
    "href": "01_blog/2022_11_28_python-beg/index.html#rename-data",
    "title": "Python Basics",
    "section": "1.5 Rename Data",
    "text": "1.5 Rename Data\n\n1.5.1 Name series object.\n\nseries_obj.name =\"added_variable\"\nseries_obj\n\nrow 1    8\nrow 2    1\nrow 3    2\nrow 4    3\nrow 5    4\nrow 6    5\nrow 7    6\nrow 8    7\nName: added_variable, dtype: int64"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#extracting-1",
    "href": "01_blog/2022_11_28_python-beg/index.html#extracting-1",
    "title": "Python Basics",
    "section": "2.1 Extracting",
    "text": "2.1 Extracting\n\n2.1.1 Select values from row 2, row 5, column 5, and column 2.\n\nDF_obj.loc[['row 2', 'row 5'], ['column 5', 'column 2']]\n\n\n\n\n\n  \n    \n      \n      column 5\n      column 2\n    \n  \n  \n    \n      row 2\n      0.402366\n      0.437611\n    \n    \n      row 5\n      0.421004\n      0.559053"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#scalars-1",
    "href": "01_blog/2022_11_28_python-beg/index.html#scalars-1",
    "title": "Python Basics",
    "section": "2.2 Scalars",
    "text": "2.2 Scalars\n\n2.2.1 Return a true or false for all values less than .2\n\nDF_obj < .2\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n      column 4\n      column 5\n      column 6\n    \n  \n  \n    \n      row 1\n      False\n      False\n      False\n      True\n      False\n      True\n    \n    \n      row 2\n      False\n      False\n      False\n      False\n      False\n      True\n    \n    \n      row 3\n      False\n      False\n      True\n      False\n      False\n      False\n    \n    \n      row 4\n      False\n      False\n      False\n      False\n      False\n      False\n    \n    \n      row 5\n      False\n      False\n      True\n      False\n      False\n      False\n    \n    \n      row 6\n      False\n      False\n      False\n      False\n      False\n      False"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#missing-values-1",
    "href": "01_blog/2022_11_28_python-beg/index.html#missing-values-1",
    "title": "Python Basics",
    "section": "2.3 Missing Values",
    "text": "2.3 Missing Values\n\n2.3.1 Set the values in rows 4-5 of column 1, and rows 2-4 of column 6 to missing.\n\niloc: python function used to select a particular cell of the dataset.\n\n\nDF_obj.iloc[3:5, 0] = missing\nDF_obj.iloc[1:4, 5] = missing\nDF_obj\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n      column 4\n      column 5\n      column 6\n    \n  \n  \n    \n      row 1\n      0.870124\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n      0.117376\n    \n    \n      row 2\n      0.684969\n      0.437611\n      0.556229\n      0.367080\n      0.402366\n      NaN\n    \n    \n      row 3\n      0.447031\n      0.585445\n      0.161985\n      0.520719\n      0.326051\n      NaN\n    \n    \n      row 4\n      NaN\n      0.836375\n      0.481343\n      0.516502\n      0.383048\n      NaN\n    \n    \n      row 5\n      NaN\n      0.559053\n      0.034450\n      0.719930\n      0.421004\n      0.436935\n    \n    \n      row 6\n      0.281701\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n      0.525819\n    \n  \n\n\n\n\n\n\n2.3.2 Replace non values with 0.\n\nfillna: pandas function used to replace missing values.\n\n\n# fill NaN values with 0\nfilled_DF = DF_obj.fillna(0)\nfilled_DF\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n      column 4\n      column 5\n      column 6\n    \n  \n  \n    \n      row 1\n      0.870124\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n      0.117376\n    \n    \n      row 2\n      0.684969\n      0.437611\n      0.556229\n      0.367080\n      0.402366\n      0.000000\n    \n    \n      row 3\n      0.447031\n      0.585445\n      0.161985\n      0.520719\n      0.326051\n      0.000000\n    \n    \n      row 4\n      0.000000\n      0.836375\n      0.481343\n      0.516502\n      0.383048\n      0.000000\n    \n    \n      row 5\n      0.000000\n      0.559053\n      0.034450\n      0.719930\n      0.421004\n      0.436935\n    \n    \n      row 6\n      0.281701\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n      0.525819\n    \n  \n\n\n\n\n\n\n2.3.3 Count the number of missing values in each column.\n\nDF_obj.isnull().sum()\n\ncolumn 1    2\ncolumn 2    0\ncolumn 3    0\ncolumn 4    0\ncolumn 5    0\ncolumn 6    3\ndtype: int64\n\n\n\n\n2.3.4 Filter out rows with missing values.\n\ndropna(): pandas function that removes rows with missing values.\n\n\nDF_no_NaN_rows = DF_obj.dropna()\nDF_no_NaN_rows\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n      column 4\n      column 5\n      column 6\n    \n  \n  \n    \n      row 1\n      0.870124\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n      0.117376\n    \n    \n      row 6\n      0.281701\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n      0.525819\n    \n  \n\n\n\n\n\n\n2.3.5 Filter out columns with missing values.\n\nDF_no_NaN_columns = DF_obj.dropna(axis=1)\nDF_no_NaN_columns\n\n\n\n\n\n  \n    \n      \n      column 2\n      column 3\n      column 4\n      column 5\n    \n  \n  \n    \n      row 1\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n    \n    \n      row 2\n      0.437611\n      0.556229\n      0.367080\n      0.402366\n    \n    \n      row 3\n      0.585445\n      0.161985\n      0.520719\n      0.326051\n    \n    \n      row 4\n      0.836375\n      0.481343\n      0.516502\n      0.383048\n    \n    \n      row 5\n      0.559053\n      0.034450\n      0.719930\n      0.421004\n    \n    \n      row 6\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n    \n  \n\n\n\n\n\n\n2.3.6 Fill the missing values with the method ffill.\n\nffill: pandas function fill forward which fills in the lass non-null value in DF.\n\n\nfill_DF = DF_obj.fillna(method='ffill')\nfill_DF\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n      column 4\n      column 5\n      column 6\n    \n  \n  \n    \n      row 1\n      0.870124\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n      0.117376\n    \n    \n      row 2\n      0.684969\n      0.437611\n      0.556229\n      0.367080\n      0.402366\n      0.117376\n    \n    \n      row 3\n      0.447031\n      0.585445\n      0.161985\n      0.520719\n      0.326051\n      0.117376\n    \n    \n      row 4\n      0.447031\n      0.836375\n      0.481343\n      0.516502\n      0.383048\n      0.117376\n    \n    \n      row 5\n      0.447031\n      0.559053\n      0.034450\n      0.719930\n      0.421004\n      0.436935\n    \n    \n      row 6\n      0.281701\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n      0.525819"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#duplicates",
    "href": "01_blog/2022_11_28_python-beg/index.html#duplicates",
    "title": "Python Basics",
    "section": "2.4 Duplicates",
    "text": "2.4 Duplicates\n\n2.4.1 Create a new data frame object.\n\nDF_obj2 = DataFrame({'column 1':[1,1,2,2,3,3,3],\n                   'column 2' :['a', 'a', 'b', 'b', 'c','c','c'],\n                   'column 3': ['A','A','B','B','C','C','C']})\nDF_obj2\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n    \n  \n  \n    \n      0\n      1\n      a\n      A\n    \n    \n      1\n      1\n      a\n      A\n    \n    \n      2\n      2\n      b\n      B\n    \n    \n      3\n      2\n      b\n      B\n    \n    \n      4\n      3\n      c\n      C\n    \n    \n      5\n      3\n      c\n      C\n    \n    \n      6\n      3\n      c\n      C\n    \n  \n\n\n\n\n\n\n2.4.2 Show which rows have duplicates.\n\nduplicated(): pandas function that returns t/f for rows with duplicate values.\n\n\nDF_obj2.duplicated()\n\n0    False\n1     True\n2    False\n3     True\n4    False\n5     True\n6     True\ndtype: bool\n\n\n\n\n2.4.3 Drop duplicates rows.\n\ndrop_duplicates()\n\n\nDF_obj2_row_drop  = DF_obj2.drop_duplicates()\nDF_obj2_row_drop\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n    \n  \n  \n    \n      0\n      1\n      a\n      A\n    \n    \n      2\n      2\n      b\n      B\n    \n    \n      4\n      3\n      c\n      C\n    \n  \n\n\n\n\n\n\n2.4.4 Drop duplicate from column 3.\n\nDF_obj2_c3_drop = DF_obj2.drop_duplicates(['column 3'])\nDF_obj2_c3_drop\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n    \n  \n  \n    \n      0\n      1\n      a\n      A\n    \n    \n      2\n      2\n      b\n      B\n    \n    \n      4\n      3\n      c\n      C"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#adding-data",
    "href": "01_blog/2022_11_28_python-beg/index.html#adding-data",
    "title": "Python Basics",
    "section": "2.5 Adding data",
    "text": "2.5 Adding data\n\n2.5.1 Slice the first 6 rows of series object.\n\nnew_series_obj = series_obj['row 0':'row 6']\nnew_series_obj\n\nrow 1    8\nrow 2    1\nrow 3    2\nrow 4    3\nrow 5    4\nrow 6    5\nName: added_variable, dtype: int64\n\n\n\n\n2.5.2 Add new_series_obj to the end of DF_obj\n\nvariable_added = DataFrame.join(DF_obj, series_obj)\nvariable_added\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n      column 4\n      column 5\n      column 6\n      added_variable\n    \n  \n  \n    \n      row 1\n      0.870124\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n      0.117376\n      8\n    \n    \n      row 2\n      0.684969\n      0.437611\n      0.556229\n      0.367080\n      0.402366\n      NaN\n      1\n    \n    \n      row 3\n      0.447031\n      0.585445\n      0.161985\n      0.520719\n      0.326051\n      NaN\n      2\n    \n    \n      row 4\n      NaN\n      0.836375\n      0.481343\n      0.516502\n      0.383048\n      NaN\n      3\n    \n    \n      row 5\n      NaN\n      0.559053\n      0.034450\n      0.719930\n      0.421004\n      0.436935\n      4\n    \n    \n      row 6\n      0.281701\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n      0.525819\n      5\n    \n  \n\n\n\n\n\n\n2.5.3 Use append to add data table to itself retaining index values.\n\nadded_datatable = variable_added.append(variable_added, ignore_index=False)\nadded_datatable\n\n/var/folders/90/4rtssdj16dl23f_f66qj0t3w0000gn/T/ipykernel_1064/426574045.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  added_datatable = variable_added.append(variable_added, ignore_index=False)\n\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n      column 4\n      column 5\n      column 6\n      added_variable\n    \n  \n  \n    \n      row 1\n      0.870124\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n      0.117376\n      8\n    \n    \n      row 2\n      0.684969\n      0.437611\n      0.556229\n      0.367080\n      0.402366\n      NaN\n      1\n    \n    \n      row 3\n      0.447031\n      0.585445\n      0.161985\n      0.520719\n      0.326051\n      NaN\n      2\n    \n    \n      row 4\n      NaN\n      0.836375\n      0.481343\n      0.516502\n      0.383048\n      NaN\n      3\n    \n    \n      row 5\n      NaN\n      0.559053\n      0.034450\n      0.719930\n      0.421004\n      0.436935\n      4\n    \n    \n      row 6\n      0.281701\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n      0.525819\n      5\n    \n    \n      row 1\n      0.870124\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n      0.117376\n      8\n    \n    \n      row 2\n      0.684969\n      0.437611\n      0.556229\n      0.367080\n      0.402366\n      NaN\n      1\n    \n    \n      row 3\n      0.447031\n      0.585445\n      0.161985\n      0.520719\n      0.326051\n      NaN\n      2\n    \n    \n      row 4\n      NaN\n      0.836375\n      0.481343\n      0.516502\n      0.383048\n      NaN\n      3\n    \n    \n      row 5\n      NaN\n      0.559053\n      0.034450\n      0.719930\n      0.421004\n      0.436935\n      4\n    \n    \n      row 6\n      0.281701\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n      0.525819\n      5\n    \n  \n\n\n\n\n\n\n2.5.4 Use append to add data table to itself, resetting index values.\n\nadded_datatable = variable_added.append(variable_added, ignore_index=True)\nadded_datatable\n\n/var/folders/90/4rtssdj16dl23f_f66qj0t3w0000gn/T/ipykernel_1064/4230768127.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  added_datatable = variable_added.append(variable_added, ignore_index=True)\n\n\n\n\n\n\n  \n    \n      \n      column 1\n      column 2\n      column 3\n      column 4\n      column 5\n      column 6\n      added_variable\n    \n  \n  \n    \n      0\n      0.870124\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n      0.117376\n      8\n    \n    \n      1\n      0.684969\n      0.437611\n      0.556229\n      0.367080\n      0.402366\n      NaN\n      1\n    \n    \n      2\n      0.447031\n      0.585445\n      0.161985\n      0.520719\n      0.326051\n      NaN\n      2\n    \n    \n      3\n      NaN\n      0.836375\n      0.481343\n      0.516502\n      0.383048\n      NaN\n      3\n    \n    \n      4\n      NaN\n      0.559053\n      0.034450\n      0.719930\n      0.421004\n      0.436935\n      4\n    \n    \n      5\n      0.281701\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n      0.525819\n      5\n    \n    \n      6\n      0.870124\n      0.582277\n      0.278839\n      0.185911\n      0.411100\n      0.117376\n      8\n    \n    \n      7\n      0.684969\n      0.437611\n      0.556229\n      0.367080\n      0.402366\n      NaN\n      1\n    \n    \n      8\n      0.447031\n      0.585445\n      0.161985\n      0.520719\n      0.326051\n      NaN\n      2\n    \n    \n      9\n      NaN\n      0.836375\n      0.481343\n      0.516502\n      0.383048\n      NaN\n      3\n    \n    \n      10\n      NaN\n      0.559053\n      0.034450\n      0.719930\n      0.421004\n      0.436935\n      4\n    \n    \n      11\n      0.281701\n      0.900274\n      0.669612\n      0.456069\n      0.289804\n      0.525819\n      5\n    \n  \n\n\n\n\n\n\n2.5.5 Create a 6x6 data frame with values arraged from 0-35, and another 3x5 data frame with values arranged from 0-14.\n\nDF_obj3 = pd.DataFrame(np.arange(36).reshape(6,6))\nDF_obj3\n\nDF_obj4 = pd.DataFrame(np.arange(15).reshape(5,3))\nDF_obj4\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n    \n    \n      1\n      3\n      4\n      5\n    \n    \n      2\n      6\n      7\n      8\n    \n    \n      3\n      9\n      10\n      11\n    \n    \n      4\n      12\n      13\n      14\n    \n  \n\n\n\n\n\n\n2.5.6 Concatenate by adding columns.\n\npd.concat([DF_obj3, DF_obj4], axis = 1)\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n      4\n      5\n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n      3\n      4\n      5\n      0.0\n      1.0\n      2.0\n    \n    \n      1\n      6\n      7\n      8\n      9\n      10\n      11\n      3.0\n      4.0\n      5.0\n    \n    \n      2\n      12\n      13\n      14\n      15\n      16\n      17\n      6.0\n      7.0\n      8.0\n    \n    \n      3\n      18\n      19\n      20\n      21\n      22\n      23\n      9.0\n      10.0\n      11.0\n    \n    \n      4\n      24\n      25\n      26\n      27\n      28\n      29\n      12.0\n      13.0\n      14.0\n    \n    \n      5\n      30\n      31\n      32\n      33\n      34\n      35\n      NaN\n      NaN\n      NaN\n    \n  \n\n\n\n\n\n\n2.5.7 Concatenate by adding rows.\n\npd.concat([DF_obj3, DF_obj4])\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n      4\n      5\n    \n  \n  \n    \n      0\n      0\n      1\n      2\n      3.0\n      4.0\n      5.0\n    \n    \n      1\n      6\n      7\n      8\n      9.0\n      10.0\n      11.0\n    \n    \n      2\n      12\n      13\n      14\n      15.0\n      16.0\n      17.0\n    \n    \n      3\n      18\n      19\n      20\n      21.0\n      22.0\n      23.0\n    \n    \n      4\n      24\n      25\n      26\n      27.0\n      28.0\n      29.0\n    \n    \n      5\n      30\n      31\n      32\n      33.0\n      34.0\n      35.0\n    \n    \n      0\n      0\n      1\n      2\n      NaN\n      NaN\n      NaN\n    \n    \n      1\n      3\n      4\n      5\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      6\n      7\n      8\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      9\n      10\n      11\n      NaN\n      NaN\n      NaN\n    \n    \n      4\n      12\n      13\n      14\n      NaN\n      NaN\n      NaN"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#grouping-and-aggregating-data",
    "href": "01_blog/2022_11_28_python-beg/index.html#grouping-and-aggregating-data",
    "title": "Python Basics",
    "section": "2.6 Grouping and Aggregating Data",
    "text": "2.6 Grouping and Aggregating Data\n\n2.6.1 Read cars csv with python.\n\naddress = '../../00_data/mtcars.csv'\ncars = pd.read_csv(address)\n# assign column names\ncars.columns = ['car_names', 'mpg', 'cyl', 'disp', 'hp', 'drat', 'wt', 'qsec', 'vs', 'am', 'gear', 'carb']\ncars.head()\n\n\n\n\n\n  \n    \n      \n      car_names\n      mpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n  \n  \n    \n      0\n      Mazda RX4\n      21.0\n      6\n      160.0\n      110\n      3.90\n      2.620\n      16.46\n      0\n      1\n      4\n      4\n    \n    \n      1\n      Mazda RX4 Wag\n      21.0\n      6\n      160.0\n      110\n      3.90\n      2.875\n      17.02\n      0\n      1\n      4\n      4\n    \n    \n      2\n      Datsun 710\n      22.8\n      4\n      108.0\n      93\n      3.85\n      2.320\n      18.61\n      1\n      1\n      4\n      1\n    \n    \n      3\n      Hornet 4 Drive\n      21.4\n      6\n      258.0\n      110\n      3.08\n      3.215\n      19.44\n      1\n      0\n      3\n      1\n    \n    \n      4\n      Hornet Sportabout\n      18.7\n      8\n      360.0\n      175\n      3.15\n      3.440\n      17.02\n      0\n      0\n      3\n      2\n    \n  \n\n\n\n\n\n\n2.6.2 Group by cyl and find mean values.\n\ncars_groups = cars.groupby(cars['cyl'])\ncars_groups.mean()\n\n/var/folders/90/4rtssdj16dl23f_f66qj0t3w0000gn/T/ipykernel_1064/3858733335.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n  cars_groups.mean()\n\n\n\n\n\n\n  \n    \n      \n      mpg\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n    \n      cyl\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      4\n      26.663636\n      105.136364\n      82.636364\n      4.070909\n      2.285727\n      19.137273\n      0.909091\n      0.727273\n      4.090909\n      1.545455\n    \n    \n      6\n      19.742857\n      183.314286\n      122.285714\n      3.585714\n      3.117143\n      17.977143\n      0.571429\n      0.428571\n      3.857143\n      3.428571\n    \n    \n      8\n      15.100000\n      353.100000\n      209.214286\n      3.229286\n      3.999214\n      16.772143\n      0.000000\n      0.142857\n      3.285714\n      3.500000\n    \n  \n\n\n\n\n\n\n2.6.3 Group by am and find mean values.\n\ncars_trans_group = cars.groupby(cars['am'])\ncars_trans_group.mean()\n\n/var/folders/90/4rtssdj16dl23f_f66qj0t3w0000gn/T/ipykernel_1064/564591146.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n  cars_trans_group.mean()\n\n\n\n\n\n\n  \n    \n      \n      mpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      gear\n      carb\n    \n    \n      am\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      0\n      17.147368\n      6.947368\n      290.378947\n      160.263158\n      3.286316\n      3.768895\n      18.183158\n      0.368421\n      3.210526\n      2.736842\n    \n    \n      1\n      24.392308\n      5.076923\n      143.530769\n      126.846154\n      4.050000\n      2.411000\n      17.360000\n      0.538462\n      4.384615\n      2.923077"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#line-charts",
    "href": "01_blog/2022_11_28_python-beg/index.html#line-charts",
    "title": "Python Basics",
    "section": "3.1 Line Charts",
    "text": "3.1 Line Charts\n\n3.1.1 Plot a line chart with matplotlib.\n\nx = range(1,10)\ny = [1,2,3,4,0,4,3,2,1]\nplt.plot(x,y)\n\n\n\n\n\n\n3.1.2 Defining axes, limits, and tick marks\n\n# gerate a figure\nfig = plt.figure()\n\n# add axis\nax = fig.add_axes([.1,.1,1,1]) \n\n# add limits \nax.set_xlim([1,9])\nax.set_ylim([0,5])\n\n# set tick marks\nax.set_xticks([0,1,2,4,5,6,8,9,10])\nax.set_yticks([0,1,2,3,4,5])\n\n# plot\nax.plot(x,y)\n\n\n\n\n\n\n3.1.3 Add Grid\n\n# gerate a figure\nfig = plt.figure()\n\n# add axis\nax = fig.add_axes([.1,.1,1,1])\n\n# add limits \nax.set_xlim([1,9])\nax.set_ylim([0,5])\n\n# add grid\nax.grid()\n\n# plot\nax.plot(x,y)\n\n\n\n\n\n\n3.1.4 Create A plot with two lines\n\n# create new variables\nx1 = range(0,10)\ny1 = [10,9,8,7,6,5,4,3,2,1]\n\n# make line plot with two lines\nplt.plot(x,y)\nplt.plot(x1,y1)\n\n\n\n\n\n\n3.1.5 Customizing Line Styles\n\n# make line plot with two lines with style\nplt.plot(x,y, ds ='steps', lw=5)\nplt.plot(x1,y1, ls='--', lw=10)\n\n\n\n\n\n\n3.1.6 Customizing Markers\n\n# make line plot with two lines with markers\nplt.plot(x,y, marker='1', mew='20')\nplt.plot(x1,y1, marker='+', mew=15)\n\n\n\n\n\n\n3.1.7 Generating Multiple Plots\n\n# generate a figure\nfig = plt.figure()\n\n# create a tuple equal to the subplots function defined as 1 row with 2 columns\nfig,(ax1, ax2) = plt.subplots(1,2)\n\n# defining axes\nax1.plot(x)\nax2.plot(x,y)\n\n<Figure size 672x480 with 0 Axes>\n\n\n\n\n\n\n\n3.1.8 Plot a line chart with Pandas\nUsing the cars data set from 2.6.1:\n\n# select mpg variable\nmpg = cars['mpg']\n\n# print plot\nmpg.plot()\n\n<AxesSubplot: >\n\n\n\n\n\n\n\n3.1.9 Plot 3 Variables\n\ndf = cars[['cyl','wt','mpg']]\ndf.plot()\n\n<AxesSubplot: >\n\n\n\n\n\n\n\n3.1.10 Define Color\n\n# color\ncolor_theme = ['darkgray', 'lightsalmon', 'powderblue']\n\n# pass in color theme\ndf.plot(color=color_theme)\n\n<AxesSubplot: >\n\n\n\n\n\n\n\n3.1.11 Add Labels (Object Oriented Method)\nNote: Car names are numbers because of the data set I am using.\n\n# create a figure\nfig = plt.figure()\n\n# add axis \nax = fig.add_axes([.1,.1,1,1])\n\n# call plot method\nmpg.plot()\n\n# add tick marks\nax.set_xticks(range(32))\n\n# add lables with 60 degree rotaion\nax.set_xticklabels(cars.car_names, rotation=60, fontsize='medium')\n\n# set title\nax.set_title('Miles per Gallon of Cars in mtcars Dataset')\n\n# set x and y lables\nax.set_xlabel('car names')\nax.set_ylabel('mpg')\n\nText(0, 0.5, 'mpg')\n\n\n\n\n\n\n\n3.1.12 Add Legend (Object Oriented Method)\n\n# create a figure\nfig = plt.figure()\n\n# add axis \nax = fig.add_axes([.1,.1,1,1])\n\n# call plot method\nmpg.plot()\n\n# add tick marks\nax.set_xticks(range(32))\n\n# add lables with 60 degree rotaion\nax.set_xticklabels(cars.car_names, rotation=60, fontsize='medium')\n\n# set title\nax.set_title('Miles per Gallon of Cars in mtcars Dataset')\n\n# set x and y lables\nax.set_xlabel('car names')\nax.set_ylabel('mpg')\n\n# add legend\nax.legend(loc='best')\n\n<matplotlib.legend.Legend at 0x7fea6ccd8250>\n\n\n\n\n\n\n\n3.1.13 Annotating\n\n# create a figure\nfig = plt.figure()\n\n# add axis \nax = fig.add_axes([.1,.1,1,1])\n\n# call plot method\nmpg.plot()\n\n# add tick marks\nax.set_xticks(range(32))\n\n# add lables with 60 degree rotaion\nax.set_xticklabels(cars.car_names, rotation=60, fontsize='medium')\n\n# set title\nax.set_title('Miles per Gallon of Cars in mtcars Dataset')\n\n# set x and y lables\nax.set_xlabel('car names')\nax.set_ylabel('mpg')\n\n# add legend\nax.legend(loc='best')\n\n# set y limit\nax.set_ylim([0,45])\n\n# create annotation at (19,33.9) with text at (21,35) of an arrow\nax.annotate('Toyota Corolla', xy=(19,33.9), xytext=(21,35), \n            arrowprops=dict(facecolor='black', shrink=0.05))\n\nText(21, 35, 'Toyota Corolla')"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#bar-charts",
    "href": "01_blog/2022_11_28_python-beg/index.html#bar-charts",
    "title": "Python Basics",
    "section": "3.2 Bar Charts",
    "text": "3.2 Bar Charts\n\n3.2.1 Create a bar chart from a list\n\nplt.bar(x,y)\n\n<BarContainer object of 9 artists>\n\n\n\n\n\n\n\n3.2.2 Define bar width and plot color\n\n# widths to adjust default bar width\nwide = [.5,.5,.5,.9,.9,.9,.5,.5,.5]\n\n# change color\ncolor = ['salmon']\n\n# format barchart with adjustments\nplt.bar(x,y, width=wide, color=color, align='center')\n\n<BarContainer object of 9 artists>\n\n\n\n\n\n\n\n3.2.3 Create a bar chart from Pandas object\n\nmpg.plot(kind=\"bar\")\n\n<AxesSubplot: >\n\n\n\n\n\n\n\n3.2.4 Create a horizontal bar chart\n\nmpg.plot(kind=\"barh\")\n\n<AxesSubplot: >\n\n\n\n\n\n\n\n3.2.5 Add labels\n\n# create variables\nx = range(1,10)\ny = [1,2,3,4,.5,4,3,2,1]\n\n# generate barchart \nplt.bar(x,y)\n\n# add labels\nplt.xlabel('your x-axis label')\nplt.ylabel('your y-axis label')\n\nText(0, 0.5, 'your y-axis label')"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#pie-charts",
    "href": "01_blog/2022_11_28_python-beg/index.html#pie-charts",
    "title": "Python Basics",
    "section": "3.3 Pie Charts",
    "text": "3.3 Pie Charts\n\n3.3.1 Create a pie chart.\n\nx = [1,2,3,4,0.5]\n\n# create pie chart\nplt.pie(x)\n\n# show pie chart\nplt.show()\n\n\n\n\n\n\n3.3.2 Define Color\n\n# create color theme with RGB code\ncolor_theme = ['#A9A9A9', '#FFA07A', '#B0E0E6', '#FFE4C4', '#BDB76B']\n\n# call pie function\nplt.pie(x, colors=color_theme)\n\n# show pie chart\nplt.show()\n\n\n\n\n\n\n3.3.3 Add labels (Functional Method)\n\n# create variable\nz = [1,2,3,4,.5]\nveh_type = ['bicycle', 'motorbike', 'car', 'van', 'stroller']\n\n# generate pie chart\nplt.pie(z, labels=veh_type)\n\n# plot pie chart\nplt.show()\n\n\n\n\n\n\n3.3.4 Add Legend\n\n# create pie chart\nplt.pie(x)\n\n# create a legend located in the best location\nplt.legend(veh_type, loc='best')\n\n# show pot\nplt.show()\n\n\n\n\n\n\n3.3.5Saving a pie chart\n\nplt.pie(x)\nplt.savefig('../../00_figs/pie-chart.png')\nplt.show()"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#time-series",
    "href": "01_blog/2022_11_28_python-beg/index.html#time-series",
    "title": "Python Basics",
    "section": "3.4 Time Series",
    "text": "3.4 Time Series\n\n3.4.0 Load Data\n\n# address\naddress = '../../00_data/Superstore-Sales.csv'\n# create a dataframe of csv file\ndf = pd.read_csv(address, index_col='Order Date', encoding='cp1252', parse_dates=True)\n\n# look at first 5 records\ndf.head()\n\n\n\n\n\n  \n    \n      \n      Row ID\n      Order ID\n      Order Priority\n      Order Quantity\n      Sales\n      Discount\n      Ship Mode\n      Profit\n      Unit Price\n      Shipping Cost\n      Customer Name\n      Province\n      Region\n      Customer Segment\n      Product Category\n      Product Sub-Category\n      Product Name\n      Product Container\n      Product Base Margin\n      Ship Date\n    \n    \n      Order Date\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2010-10-13\n      1\n      3\n      Low\n      6\n      261.5400\n      0.04\n      Regular Air\n      -213.25\n      38.94\n      35.00\n      Muhammed MacIntyre\n      Nunavut\n      Nunavut\n      Small Business\n      Office Supplies\n      Storage & Organization\n      Eldon Base for stackable storage shelf, platinum\n      Large Box\n      0.80\n      10/20/2010\n    \n    \n      2012-10-01\n      49\n      293\n      High\n      49\n      10123.0200\n      0.07\n      Delivery Truck\n      457.81\n      208.16\n      68.02\n      Barry French\n      Nunavut\n      Nunavut\n      Consumer\n      Office Supplies\n      Appliances\n      1.7 Cubic Foot Compact \"Cube\" Office Refrigera...\n      Jumbo Drum\n      0.58\n      10/2/2012\n    \n    \n      2012-10-01\n      50\n      293\n      High\n      27\n      244.5700\n      0.01\n      Regular Air\n      46.71\n      8.69\n      2.99\n      Barry French\n      Nunavut\n      Nunavut\n      Consumer\n      Office Supplies\n      Binders and Binder Accessories\n      Cardinal Slant-DÂ® Ring Binder, Heavy Gauge Vinyl\n      Small Box\n      0.39\n      10/3/2012\n    \n    \n      2011-07-10\n      80\n      483\n      High\n      30\n      4965.7595\n      0.08\n      Regular Air\n      1198.97\n      195.99\n      3.99\n      Clay Rozendal\n      Nunavut\n      Nunavut\n      Corporate\n      Technology\n      Telephones and Communication\n      R380\n      Small Box\n      0.58\n      7/12/2011\n    \n    \n      2010-08-28\n      85\n      515\n      Not Specified\n      19\n      394.2700\n      0.08\n      Regular Air\n      30.94\n      21.78\n      5.94\n      Carlos Soltero\n      Nunavut\n      Nunavut\n      Consumer\n      Office Supplies\n      Appliances\n      Holmes HEPA Air Purifier\n      Medium Box\n      0.50\n      8/30/2010\n    \n  \n\n\n\n\n\n\n3.4.1 Use Sample Method to Create Line Chart\n\n# use sample method\ndf2 = df.sample(n=100, random_state=25, axis=0)\n\n# add labels\nplt.xlabel('Order Date')\nplt.ylabel('Order Quantity')\n\n# add title\nplt.title('Superstore Sales')\n\n# select Order Quantity and plot\ndf2['Order Quantity'].plot()\n\n<AxesSubplot: title={'center': 'Superstore Sales'}, xlabel='Order Date', ylabel='Order Quantity'>"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#statistical-plots",
    "href": "01_blog/2022_11_28_python-beg/index.html#statistical-plots",
    "title": "Python Basics",
    "section": "3.5 Statistical Plots",
    "text": "3.5 Statistical Plots\n\n3.5.1 Scatterplot\n\n# create a scatterplot with darkgray dots of size 150\ncars.plot(kind='scatter', x='hp', y='mpg', c=['darkgray'], s=150)\n\n<AxesSubplot: xlabel='hp', ylabel='mpg'>\n\n\n\n\n\n\n\n3.5.2 Boxplots\n\n# create 2 boxplots with matplotlib\ncars.boxplot(column='mpg', by='am')\ncars.boxplot(column='wt', by='am')\n\n<AxesSubplot: title={'center': 'wt'}, xlabel='am'>"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#arrays",
    "href": "01_blog/2022_11_28_python-beg/index.html#arrays",
    "title": "Python Basics",
    "section": "4.1 Arrays",
    "text": "4.1 Arrays\n\n4.1.1 Creating Arrays\n\na = np.array([1,2,3,4,5,6])\nb = np.array([6,5,4,3,2,1])\na\nb\n\narray([6, 5, 4, 3, 2, 1])\n\n\n\n\n4.1.2 Array Arithimetic\n\na*10\na+b\na-b\na*b\na/b\n\narray([0.16666667, 0.4       , 0.75      , 1.33333333, 2.5       ,\n       6.        ])"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#matricies",
    "href": "01_blog/2022_11_28_python-beg/index.html#matricies",
    "title": "Python Basics",
    "section": "4.2 Matricies",
    "text": "4.2 Matricies\n\n4.2.1 Creating Matricies\n\naa = np.array([[2,3,6],[1,3,5],[10,20,30]])\nbb = np.array([[0,1,2],[3,4,5],[6,7,8]])\naa\nbb\n\narray([[0, 1, 2],\n       [3, 4, 5],\n       [6, 7, 8]])\n\n\n\n\n4.2.2 Multiplying Matricies\n\naa*bb\n\narray([[  0,   3,  12],\n       [  3,  12,  25],\n       [ 60, 140, 240]])\n\n\n\n\n4.2.3 Dot Product of Matricies\n\nnp.dot(aa,bb)\n\narray([[ 45,  56,  67],\n       [ 39,  48,  57],\n       [240, 300, 360]])"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#summary-statistics",
    "href": "01_blog/2022_11_28_python-beg/index.html#summary-statistics",
    "title": "Python Basics",
    "section": "4.3 Summary Statistics",
    "text": "4.3 Summary Statistics\n\n4.3.1 Sum of Column values\n\ncars.sum()\n\ncar_names    Mazda RX4Mazda RX4 WagDatsun 710Hornet 4 Drive...\nmpg                                                      642.9\ncyl                                                        198\ndisp                                                    7383.1\nhp                                                        4694\ndrat                                                    115.09\nwt                                                     102.952\nqsec                                                    571.16\nvs                                                          14\nam                                                          13\ngear                                                       118\ncarb                                                        90\ndtype: object\n\n\n\n\n4.3.2 Sum of Row values\n\ncars.sum(axis=1)\n\n/var/folders/90/4rtssdj16dl23f_f66qj0t3w0000gn/T/ipykernel_1064/1808080884.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n  cars.sum(axis=1)\n\n\n0     328.980\n1     329.795\n2     259.580\n3     426.135\n4     590.310\n5     385.540\n6     656.920\n7     270.980\n8     299.570\n9     350.460\n10    349.660\n11    510.740\n12    511.500\n13    509.850\n14    728.560\n15    726.644\n16    725.695\n17    213.850\n18    195.165\n19    206.955\n20    273.775\n21    519.650\n22    506.085\n23    646.280\n24    631.175\n25    208.215\n26    272.570\n27    273.683\n28    670.690\n29    379.590\n30    694.710\n31    288.890\ndtype: float64\n\n\n\n\n4.3.3 Median\n\ncars.median()\n\n/var/folders/90/4rtssdj16dl23f_f66qj0t3w0000gn/T/ipykernel_1064/2356643283.py:1: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n  cars.median()\n\n\nmpg      19.200\ncyl       6.000\ndisp    196.300\nhp      123.000\ndrat      3.695\nwt        3.325\nqsec     17.710\nvs        0.000\nam        0.000\ngear      4.000\ncarb      2.000\ndtype: float64\n\n\n\n\n4.3.4 Mean\n\ncars.mean()\n\n/var/folders/90/4rtssdj16dl23f_f66qj0t3w0000gn/T/ipykernel_1064/1764053374.py:1: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n  cars.mean()\n\n\nmpg      20.090625\ncyl       6.187500\ndisp    230.721875\nhp      146.687500\ndrat      3.596563\nwt        3.217250\nqsec     17.848750\nvs        0.437500\nam        0.406250\ngear      3.687500\ncarb      2.812500\ndtype: float64\n\n\n\n\n4.3.5 Max\n\ncars.max()\n\ncar_names    Volvo 142E\nmpg                33.9\ncyl                   8\ndisp              472.0\nhp                  335\ndrat               4.93\nwt                5.424\nqsec               22.9\nvs                    1\nam                    1\ngear                  5\ncarb                  8\ndtype: object\n\n\n\n\n4.3.6 Find index value for row with max value\n\nmpg = cars.mpg\nmpg.idxmax()\n\n19\n\n\n\n\n4.3.7 Standard Deviation\n\ncars.std()\n\n/var/folders/90/4rtssdj16dl23f_f66qj0t3w0000gn/T/ipykernel_1064/2703001680.py:1: FutureWarning: The default value of numeric_only in DataFrame.std is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n  cars.std()\n\n\nmpg       6.026948\ncyl       1.785922\ndisp    123.938694\nhp       68.562868\ndrat      0.534679\nwt        0.978457\nqsec      1.786943\nvs        0.504016\nam        0.498991\ngear      0.737804\ncarb      1.615200\ndtype: float64\n\n\n\n\n4.3.8 Variance\n\ncars.var()\n\n/var/folders/90/4rtssdj16dl23f_f66qj0t3w0000gn/T/ipykernel_1064/2053581105.py:1: FutureWarning: The default value of numeric_only in DataFrame.var is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n  cars.var()\n\n\nmpg        36.324103\ncyl         3.189516\ndisp    15360.799829\nhp       4700.866935\ndrat        0.285881\nwt          0.957379\nqsec        3.193166\nvs          0.254032\nam          0.248992\ngear        0.544355\ncarb        2.608871\ndtype: float64\n\n\n\n\n4.3.9 Counts\n\ngear = cars.gear\ngear.value_counts()\n\n3    15\n4    12\n5     5\nName: gear, dtype: int64\n\n\n\n\n4.3.10 Descriptive Statistics\n\ncars.describe()\n\n\n\n\n\n  \n    \n      \n      mpg\n      cyl\n      disp\n      hp\n      drat\n      wt\n      qsec\n      vs\n      am\n      gear\n      carb\n    \n  \n  \n    \n      count\n      32.000000\n      32.000000\n      32.000000\n      32.000000\n      32.000000\n      32.000000\n      32.000000\n      32.000000\n      32.000000\n      32.000000\n      32.0000\n    \n    \n      mean\n      20.090625\n      6.187500\n      230.721875\n      146.687500\n      3.596563\n      3.217250\n      17.848750\n      0.437500\n      0.406250\n      3.687500\n      2.8125\n    \n    \n      std\n      6.026948\n      1.785922\n      123.938694\n      68.562868\n      0.534679\n      0.978457\n      1.786943\n      0.504016\n      0.498991\n      0.737804\n      1.6152\n    \n    \n      min\n      10.400000\n      4.000000\n      71.100000\n      52.000000\n      2.760000\n      1.513000\n      14.500000\n      0.000000\n      0.000000\n      3.000000\n      1.0000\n    \n    \n      25%\n      15.425000\n      4.000000\n      120.825000\n      96.500000\n      3.080000\n      2.581250\n      16.892500\n      0.000000\n      0.000000\n      3.000000\n      2.0000\n    \n    \n      50%\n      19.200000\n      6.000000\n      196.300000\n      123.000000\n      3.695000\n      3.325000\n      17.710000\n      0.000000\n      0.000000\n      4.000000\n      2.0000\n    \n    \n      75%\n      22.800000\n      8.000000\n      326.000000\n      180.000000\n      3.920000\n      3.610000\n      18.900000\n      1.000000\n      1.000000\n      4.000000\n      4.0000\n    \n    \n      max\n      33.900000\n      8.000000\n      472.000000\n      335.000000\n      4.930000\n      5.424000\n      22.900000\n      1.000000\n      1.000000\n      5.000000\n      8.0000"
  },
  {
    "objectID": "01_blog/2022_11_28_python-beg/index.html#summarizing-categorical-data",
    "href": "01_blog/2022_11_28_python-beg/index.html#summarizing-categorical-data",
    "title": "Python Basics",
    "section": "4.4 Summarizing Categorical Data",
    "text": "4.4 Summarizing Categorical Data\n\n4.4.1 Count Carborators of Each Car\n\ncarb = cars.carb\ncarb.value_counts()\n\n4    10\n2    10\n1     7\n3     3\n6     1\n8     1\nName: carb, dtype: int64\n\n\n\n\n4.4.2 Group By Gear\n\n# subset data\ncars_cat = cars[['cyl', 'vs', 'am', 'gear', 'carb']]\n# Group by gear\ngears_group = cars_cat.groupby('gear')\ngears_group.describe()\n\n\n\n\n\n  \n    \n      \n      cyl\n      vs\n      ...\n      am\n      carb\n    \n    \n      \n      count\n      mean\n      std\n      min\n      25%\n      50%\n      75%\n      max\n      count\n      mean\n      ...\n      75%\n      max\n      count\n      mean\n      std\n      min\n      25%\n      50%\n      75%\n      max\n    \n    \n      gear\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      3\n      15.0\n      7.466667\n      1.187234\n      4.0\n      8.0\n      8.0\n      8.0\n      8.0\n      15.0\n      0.200000\n      ...\n      0.0\n      0.0\n      15.0\n      2.666667\n      1.175139\n      1.0\n      2.0\n      3.0\n      4.0\n      4.0\n    \n    \n      4\n      12.0\n      4.666667\n      0.984732\n      4.0\n      4.0\n      4.0\n      6.0\n      6.0\n      12.0\n      0.833333\n      ...\n      1.0\n      1.0\n      12.0\n      2.333333\n      1.302678\n      1.0\n      1.0\n      2.0\n      4.0\n      4.0\n    \n    \n      5\n      5.0\n      6.000000\n      2.000000\n      4.0\n      4.0\n      6.0\n      8.0\n      8.0\n      5.0\n      0.200000\n      ...\n      1.0\n      1.0\n      5.0\n      4.400000\n      2.607681\n      2.0\n      2.0\n      4.0\n      6.0\n      8.0\n    \n  \n\n3 rows Ã— 32 columns\n\n\n\n\n\n4.4.3 Transforming Variables to Categorical Data type\n\n# create new column\ncars['group'] = pd.Series(cars.gear, dtype = 'category')\n# look at new variable \ncars['group'].dtypes\n# look at distribution\ncars['group'].value_counts()\n\n3    15\n4    12\n5     5\nName: group, dtype: int64\n\n\n\n\n4.4.4 Describe Categorical Data with Crosstabs\n\npd.crosstab(cars['am'], cars['gear'])\n\n\n\n\n\n  \n    \n      gear\n      3\n      4\n      5\n    \n    \n      am\n      \n      \n      \n    \n  \n  \n    \n      0\n      15\n      4\n      0\n    \n    \n      1\n      0\n      8\n      5"
  },
  {
    "objectID": "01_blog/2022_06_27_Predicting-Stock-Prices/index.html",
    "href": "01_blog/2022_06_27_Predicting-Stock-Prices/index.html",
    "title": "Predicting Stock Prices",
    "section": "",
    "text": "1. Background\nDuring the summer of 2021 I took a business fiance class, and learned a lot about stocks and the stock market. Most of my projects centered around MicroVision which is a research and development company creating the newest Lidar technology for autonomous vehicles.\n\n\n2. Set Up\nThis analysis will use three packages:\n\ntidyverse: to clean the data\nquantmod: to get data from yahoo finace\nprophet: to make predictions\n\n\n# Load Libraries \nlibrary(quantmod)\nlibrary(tidyverse)  \nlibrary(prophet) \n\nThere are a few places that quantmod can pull data from, but the default which I will be using is Yahoo Finace. You can specify this with src=\"yahoo\". Use ?getSymbols for more information on this functions parameters.\nNote: If you are having issues with quantmod try re-installing it.\n\nquantmod::getSymbols(\"MVIS\", src=\"yahoo\")\n\n[1] \"MVIS\"\n\n\n\n\n3. quantmod Functions\nRight away we quantmod functions like chartSeries() can be used to look at various plots of MicroVision stocks. Below are a few examples showing various subsets of data from 2019 - 2022. As well as different types such as bar, line, candlesticks, and auto. The last graph also includes addBBands(), addMomentum() and addROC(). Use ? with any of these functions to find out more details on their parameters.\n\nchartSeries(MVIS, type = \"candlesticks\", subset = '2019-09-01::2019-12-31', theme= chartTheme('white'))\n\n\n\nchartSeries(MVIS, type = \"bar\", subset = '2020', theme= chartTheme('white'))\n\n\n\nchartSeries(MVIS, type = \"line\", subset = '2021', theme= chartTheme('white'))\n\n\n\nchartSeries(MVIS, type = \"auto\", subset = '2022', theme= chartTheme('white'))\n\n\n\nchartSeries(MVIS, type = \"auto\", subset = '2022-06', theme= chartTheme('white'))\n\n\n\naddBBands(n=20,sd=2)\n\n\n\naddMomentum(n=1)\n\n\n\naddROC(n=7)\n\n\n\n\n\n\n4. Tidy Data\n\nhead(MVIS)\n\n           MVIS.Open MVIS.High MVIS.Low MVIS.Close MVIS.Volume MVIS.Adjusted\n2007-01-03     25.68     26.40    24.16      24.56      106750         24.56\n2007-01-04     25.76     30.48    25.44      29.92      703538         29.92\n2007-01-05     30.00     31.44    28.16      29.60      333425         29.60\n2007-01-08     31.92     32.64    30.24      31.44      341050         31.44\n2007-01-09     30.96     31.20    29.20      29.36      242725         29.36\n2007-01-10     29.68     30.80    27.76      29.68      169038         29.68\n\n\nYou might notice that the date column doesnâ€™t have a column name, and that is because it is being read as the names of the rows. To change this I will first need to change the data into a data frame, and then change the row names into a column with the function rownames_to_column(). It is then important to assign the date series column the name ds. That is how the prophet package will recognize it, so this will save us the step of renaming this later on.\n\nMVIS <- base::data.frame(MVIS)\nMVIS <- tibble::rownames_to_column(MVIS, \"ds\")\nutils::head(MVIS)\n\n          ds MVIS.Open MVIS.High MVIS.Low MVIS.Close MVIS.Volume MVIS.Adjusted\n1 2007-01-03     25.68     26.40    24.16      24.56      106750         24.56\n2 2007-01-04     25.76     30.48    25.44      29.92      703538         29.92\n3 2007-01-05     30.00     31.44    28.16      29.60      333425         29.60\n4 2007-01-08     31.92     32.64    30.24      31.44      341050         31.44\n5 2007-01-09     30.96     31.20    29.20      29.36      242725         29.36\n6 2007-01-10     29.68     30.80    27.76      29.68      169038         29.68\n\n\nIt will also be important that the ds column is read as date values instead of character value.\n\nMVIS <- MVIS %>% \n  dplyr::mutate(ds = as.Date(ds))\nutils::head(MVIS)\n\n          ds MVIS.Open MVIS.High MVIS.Low MVIS.Close MVIS.Volume MVIS.Adjusted\n1 2007-01-03     25.68     26.40    24.16      24.56      106750         24.56\n2 2007-01-04     25.76     30.48    25.44      29.92      703538         29.92\n3 2007-01-05     30.00     31.44    28.16      29.60      333425         29.60\n4 2007-01-08     31.92     32.64    30.24      31.44      341050         31.44\n5 2007-01-09     30.96     31.20    29.20      29.36      242725         29.36\n6 2007-01-10     29.68     30.80    27.76      29.68      169038         29.68\n\n\nLastly to create a data frame for the prophet package with just the date and closing costs. It is important to rename the closing cost column to y.\n\n# CLosing Data \nMVIS_close <- base::data.frame(ds = MVIS$ds, y = MVIS$MVIS.Close)\nutils::head(MVIS_close)\n\n          ds     y\n1 2007-01-03 24.56\n2 2007-01-04 29.92\n3 2007-01-05 29.60\n4 2007-01-08 31.44\n5 2007-01-09 29.36\n6 2007-01-10 29.68\n\n\n\n\n5. Prophet Functions\nUsing the prophet() function I can create a model of the data. Then I can use make_future_dataframe() to make a predicted model of the next three years.\n\n# call prophet function to fit the model \nModel1 <- prophet::prophet(MVIS_close,\n                           daily.seasonality=TRUE)\nFuture1 <- prophet::make_future_dataframe(Model1,\n                                          periods = 365*3)\nutils::tail(Future1)\n\n             ds\n5107 2025-12-08\n5108 2025-12-09\n5109 2025-12-10\n5110 2025-12-11\n5111 2025-12-12\n5112 2025-12-13\n\n\n\n\n6. Predict Function\nThe predict() function is a stats function that uses various model fitting functions to predict future results.\n\n# Forecast Proper \nForecast1 <- stats::predict(Model1, Future1)\n# Forecast Values \npredict_date <- Forecast1$ds[length(Forecast1$ds)]\npredict_value <- Forecast1$yhat[length(Forecast1$yhat)]\npredict_lower <- Forecast1$yhat_lower[length(Forecast1$yhat_lower)]\npredict_upper <- Forecast1$yhat_upper[length(Forecast1$yhat_upper)]\n\nThis model predicts that on 2025-12-13, the value of MicroVision stock will be about 11.6995669. This value is in a range between -7.8638649 and 29.3207726. Note that this range is so large because of the long time period on which it is making the prediction.\n\n\n7. Plot Model\nBelow is an interactive plot that shows the actual values in black, and the predicted values in blue. The grey graph underneath can be adjusted to look at a specific window of time.\n\nprophet::dyplot.prophet(Model1, Forecast1)\n\n\n\n\n\n\n\n8. Plot Componets\nLastly using the prophet_plot_components() function can be used to see yearly, weekly, seasonally, and daily trends.\n\nprophet::prophet_plot_components(Model1, Forecast1)\n\n\n\n\nLooking at daily trends it appears that MicroVision was on the decline after 2010 for some time, but has been trading up since about 2019.\nLooking at the weekly trends, it obvious MicroVision is popular during the Monday - Friday trading week, however looking at the time trends the stock is most popular at the beginning and end of the day.\nThe third graph shows us that MicroVision does not seem to preform well in the first quarter of the year, but picks up around May until it starts to drop off again around November.\n\n\n9. Sources\nEasily Import Financial Data to R with Quantmod\nTechnical Analysis with R - Ch.7 Quantmod\nForecasting Bitcoin Prices Using Prophet in R"
  },
  {
    "objectID": "01_blog/2022_07_18_Reactable/index.html",
    "href": "01_blog/2022_07_18_Reactable/index.html",
    "title": "Reactable",
    "section": "",
    "text": "1. Set Up\nThis post will use three packages:\n\nrvest: to harvest the data.\ndplyr: to join and tidy data.\nreactable: to make interactive tables.\n\n\nlibrary(rvest) \nlibrary(dplyr)\nlibrary(reactable)\n\n\n\n2. Havest the Data with rvest\nUsing data from Basketball Reference and the rvest package I can harvest current data without having to save CSVâ€™s. For this table I will be pulling in the final two teams which competed in the 2022 NBA Finals:\n\nGolden State Warriors\nBoston Celtics\n\n\n# team name\ngsw <- \"Golden State Warriors\"\nbc <- \"Boston Celtics\"\n\n# team slug\ngsw_slug <- \"GSW\"\nbc_slug <- \"BOS\"\n\n# url\ngsw_url <- base::paste0(\"https://www.basketball-reference.com/teams/\",\n                        gsw_slug,\"/2022.html\")\nbc_url <- base::paste0(\"https://www.basketball-reference.com/teams/\",\n                       bc_slug,\"/2022.html\")\n\nThere is a lot of data available on Basketball Reference, but for this table I will only be looking at each teams 2022 total stats.\n\n# harvest data\ngsw_ttl_stat <- gsw_url %>%\n  read_html %>%\n  html_node(\"#totals\") %>% \n  html_table()\n\nbc_ttl_stat <- bc_url %>%\n  read_html %>%\n  html_node(\"#totals\") %>% \n  html_table()\n# look at data\nutils::head(gsw_ttl_stat)\n\n# A tibble: 6 Ã— 28\n     Rk ``       Age     G    GS    MP    FG   FGA `FG%`  `3P` `3PA` `3P%`  `2P`\n  <int> <chr>  <int> <int> <int> <int> <int> <int> <dbl> <int> <int> <dbl> <int>\n1     1 Andreâ€¦    26    73    73  2329   475  1019 0.466   157   399 0.393   318\n2     2 Jordaâ€¦    22    76    51  2283   474  1058 0.448   211   580 0.364   263\n3     3 Stephâ€¦    33    64    64  2211   535  1224 0.437   285   750 0.38    250\n4     4 Kevonâ€¦    25    82    80  1732   208   364 0.571     0     1 0       208\n5     5 Otto â€¦    28    63    15  1396   193   416 0.464    80   216 0.37    113\n6     6 Draymâ€¦    31    46    44  1329   135   257 0.525    16    54 0.296   119\n# â€¦ with 15 more variables: `2PA` <int>, `2P%` <dbl>, `eFG%` <dbl>, FT <int>,\n#   FTA <int>, `FT%` <dbl>, ORB <int>, DRB <int>, TRB <int>, AST <int>,\n#   STL <int>, BLK <int>, TOV <int>, PF <int>, PTS <int>\n\nutils::head(bc_ttl_stat)\n\n# A tibble: 6 Ã— 28\n     Rk ``       Age     G    GS    MP    FG   FGA `FG%`  `3P` `3PA` `3P%`  `2P`\n  <int> <chr>  <int> <int> <int> <int> <int> <int> <dbl> <int> <int> <dbl> <int>\n1     1 Jaysoâ€¦    23    76    76  2731   708  1564 0.453   230   651 0.353   478\n2     2 Marcuâ€¦    27    71    71  2296   300   718 0.418   119   360 0.331   181\n3     3 Jayleâ€¦    25    66    66  2220   576  1217 0.473   166   464 0.358   410\n4     4 Al Hoâ€¦    35    69    69  2005   266   569 0.467    89   265 0.336   177\n5     5 Grantâ€¦    23    77    21  1875   205   432 0.475   106   258 0.411    99\n6     6 Roberâ€¦    24    61    61  1804   271   368 0.736     0     1 0       271\n# â€¦ with 15 more variables: `2PA` <int>, `2P%` <dbl>, `eFG%` <dbl>, FT <int>,\n#   FTA <int>, `FT%` <dbl>, ORB <int>, DRB <int>, TRB <int>, AST <int>,\n#   STL <int>, BLK <int>, TOV <int>, PF <int>, PTS <int>\n\n\n\n\n3. Tidy Data\nTo tidy the data I want to do 3 things:\n\nRename column 2 to â€˜Nameâ€™.\nAdd a column with the team name.\nJoin two tables into one.\n\n\n# remane \nbase::names(gsw_ttl_stat)[2] <- \"Name\"\nbase::names(bc_ttl_stat)[2] <- \"Name\"\n\n# add column\ngsw_ttl_stat$Team <- gsw\nbc_ttl_stat$Team <- bc\n\n# merge tables\ntotal_stats <- dplyr::full_join(gsw_ttl_stat, bc_ttl_stat)\n\n#view data  \nutils::head(total_stats)\n\n# A tibble: 6 Ã— 29\n     Rk Name     Age     G    GS    MP    FG   FGA `FG%`  `3P` `3PA` `3P%`  `2P`\n  <int> <chr>  <int> <int> <int> <int> <int> <int> <dbl> <int> <int> <dbl> <int>\n1     1 Andreâ€¦    26    73    73  2329   475  1019 0.466   157   399 0.393   318\n2     2 Jordaâ€¦    22    76    51  2283   474  1058 0.448   211   580 0.364   263\n3     3 Stephâ€¦    33    64    64  2211   535  1224 0.437   285   750 0.38    250\n4     4 Kevonâ€¦    25    82    80  1732   208   364 0.571     0     1 0       208\n5     5 Otto â€¦    28    63    15  1396   193   416 0.464    80   216 0.37    113\n6     6 Draymâ€¦    31    46    44  1329   135   257 0.525    16    54 0.296   119\n# â€¦ with 16 more variables: `2PA` <int>, `2P%` <dbl>, `eFG%` <dbl>, FT <int>,\n#   FTA <int>, `FT%` <dbl>, ORB <int>, DRB <int>, TRB <int>, AST <int>,\n#   STL <int>, BLK <int>, TOV <int>, PF <int>, PTS <int>, Team <chr>\n\ntotal_stats\n\n# A tibble: 47 Ã— 29\n      Rk Name    Age     G    GS    MP    FG   FGA `FG%`  `3P` `3PA` `3P%`  `2P`\n   <int> <chr> <int> <int> <int> <int> <int> <int> <dbl> <int> <int> <dbl> <int>\n 1     1 Andrâ€¦    26    73    73  2329   475  1019 0.466   157   399 0.393   318\n 2     2 Jordâ€¦    22    76    51  2283   474  1058 0.448   211   580 0.364   263\n 3     3 Stepâ€¦    33    64    64  2211   535  1224 0.437   285   750 0.38    250\n 4     4 Kevoâ€¦    25    82    80  1732   208   364 0.571     0     1 0       208\n 5     5 Ottoâ€¦    28    63    15  1396   193   416 0.464    80   216 0.37    113\n 6     6 Drayâ€¦    31    46    44  1329   135   257 0.525    16    54 0.296   119\n 7     7 Damiâ€¦    29    63     5  1256   169   383 0.441    63   187 0.337   106\n 8     8 Garyâ€¦    29    71    16  1247   212   344 0.616    43   120 0.358   169\n 9     9 Jonaâ€¦    19    70    12  1185   236   460 0.513    50   149 0.336   186\n10    10 Nemaâ€¦    33    71     0  1142   160   342 0.468    54   149 0.362   106\n# â€¦ with 37 more rows, and 16 more variables: `2PA` <int>, `2P%` <dbl>,\n#   `eFG%` <dbl>, FT <int>, FTA <int>, `FT%` <dbl>, ORB <int>, DRB <int>,\n#   TRB <int>, AST <int>, STL <int>, BLK <int>, TOV <int>, PF <int>, PTS <int>,\n#   Team <chr>\n\n\n\n\n4. Reactable\nNow to make a simple reactable I will do 7 things:\n\nGroup by â€œTeamâ€ name.\nDefine column names.\nInclude boarders around the table and every cell.\nInclude highlight rows that are hovered over.\nMake filterable.\nMake Searchable.\nHave the two teams be the minimum number of rows initally shown.\n\n\nreactable(\n  total_stats,\n  groupBy = \"Team\",\n  columns = list(\n    Rk = colDef(name = \"Rank\"),\n    G = colDef(name = \"Games\"),\n    MP = colDef(name = \"Minutes Played\"),\n    FG = colDef(name = \"Field Goals\"),\n    `3P` = colDef(name = \"3 Point Goals\"),\n    `2P` = colDef(name = \"2 Point Goals\"),\n    FT = colDef(name = \"Free Throws\"),\n    AST = colDef(name = \"Assists\"),\n    STL = colDef(name = \"Steals\"),\n    BLK = colDef(name = \"Blocks\"),\n    PTS = colDef(name = \"Points\"),\n    TOV = colDef(name = \"Turnovers\"),\n    PF = colDef(name = \"Personal Fouls\")\n  ),\n  bordered = TRUE,\n  highlight = TRUE,\n  filterable = TRUE,\n  searchable = TRUE,\n  minRows = 2\n  )\n\n\n\n\n\n\n\n\n5. Sources\nNBA Analytics Tutorial: Using R to Display Player Career Stats\nReactable"
  },
  {
    "objectID": "01_blog/2022_07_25_Tidyverse-P1/index.html",
    "href": "01_blog/2022_07_25_Tidyverse-P1/index.html",
    "title": "Tidyverse Style Guide (Part 1)",
    "section": "",
    "text": "This is part 1 of my notes on the tidyverse style guide."
  },
  {
    "objectID": "01_blog/2022_07_25_Tidyverse-P1/index.html#files",
    "href": "01_blog/2022_07_25_Tidyverse-P1/index.html#files",
    "title": "Tidyverse Style Guide (Part 1)",
    "section": "2.1 Files",
    "text": "2.1 Files\n\nnames are meaningful and use letters, numbers, _, and/or -.\navoid special characters in files names.\nif more than 10 files then left pad with a zero (i.e.Â 00, 01, 02, 03,â€¦)\nrename files instead of attempting 02a, 02b, and so on.\npay attention to capitalization.\nload all packages at once in the beginning of the file.\nuse - and = to break up file into readable chunks.\n\n\n# Load data ---------------------------\n\n# Plot data ---------------------------"
  },
  {
    "objectID": "01_blog/2022_07_25_Tidyverse-P1/index.html#syntax",
    "href": "01_blog/2022_07_25_Tidyverse-P1/index.html#syntax",
    "title": "Tidyverse Style Guide (Part 1)",
    "section": "2.2 Syntax",
    "text": "2.2 Syntax\n\n2.2.1 Object Names\n\nVariables and function names should use lowercase letters, numbers and _ (no camel case).\nBase R uses dots in function and class names (data.frame).\nVariable names should be names and nouns.\nFunction names should be verbs.\nNames should be concise and meaningful.\nAvoid re-using names of common function and variables.\n\n\n\n2.2.2 Spacing\n\nPut a space after a common, never before.\nDo not put spaces inside or outside parentheses for regular functions : mean(x, na.rm = TRUE).\nPut a space before and after () when using if, for, or while.\nPlace a space after () used for function arguments : function(x) {}.\n\n\n# if (debug) {\n#   show(x)\n# }\n\n\nThe embracing operator, {{ }}, should always have inner spaces to help emphasize its special behavior.\nMost infix operators (==, +, -, <-, etc.) should always be surrounded by spaces.\nExceptions being:\n\nThe operators with high precedence: ::, :::, $, @, [, [[, ^, unary -, unary +, and :.\nSingle-sided formulas when the right-hand side is a single identifier: call(!!xyz).\nWhen used in tidy evaluation !! (bang-bang) and !!! (bang-bang-bang) (because have precedence equivalent to unary -/+).\nThe helper operator: package?stats.\n\nadding extra spaces is ok if it improves alignment of = or <-.\n\n\n\n2.2.3 Function Calls\n\nWhen you call a function omit the names of data arguemnts (such as x= because it is used so commonly).\nIf you override the default value of an argument, use the full name.\nAvoid assignments in function calls.\n\nException: function that capture side-effects: output <- capture.output(x <- f()).\n\n\n\n\n2.2.4 Control Flow\n\nFor {} brackets:\n\n{ should be the last character on the line.\nContents should be indented by two spaces.\n} should be the first character on the line.\nElse should be on the same line as } (if used).\n\n{} define the most important hierarchy of R code.\nAlways use && and || inside an if clause and never & and |.\nIf you want to rewrite a simple but lengthy if block:\n\n\nif (x > 10) {\n  message <- \"big\"\n} else {\n  message <- \"small\"\n}\n\nJust write it all on one line:\n\nmessage <- if (x > 10) \"big\" else \"small\"\n\n\nit is okay to drop curly braces for very simple statements that fit on one line as long as they donâ€™t have side-effects.\nFunction calls that affect control flow (like return(), stop() or continue) should always go in their own {} block.\nAvoid implicit type coercion (e.g.Â from numeric to logical) in if statements:\n\n\n# Good\nif (length(x) > 0) {\n  # do something\n}\n\nNULL\n\n# Bad\nif (length(x)) {\n  # do something\n}\n\nNULL\n\n\n\nAvoid position-based switch() statements.\nEach element should go on its own line.\nProvided a fall-through arrow, unless you have previously validate the input.\n\n\nswitch(x, \n  a = 0,\n  b = 1, \n  c = 2,\n  stop(\"Unknown `x`\", call. = FALSE)\n)\n\n[1] 0\n\n\n\n\n2.2.5 Long Lines\n\nLimit code to 80 characters per line. This fits comfortably on a printed page with a reasonably sized font.\n\n\n# # Good\n# do_something_very_complicated(\n#   something = \"that\",\n#   requires = many,\n#   arguments = \"some of which may be long\"\n# )\n# \n# # Bad\n# do_something_very_complicated(\"that\", requires, many, arguments,\n#                               \"some of which may be long\"\n#                               )\n\n\nYou may also place several arguments on the same line if they are closely related to each other, e.g., strings in calls to paste() or stop().\n\n\n\n2.2.6 Semicolons\n\nDonâ€™t put ; at the end of a line, and donâ€™t use ; to put multiple commands on one line.\n\n\n\n2.2.7 Assignment\n\nUse <-, not =, for assignment.\n\n\n\n2.2.8 Data\n\nUse \", not ', for quoting text. The only exception is when the text already contains double quotes and no single quotes.\nPrefer TRUE and FALSE over T and F.\n\n\n\n2.2.9 Comments\n\nEach line of a comment should begin with the comment symbol and a single space.\nIn data analysis code, use comments to record important findings and analysis decisions.\nIf you need comments to explain what your code is doing, consider rewriting your code to be clearer.\nIf you discover that you have more comments than code, consider switching to R Markdown."
  },
  {
    "objectID": "01_blog/2022_07_25_Tidyverse-P1/index.html#functions",
    "href": "01_blog/2022_07_25_Tidyverse-P1/index.html#functions",
    "title": "Tidyverse Style Guide (Part 1)",
    "section": "2.3 Functions",
    "text": "2.3 Functions\n\n2.3.1 Naming\n\nStrive to use verbs for function names.\n\n\n\n2.3.2 Long Lines\n\nPrefer function-indent style to double-indent style when it fits.\n\n\n# Function-indent --------------------------------------\nlong_function_name <- function(a = \"a long argument\",\n                               b = \"another argument\",\n                               c = \"another long argument\") {\n  # As usual code is indented by two spaces.\n}\n\n# Double-indent ----------------------------------------\nlong_function_name <- function(\n    a = \"a long argument\",\n    b = \"another argument\",\n    c = \"another long argument\") {\n  # As usual code is indented by two spaces.\n}\n\n\nIf a function argument canâ€™t fit on a single line, this is a sign you should rework the argument to keep it short and sweet.\n\n\n\n2.3.3 return()\n\nOnly use return() for early returns. Otherwise, rely on R to return the result of the last evaluated expression.\n\n\n# Good\nfind_abs <- function(x) {\n  if (x > 0) {\n    return(x)\n  }\n  x * -1\n}\nadd_two <- function(x, y) {\n  x + y\n}\n\n# Bad\nadd_two <- function(x, y) {\n  return(x + y)\n}\n\n\nReturn statements should always be on their own line because they have important effects on the control flow.\nIf your function is called primarily for its side-effects (like printing, plotting, or saving to disk), it should return the first argument invisibly. This makes it possible to use the function as part of a pipe.\n\n\n\n2.3.4 Comments\n\nIn code, use comments to explain the â€œwhyâ€ not the â€œwhatâ€ or â€œhowâ€.\nComments should be in sentence case, and only end with a full stop if they contain at least two sentences.\n\n\n# Good -----------------------------------------\n\n# Objects like data frames are treated as leaves\n\n# Do not use `is.list()`. Objects like data frames \n# must be treated as leaves.\n\n# Bad -----------------------------------------\n\n# objects like data frames are treated as leaves\n\n# Objects like data frames are treated as leaves."
  },
  {
    "objectID": "01_blog/2022_07_25_Tidyverse-P1/index.html#pipes",
    "href": "01_blog/2022_07_25_Tidyverse-P1/index.html#pipes",
    "title": "Tidyverse Style Guide (Part 1)",
    "section": "2.4 Pipes",
    "text": "2.4 Pipes\n\n2.4.1 Introduction\n\nReserve pipes for a sequence of steps applied to one primary object.\nAvoid using pipes when there are meaningful intermediate objects that could be given informative names.\n\n\n\n2.4.2 Withespace\n\n%>% should always have a space before it, and should usually be followed by a new line. After the first step, each line should be indented by two spaces.\n\n\n\n2.4.3 Long Lines\n\nIf the arguments to a function donâ€™t all fit on one line, put each argument on its own line and indent.\n\n\n\n2.4.4 Short Pipes\n\nA one-step pipe can stay on one line, but unless you plan to expand it later on, you should consider rewriting it to a regular function call.\nSometimes itâ€™s useful to include a short pipe as an argument to a function in a longer pipe. Carefully consider whether the code is more readable with a short inline pipe (which doesnâ€™t require a lookup elsewhere) or if itâ€™s better to move the code outside the pipe and give it an evocative name.\n\n\n# Good\n# x %>%\n#   select(a, b, w) %>%\n#   left_join(y %>% select(a, b, v), by = c(\"a\", \"b\"))\n# \n# # Better\n# x_join <- x %>% select(a, b, w)\n# y_join <- y %>% select(a, b, v)\n# left_join(x_join, y_join, by = c(\"a\", \"b\"))\n\n\n\n2.4.5 No Arguments\n\nmagrittr allows you to omit () on functions that donâ€™t have arguments. Avoid this feature.\n\n\n\n2.4.6 Assignment\nThere are three acceptable forms of assignment:\n\nVariable name and assignment on separate lines:\n\n\niris_long <-\n  iris %>%\n  gather(measure, value, -Species) %>%\n  arrange(-value)\n\n\nVariable name and assignment on the same line:\n\n\niris_long <- iris %>%\n  gather(measure, value, -Species) %>%\n  arrange(-value)\n\n\nAssignment at the end of the pipe with ->:\n\n\niris %>%\n  gather(measure, value, -Species) %>%\n  arrange(-value) ->\n  iris_long\n\n\nThe magrittr package provides the %<>% operator as a shortcut for modifying an object in place. Avoid this operator."
  },
  {
    "objectID": "01_blog/2022_07_25_Tidyverse-P1/index.html#ggplot2",
    "href": "01_blog/2022_07_25_Tidyverse-P1/index.html#ggplot2",
    "title": "Tidyverse Style Guide (Part 1)",
    "section": "2.5 ggplot2",
    "text": "2.5 ggplot2\n\n2.5.1 Introduction\n\nStyling suggestions for + used to separate ggplot2 layers are very similar to those for %>% in pipelines.\n\n\n\n2.5.2 Whitespace\n\n+ should always have a space before it, and should be followed by a new line.\nIf you are creating a ggplot off of a dplyr pipeline, there should only be one level of indentation.\n\n\n\n2.5.3 Long lines\n\nIf the arguments to a ggplot2 layer donâ€™t all fit on one line, put each argument on its own line and indent.\nggplot2 allows you to do data manipulation, such as filtering or slicing, within the data argument. Avoid this, and instead do the data manipulation in a pipeline before starting plotting.\n\n\nTo be continued â€¦"
  },
  {
    "objectID": "01_blog/2022_11_21_Quartro/index.html",
    "href": "01_blog/2022_11_21_Quartro/index.html",
    "title": "Quarto Links",
    "section": "",
    "text": "1. Creating a Blog with Quatro\nCreating a blog with Quarto in 10 steps - Bea Milz\nInstalling and Configuring Python with RStudio\nQuarto: Creating a Blog Documentation\nA Quarto tip a day\n\n\n2. Quartro Blogs and their Github Repos\nBea Milz: repo\nDaniel Tran: Repo\nDanielle Navarro - Notes from a data witch: repo\nRober Mitchell: Repo\nSam Csik: Repo\nTed Landeras, PhD: repo\n\n\nMore Blogs (For Inspiration)\nThese blogs are either not made with quarto, or I couldnâ€™t find their github repositories.\nAlicia Johnson (Made with blogdown)\nAllison Hill, PhD\nJulia Silge: Repo (Made with Blogdown and Hugo)\nMachine Learning Mastery!\nNan Xiao: Repo\nTanner Heffner: Repo (Made with Svelte)"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "R\n\n\nWeb-Scraping\n\n\nNBA\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nStatistics\n\n\nLinear Regression\n\n\n\n\n\n\n\n\n\n\n\nDec 5, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nPython\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\nNov 28, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nQuarto\n\n\n\n\n\n\n\n\n\n\n\nNov 21, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nNBA\n\n\nWeb-Scraping\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nMath\n\n\nProof\n\n\n\n\n\n\n\n\n\n\n\nOct 31, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nBayes\n\n\n\n\n\n\n\n\n\n\n\nAug 22, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJul 25, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nNBA\n\n\nWeb-Scraping\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\n\nJul 18, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nStatistics\n\n\n\n\n\n\n\n\n\n\n\nJun 20, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nGeometry\n\n\n\n\n\n\n\n\n\n\n\nMay 30, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAbstract Math\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\n\nApr 25, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nNLP\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\nApr 18, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAbstract Math\n\n\n\n\n\n\n\n\n\n\n\nMar 28, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nGeometry\n\n\n\n\n\n\n\n\n\n\n\nMar 21, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\nFeb 21, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nGeometry\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nMath\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2022\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nLinear Regression\n\n\n\n\n\n\n\n\n\n\n\nDec 20, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nProof\n\n\nStatistics\n\n\nLinear Regression\n\n\n\n\n\n\n\n\n\n\n\nNov 29, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nStatistics\n\n\n\n\n\n\n\n\n\n\n\nNov 22, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nMath\n\n\nAbstract Math\n\n\n\n\n\n\n\n\n\n\n\nOct 25, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nConditional Probabilty\n\n\nTree Diagrams\n\n\nStatistics\n\n\n\n\n\n\n\n\n\n\n\nOct 18, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nGenerative Art\n\n\n\n\n\n\n\n\n\n\n\nSep 27, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\ntidycensus\n\n\nAPI\n\n\n\n\n\n\n\n\n\n\n\nSep 20, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nData Visuals\n\n\n\n\n\n\n\n\n\n\n\nAug 30, 2021\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nQuarto\n\n\n\n\n\n\n\n\n\n\n\nAug 23, 2021\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "01_blog/2022_08_22_Bayes-Rules/index.html",
    "href": "01_blog/2022_08_22_Bayes-Rules/index.html",
    "title": "Bayes Rules! - Salt Lake City R User Group",
    "section": "",
    "text": "Alicia Johnson led this R User Connect Philadelphia to discus the book she co-authored, Bayes Rules!."
  },
  {
    "objectID": "01_blog/2022_08_22_Bayes-Rules/index.html#alicia-johnson",
    "href": "01_blog/2022_08_22_Bayes-Rules/index.html#alicia-johnson",
    "title": "Bayes Rules! - Salt Lake City R User Group",
    "section": "1.1. Alicia Johnson",
    "text": "1.1. Alicia Johnson\n\nStatistics Professor.\nAuthor of Bayes Rules!."
  },
  {
    "objectID": "01_blog/2022_08_22_Bayes-Rules/index.html#materials",
    "href": "01_blog/2022_08_22_Bayes-Rules/index.html#materials",
    "title": "Bayes Rules! - Salt Lake City R User Group",
    "section": "1.2. Materials",
    "text": "1.2. Materials\nSlides\nGithub Repository"
  },
  {
    "objectID": "01_blog/2022_08_22_Bayes-Rules/index.html#what-does-pheads0.5-mean",
    "href": "01_blog/2022_08_22_Bayes-Rules/index.html#what-does-pheads0.5-mean",
    "title": "Bayes Rules! - Salt Lake City R User Group",
    "section": "2.1. What does P(heads)=0.5 mean?",
    "text": "2.1. What does P(heads)=0.5 mean?\n\nIf I flip this coin over and over, roughly 50% will be heads.\nHeads and Tails are equally plausible.\nBoth a and b make sense.\n\n\nScores: a = 1, b = 3, c = 2\nMajority Responses: C\n\n\nFrequentist Philosophy\n\nlong run outcome\n\nBayesian Philosophy\n\nrelative probability of events\n\nPragmatic Philosophy\n\nboth interpretations make sense"
  },
  {
    "objectID": "01_blog/2022_08_22_Bayes-Rules/index.html#what-does-pcandidate-a-wins-0.8-mean",
    "href": "01_blog/2022_08_22_Bayes-Rules/index.html#what-does-pcandidate-a-wins-0.8-mean",
    "title": "Bayes Rules! - Salt Lake City R User Group",
    "section": "2.2 What does P(candidate A wins) = 0.8 mean?",
    "text": "2.2 What does P(candidate A wins) = 0.8 mean?\n\nIf we observe this election over and over, candidate A will win roughly 80% of the time.\nCandidate A is much more likely to win than to lose (4 times more likely).\nThe pollsterâ€™s calculation is wrong.\n\n\nMajority Response: B\nScores: a = 1, b = 3, c = 1\n\n\nFreq.\nBayes\nFreq.\n\nthe event cannot be repeated over and over again"
  },
  {
    "objectID": "01_blog/2022_08_22_Bayes-Rules/index.html#alicia-claims-she-can-predict-the-outcome-of-a-coin-flip.-mine-claims-she-can-distinguish-between-a-crown-burger-and-a-vegan-alternative.-both-succeed-in-10-out-of-10-trials.-what-do-you-conclude",
    "href": "01_blog/2022_08_22_Bayes-Rules/index.html#alicia-claims-she-can-predict-the-outcome-of-a-coin-flip.-mine-claims-she-can-distinguish-between-a-crown-burger-and-a-vegan-alternative.-both-succeed-in-10-out-of-10-trials.-what-do-you-conclude",
    "title": "Bayes Rules! - Salt Lake City R User Group",
    "section": "2.3 Alicia claims she can predict the outcome of a coin flip. Mine claims she can distinguish between a Crown Burger and a Vegan Alternative. Both succeed in 10 out of 10 trials. What do you conclude?",
    "text": "2.3 Alicia claims she can predict the outcome of a coin flip. Mine claims she can distinguish between a Crown Burger and a Vegan Alternative. Both succeed in 10 out of 10 trials. What do you conclude?\n\nYouâ€™re still more confident in Mineâ€™s claim than Aliciaâ€™s claim.\nThe evidence supporting Mineâ€™s claim.\n\n\nScore: a = 3, b = 1\n\n\nBayes\nFreq."
  },
  {
    "objectID": "01_blog/2022_08_22_Bayes-Rules/index.html#youve-tested-positive-for-a-very-rare-genetic-trait.-if-you-only-get-to-ask-the-doctor-one-question-which-would-it-be",
    "href": "01_blog/2022_08_22_Bayes-Rules/index.html#youve-tested-positive-for-a-very-rare-genetic-trait.-if-you-only-get-to-ask-the-doctor-one-question-which-would-it-be",
    "title": "Bayes Rules! - Salt Lake City R User Group",
    "section": "2.4 Youâ€™ve tested positive for a very rare genetic trait. If you only get to ask the doctor one question, which would it be?",
    "text": "2.4 Youâ€™ve tested positive for a very rare genetic trait. If you only get to ask the doctor one question, which would it be?\n\nP(rare trait|+)\nP(+| no rare trait)\n\n\nScore: a = 3, b = 1\n\n\nBayes\n\nasking about uncertainty of hypothesis given certainty of the data\nmore natural question to ask\n\nFreq. = p-value\n\nhard to wrap minds around\nasking about uncertainty in data\nless natural question to ask (since data is certain)"
  },
  {
    "objectID": "01_blog/2022_08_22_Bayes-Rules/index.html#goals",
    "href": "01_blog/2022_08_22_Bayes-Rules/index.html#goals",
    "title": "Bayes Rules! - Salt Lake City R User Group",
    "section": "3.1 Goals",
    "text": "3.1 Goals\n\nLearn to think like Bayesians.\nApply Bayesian thinking in a regression setting."
  },
  {
    "objectID": "01_blog/2022_08_22_Bayes-Rules/index.html#set-up",
    "href": "01_blog/2022_08_22_Bayes-Rules/index.html#set-up",
    "title": "Bayes Rules! - Salt Lake City R User Group",
    "section": "3.2 Set Up",
    "text": "3.2 Set Up\n\n# Load packages\nlibrary(tidyverse)\nlibrary(tidybayes)\nlibrary(bayesrules)\nlibrary(bayesplot)\nlibrary(rstanarm)\nlibrary(broom.mixed)"
  },
  {
    "objectID": "01_blog/2022_08_22_Bayes-Rules/index.html#background",
    "href": "01_blog/2022_08_22_Bayes-Rules/index.html#background",
    "title": "Bayes Rules! - Salt Lake City R User Group",
    "section": "3.3 Background",
    "text": "3.3 Background\nLet \\(\\pi\\) (â€œpiâ€) be the proportion of U.S. adults that believe that climate change is real and caused by people. Thus \\(\\pi\\) is some value between 0 and 1."
  },
  {
    "objectID": "01_blog/2022_08_22_Bayes-Rules/index.html#exercise-1-specify-a-prior-model",
    "href": "01_blog/2022_08_22_Bayes-Rules/index.html#exercise-1-specify-a-prior-model",
    "title": "Bayes Rules! - Salt Lake City R User Group",
    "section": "3.4 Exercise 1: Specify a Prior Model",
    "text": "3.4 Exercise 1: Specify a Prior Model\nThe first step in learning about \\(\\pi\\) is to specify a prior model for \\(\\pi\\) (i.e.Â prior to collecting any data). Suppose your friend specifies their understanding of \\(\\pi\\) through the â€œBeta(2, 20)â€ model. Plot this Beta model and discuss what it tells you about your friendâ€™s prior understanding. For example:\n\nWhat do they think is the most likely value of \\(\\pi\\)?\n\nWhat range of \\(\\pi\\) values do they think are plausible?\n\n\nplot_beta(alpha = 2, beta = 20)\n\n\n\n\n\n\n\n\nNotes:\n\nproportion between 0 and 1 (not \\(-\\infty\\) to \\(+\\infty\\))\nthis model, beta-2-20, is right skewed\n\n\n3.4.1 What is your friend saying is the most likely value of pi?\nAbout .12 or 12 % or people believe in climate change.\n\nspike of model is best estimate\nlooking at range the prior model drops off above .25, so you friend believes under 25% of people believe in climate change."
  },
  {
    "objectID": "01_blog/2022_08_22_Bayes-Rules/index.html#check-out-some-data",
    "href": "01_blog/2022_08_22_Bayes-Rules/index.html#check-out-some-data",
    "title": "Bayes Rules! - Salt Lake City R User Group",
    "section": "3.5 Check Out Some Data",
    "text": "3.5 Check Out Some Data\nThe second step in learning about \\(\\pi\\), the proportion of U.S. adults that believe that climate change is real and caused by people, is to collect data. Your friend surveys 10 people and 6 believe that climate change is real and caused by people. The likelihood function of \\(\\pi\\) plots the chance of getting this 6-out-of-10 survey result under different possible \\(\\pi\\) values. Based on this plot:\n\nplot_binomial_likelihood(y = 6, n = 10)\n\n\n\n\n\n\n\n\nNotes:\n\nThe next step after creating a model (beta-2-20) we collect data.\nThis plot is showing us what the chance is that we got these survey results under different possible pie values.\n\n\n3.5.1 With what values of \\(\\pi\\) are the 6-out-of-10 results most consistent?\nApprox. 60% of people believe in climate change. Shown by our graph spiking at that value.\n\n\n3.5.2 For what values of \\(\\pi\\) would these 6-out-of-10 results be unlikely?\nOur data would not be very likely to happen for values below .25 and above .9."
  },
  {
    "objectID": "01_blog/2022_08_22_Bayes-Rules/index.html#exercist-3-build-the-posterior-model",
    "href": "01_blog/2022_08_22_Bayes-Rules/index.html#exercist-3-build-the-posterior-model",
    "title": "Bayes Rules! - Salt Lake City R User Group",
    "section": "3.6 Exercist 3: Build the Posterior Model",
    "text": "3.6 Exercist 3: Build the Posterior Model\nIn a Bayesian analysis of \\(\\pi\\), we build a posterior model of \\(\\pi\\) by combining the prior model of \\(\\pi\\) with the data (represented through the likelihood function). Plot all 3 components below. Summarize your observations:\n\nplot_beta_binomial(alpha = 2, beta = 20, y = 6, n = 10)\n\n\n\n\n\n\n\n\nNotes:\n\nDepends on a lot of factors\n\n\n3.6.1 Whatâ€™s your friendâ€™s posterior understanding of \\(\\pi\\)?\nMy friendâ€™s prior understanding of \\(\\pi\\) is not as low as what it was before, but also not as high as what is suggested in the data.\n\n\n3.6.2 How does their posterior understanding compare to their prior and likelihood? Thus how does their posterior balance the prior and data?\nTheir posterior understanding is higher than their prior knowledge and likelihood. The density of their posterior knowledge is lower than their previous density."
  },
  {
    "objectID": "01_blog/2022_08_22_Bayes-Rules/index.html#exercise-4-another-friend",
    "href": "01_blog/2022_08_22_Bayes-Rules/index.html#exercise-4-another-friend",
    "title": "Bayes Rules! - Salt Lake City R User Group",
    "section": "3.7 Exercise 4: Another Friend",
    "text": "3.7 Exercise 4: Another Friend\nConsider another friend that saw the same 6-out-of-10 polling data but started with a Beta(1, 1) prior model for \\(\\pi\\):\n\nplot_beta(alpha = 1, beta = 1)\n\n\n\n\n\n\n\n\n\n3.7.1 Describe the new friendâ€™s understanding of \\(\\pi\\). Compared to the first friend, are they more or less sure about \\(\\pi\\)?\nThis is a uniform distribution which maybe indicates the friend thinks everyone believes in Climate Change.\n\n\n3.7.2 Do you think the new friend will have a different posterior model than the first friend? If so, how do you think it will compare?\nYes, I think their posterior model will be higher than the first friend.\nTest your intuition. Use plot_beta_binomial() to explore your new friendâ€™s posterior model of \\(\\pi\\).\n\nplot_beta_binomial(alpha = 1, beta = 1, y = 6, n = 10)\n\n\n\n\n\n\n\n\nNotes:\n\nThis is a shoulder shrug, uncertain prior model. It could really be anything."
  },
  {
    "objectID": "01_blog/2022_08_22_Bayes-Rules/index.html#exercise-5-more-data",
    "href": "01_blog/2022_08_22_Bayes-Rules/index.html#exercise-5-more-data",
    "title": "Bayes Rules! - Salt Lake City R User Group",
    "section": "3.8 Exercise 5: More Data",
    "text": "3.8 Exercise 5: More Data\nTest your intuition. Use plot_beta_binomial() to explore your new friendâ€™s posterior model of \\(\\pi\\).\n\ndata(\"pulse_of_the_nation\")\npulse_of_the_nation %>% \n  count(climate_change)\n\n# A tibble: 3 Ã— 2\n  climate_change                    n\n  <fct>                         <int>\n1 Not Real At All                 150\n2 Real and Caused by People       655\n3 Real but not Caused by People   195\n\n\n\n3.8.1 How do you think the additional data will impact your first friendâ€™s posterior understanding of \\(\\pi\\)? What about the second friendâ€™s?\nI think the first friends understanding of \\(\\pi\\) would increase will increase, while the second friends understanding will decrease.\n\n\n3.8.2 Upon seeing the 1000-person survey results, do you think your two friendsâ€™ posterior understandings of \\(\\pi\\) will disagree a lot or a little?\nI think the two friendsâ€™ posterior understanding will disagree a little.\nTest your intuition. Use plot_beta_binomial() to explore both friendsâ€™ posterior models of \\(\\pi\\).\n\n# first friend \nplot_beta_binomial(alpha = 2, beta = 20, y = 655, n = 1000)\n\n\n\n\n\n\n\n# second friend \nplot_beta_binomial(alpha = 1, beta = 1, y = 655, n = 1000)"
  },
  {
    "objectID": "01_blog/2022_08_22_Bayes-Rules/index.html#exercise-6-your-turn",
    "href": "01_blog/2022_08_22_Bayes-Rules/index.html#exercise-6-your-turn",
    "title": "Bayes Rules! - Salt Lake City R User Group",
    "section": "3.9 Exercise 6: Your Turn",
    "text": "3.9 Exercise 6: Your Turn\nLet \\(\\pi\\) be the proportion of U.S. adults that believe in ghosts.\n\nUse plot_beta() to tune your prior model of \\(\\pi\\). To this end, think about what values of \\(\\pi\\) you think are most likely and how sure you are.\n\nNote:\n\nalpha and beta must be positive.\nThe prior means falls at alpha/(alpha + beta). Thus when alpha is smaller than beta, the prior mode falls below 0.5.\nIn general, the smaller the alpha and beta, the more variable / less certain the prior.\n\n\nbayesrules::plot_beta(alpha = 20, beta = 10)\n\n\n\n\n\n\n\n\n\nCollect some data. How many of the 1000 pulse_of_the_nation respondents believe in ghosts?\n\n\npulse_of_the_nation %>% \n  count(ghosts)\n\n# A tibble: 2 Ã— 2\n  ghosts     n\n  <fct>  <int>\n1 No       621\n2 Yes      379\n\n\n\nUse plot_beta_binomial() to visualize your prior, data, and posterior.\n\n\nbayesrules::plot_beta_binomial(alpha = 20, beta = 10, y = 378, n = 1000)\n\n\n\n\n\n\n\n\nCheck out the Github Repository for Part 2: Apply Bayesian thinking to a regression model."
  },
  {
    "objectID": "01_blog/2022_12_19_NBA-Salaries-Part-1-Web-Scraping/index.html",
    "href": "01_blog/2022_12_19_NBA-Salaries-Part-1-Web-Scraping/index.html",
    "title": "NBA Salaries - Part 1: Web-Scraping",
    "section": "",
    "text": "This post exhibits a scraping function that saves and cleans data from ESPN - NBA Players Salaries, as well as some simple data visuals of NBA Salaries."
  },
  {
    "objectID": "01_blog/2022_12_19_NBA-Salaries-Part-1-Web-Scraping/index.html#change-salaray-from-character-to-numeric",
    "href": "01_blog/2022_12_19_NBA-Salaries-Part-1-Web-Scraping/index.html#change-salaray-from-character-to-numeric",
    "title": "NBA Salaries - Part 1: Web-Scraping",
    "section": "4.1 Change Salaray from Character to Numeric",
    "text": "4.1 Change Salaray from Character to Numeric\nNotice that the SALARY column is a character value. This will not be helpful when trying to do math, or make graphs with this numerical data. To change this 3 things must be addressed:\n\nRemoving the dollar sign.\nRemoving the commas.\nChange character type to numeric.\n\n\nnba_salaries_2023$SALARY <- str_remove_all(nba_salaries_2023$SALARY,\n                    \"\\\\$\")\nnba_salaries_2023$SALARY <- str_remove_all(nba_salaries_2023$SALARY,\n                    \",\")\nnba_salaries_2023$SALARY <- as.numeric(nba_salaries_2023$SALARY)\n\nNow we are able to do math, make graphs, and arrange the data by salary."
  },
  {
    "objectID": "01_blog/2022_12_19_NBA-Salaries-Part-1-Web-Scraping/index.html#basic-statistics",
    "href": "01_blog/2022_12_19_NBA-Salaries-Part-1-Web-Scraping/index.html#basic-statistics",
    "title": "NBA Salaries - Part 1: Web-Scraping",
    "section": "4.2 Basic Statistics",
    "text": "4.2 Basic Statistics\n\n\n\n\nHighest paid value : 48,070,014\nLowest paid value : 5,318\nMedian : 4,037,278\nMean : 8,586,111\nStandard Deviation : 10,147,458"
  },
  {
    "objectID": "01_blog/2022_12_19_NBA-Salaries-Part-1-Web-Scraping/index.html#box-plot",
    "href": "01_blog/2022_12_19_NBA-Salaries-Part-1-Web-Scraping/index.html#box-plot",
    "title": "NBA Salaries - Part 1: Web-Scraping",
    "section": "4.3 Box Plot",
    "text": "4.3 Box Plot\n\nggplot2::ggplot(data = nba_salaries_2023,\n                mapping = ggplot2::aes(x = SALARY,\n                                       y = TEAM)) + \n  ggplot2::geom_boxplot()"
  },
  {
    "objectID": "01_blog/2022_12_19_NBA-Salaries-Part-1-Web-Scraping/index.html#box-plots",
    "href": "01_blog/2022_12_19_NBA-Salaries-Part-1-Web-Scraping/index.html#box-plots",
    "title": "NBA Salaries - Part 1: Web-Scraping",
    "section": "4.3 Box Plots",
    "text": "4.3 Box Plots\n\n4.3.1 2022 - 2023 Yearly Salary by Postion\n\nggplot2::ggplot(data = nba_salaries_2023,\n                mapping = ggplot2::aes(x = SALARY,\n                                       y = POSITION)) + \n  ggplot2::geom_boxplot()\n\n\n\n\nFrom this visual we can see that Point Guards (PG) appear to be paid the most. Especially compared to Guards (G) and Forwards (F) who are paid considerably less than.\n\n\n4.4 2022-2023 Yearly Salary by Team\n\nggplot2::ggplot(data = nba_salaries_2023,\n                mapping = ggplot2::aes(x = SALARY,\n                                       y = TEAM)) + \n  ggplot2::geom_boxplot()\n\n\n\n\nThis plot is not the easiest to read, and might be worth sub-setting the information further. However eye-balling this visual we can see most teams pay between $2,000,000 and $15,000,000 per player with a few outliers. These outliers of course being superstar players."
  }
]