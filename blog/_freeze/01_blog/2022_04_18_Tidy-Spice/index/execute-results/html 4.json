{
  "hash": "3523b85fa6c557b7a353c647b2831f7d",
  "result": {
    "markdown": "---\ntitle: \"Tidy Spice\"\ndate: \"2022-04-18\"\ncategories: [R, NLP, Data Visuals]\ntoc: true\n---\n\n\nThis post is my reproduction of Julia Silge's blogpost [Topic Modeling for #TidyTuesday Spice Girls Lyrics](https://juliasilge.com/blog/spice-girls/), with some added inspiration from a blogpost by Ariane Aumaitre called [Tutorial: Text analysis and data visualization with Taylor Swift songs](https://arianeaumaitre.com/2019/09/15/tutorial-text-analysis-and-data-visualization-with-taylor-swift-songs/). \n\n![](../../00_img/engflag.png)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(error=FALSE, \n                      message= FALSE,\n                      warning=FALSE)\n```\n:::\n\n\n\n# `1. Set Up`\n\nFor this post I used the following packages:\n\n* tidyverse: \n\n  * readr: to use `read_csv()`\n  \n  * magrittr: to pipe `%>%`\n  \n  * dplyr: to manipulate data with `distinct()`, `mutate()`, `anti_join()`, `group_by()`, `summarise()`, `arrange()`, `count()`, `filter()`, `slice_max()`, `ungroup()`\n  \n  * stringr: to use `str_replace()`\n  \n  * ggplot2: to make data visuals with `ggplot()`\n\n* tidytext: to use `unnest_tokens()`, `get_stopwords()`, `cast_sparse()`, `tidy()`, `reorder_within()`, `scale_y_reordered()`\n\n* stm: to use `stm()` (Structural Topic Model), and `estimateEffect()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse) \nlibrary(tidytext)\nlibrary(stm)\n```\n:::\n\n\nAnd looking at data of Spice Girls lyrics: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlyrics <- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-12-14/lyrics.csv\")\nutils::head(lyrics, 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 9\n  artist_name album_name track_n…¹ song_id song_…² line_…³ secti…⁴ line  secti…⁵\n  <chr>       <chr>          <dbl>   <dbl> <chr>     <dbl> <chr>   <chr> <chr>  \n1 Spice Girls Spice              1   89740 Wannabe       1 Intro   Haha… Scary,…\n2 Spice Girls Spice              1   89740 Wannabe       2 Intro   Yo, … Scary,…\n3 Spice Girls Spice              1   89740 Wannabe       3 Intro   So t… Scary,…\n4 Spice Girls Spice              1   89740 Wannabe       4 Intro   I'll… Scary,…\n5 Spice Girls Spice              1   89740 Wannabe       5 Intro   So t… Scary,…\n# … with abbreviated variable names ¹​track_number, ²​song_name, ³​line_number,\n#   ⁴​section_name, ⁵​section_artist\n```\n:::\n\n```{.r .cell-code}\nlyrics %>% dplyr::distinct(album_name, song_name)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 31 × 2\n   album_name song_name                 \n   <chr>      <chr>                     \n 1 Spice      \"Wannabe\"                 \n 2 Spice      \"Say You\\x92ll Be There\"  \n 3 Spice      \"2 Become 1\"              \n 4 Spice      \"Love Thing\"              \n 5 Spice      \"Last Time Lover\"         \n 6 Spice      \"Mama\"                    \n 7 Spice      \"Who Do You Think You Are\"\n 8 Spice      \"Something Kinda Funny\"   \n 9 Spice      \"Naked\"                   \n10 Spice      \"If U Can\\x92t Dance\"     \n# … with 21 more rows\n```\n:::\n:::\n\n\n\n# `2. Tidy`\n\n- Change `\\x92` to '\n\n- Split words in line column into tokens\n\n- Anti-Join each word into it's own row\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_lyrics <-\n  lyrics %>%\n  dplyr::mutate(song_name = stringr::str_replace_all(song_name, \"\\x92\", \"'\")) %>%\n  tidytext::unnest_tokens(word, line) %>%\n  dplyr::anti_join(tidytext::get_stopwords())\ntidy_lyrics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6,663 × 9\n   artist_name album_name track_…¹ song_id song_…² line_…³ secti…⁴ secti…⁵ word \n   <chr>       <chr>         <dbl>   <dbl> <chr>     <dbl> <chr>   <chr>   <chr>\n 1 Spice Girls Spice             1   89740 Wannabe       1 Intro   Scary,… haha…\n 2 Spice Girls Spice             1   89740 Wannabe       2 Intro   Scary,… yo   \n 3 Spice Girls Spice             1   89740 Wannabe       2 Intro   Scary,… tell \n 4 Spice Girls Spice             1   89740 Wannabe       2 Intro   Scary,… want \n 5 Spice Girls Spice             1   89740 Wannabe       2 Intro   Scary,… real…\n 6 Spice Girls Spice             1   89740 Wannabe       2 Intro   Scary,… real…\n 7 Spice Girls Spice             1   89740 Wannabe       2 Intro   Scary,… want \n 8 Spice Girls Spice             1   89740 Wannabe       3 Intro   Scary,… tell \n 9 Spice Girls Spice             1   89740 Wannabe       3 Intro   Scary,… want \n10 Spice Girls Spice             1   89740 Wannabe       3 Intro   Scary,… real…\n# … with 6,653 more rows, and abbreviated variable names ¹​track_number,\n#   ²​song_name, ³​line_number, ⁴​section_name, ⁵​section_artist\n```\n:::\n:::\n\n\n# `3. Most Common Words`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_lyrics %>%\n  dplyr::group_by(word) %>%\n  dplyr::summarise(n = n()) %>% \n  dplyr::arrange(-n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 979 × 2\n   word      n\n   <chr> <int>\n 1 get     153\n 2 love    137\n 3 know    124\n 4 time    106\n 5 wanna   102\n 6 never   101\n 7 oh       88\n 8 yeah     88\n 9 la       85\n10 got      82\n# … with 969 more rows\n```\n:::\n:::\n\n\n**Short Way**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_lyrics %>%\n  dplyr::count(word, sort = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 979 × 2\n   word      n\n   <chr> <int>\n 1 get     153\n 2 love    137\n 3 know    124\n 4 time    106\n 5 wanna   102\n 6 never   101\n 7 oh       88\n 8 yeah     88\n 9 la       85\n10 got      82\n# … with 969 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_lyrics %>%\n  dplyr::count(word, sort = TRUE) %>%\n  dplyr::filter(n > 80,\n         word != \"la\",\n         word != \"oh\") %>%\n  ggplot2::ggplot(aes(x = n, y = reorder(word, n), fill = word)) +\n  ggplot2::geom_col() + \n  ggplot2::labs(y = \"\",\n       x = \"Number of Times Mentioned\",\n       title = \"Most Frequent Words in Spice Girls Lyrics\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n# `4. Most Common Word Per Song`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_lyrics %>%\n  dplyr::count(song_name, word, sort = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2,206 × 3\n   song_name                       word           n\n   <chr>                           <chr>      <int>\n 1 Saturday Night Divas            get           91\n 2 Spice Up Your Life              la            64\n 3 If U Can't Dance                dance         60\n 4 Holler                          holler        48\n 5 Never Give Up on the Good Times never         47\n 6 Move Over                       generation    41\n 7 Saturday Night Divas            deeper        41\n 8 Move Over                       yeah          39\n 9 Something Kinda Funny           got           39\n10 Never Give Up on the Good Times give          38\n# … with 2,196 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_lyrics %>%\n  dplyr::count(song_name, word, sort = TRUE) %>%\n  dplyr::filter(n >40,\n         word != \"la\") %>%\n  ggplot2::ggplot(aes(x = n, y = reorder(word, n), fill = word)) +\n  ggplot2::geom_col() + \n  ggplot2::labs(y = \"\",\n                x = \"Number of Times Mentioned\",\n                title = \"Most Frequent Words in Spice Girls Lyrics in a Single Song\") \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n# `5. Train a Topic Model`\n\n(Analyze text data to determine cluster words)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlyrics_sparse <-\n  tidy_lyrics %>%\n  dplyr::count(song_name, word) %>%\n  tidytext::cast_sparse(song_name, word, n)\nbase::dim(lyrics_sparse)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  31 979\n```\n:::\n:::\n\n\nThis means there are 31 songs (i.e. documents) and 979 different tokens (i.e. terms or words) in our data set for modeling.\n\n\"The most important parameter when training a [topic modeling](https://sicss.io/2019/materials/day3-text-analysis/topic-modeling/rmarkdown/Topic_Modeling.html) is K, the number of topics. This is like k in [k-means](https://allisonhorst.com/k-means-clustering) in that it is a hyper parameter of the model and we must choose this value ahead of time. We could try to multiple different values to find the best value for K, but this is a very small data set so let’s just stick with K = 4.\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbase::set.seed(123) \ntopic_model <- stm::stm(lyrics_sparse, K = 4, verbose = FALSE)\nbase::summary(topic_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nA topic model with 4 topics, 31 documents and a 979 word dictionary.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nTopic 1 Top Words:\n \t Highest Prob: get, wanna, deeper, right, night, come, gotta \n \t FREX: deeper, saturday, get, comin, back, night, ya \n \t Lift: jump, party's, body, another, anyway, blameless, breaking \n \t Score: deeper, saturday, get, night, comin, arms, wanna \nTopic 2 Top Words:\n \t Highest Prob: dance, yeah, know, generation, next, love, naked \n \t FREX: next, naked, denying, foolin, nobody, wants, lead \n \t Lift: foolin, nobody, question, next, admit, bein, check \n \t Score: next, dance, naked, generation, denying, colour, foolin \nTopic 3 Top Words:\n \t Highest Prob: got, holler, make, love, wanna, oh, time \n \t FREX: holler, kinda, swing, funny, yay, use, driving \n \t Lift: anyone, driving, fantasy, oller, blow, nudge, unwind \n \t Score: holler, swing, kinda, funny, yay, ashamed, loving \nTopic 4 Top Words:\n \t Highest Prob: la, never, love, give, time, know, way \n \t FREX: times, swear, la, bring, promise, viva, tried \n \t Lift: aggravation, angel, dreamt, heaven, letting, revelation, sent \n \t Score: la, times, aha, swear, chicas, front, havin \n```\n:::\n:::\n\n\n# `6. Explore Topic Model Results`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nword_topics <- tidytext::tidy(topic_model, matrix = \"beta\")\nword_topics \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3,916 × 3\n   topic term        beta\n   <int> <chr>      <dbl>\n 1     1 achieve 1.94e- 3\n 2     2 achieve 8.51e-29\n 3     3 achieve 1.00e-25\n 4     4 achieve 9.51e-19\n 5     1 baby    1.38e- 2\n 6     2 baby    1.44e- 2\n 7     3 baby    1.28e- 3\n 8     4 baby    4.16e- 3\n 9     1 back    2.31e- 2\n10     2 back    5.44e- 4\n# … with 3,906 more rows\n```\n:::\n:::\n\n\n# `7. Visualization`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nword_topics %>%\n  dplyr::group_by(topic) %>%\n  dplyr::slice_max(beta, n = 10) %>%\n  dplyr::ungroup() %>%\n  dplyr::mutate(topic = paste(\"Topic\", topic)) %>%\n  ggplot2::ggplot(ggplot2::aes(beta,\n                               tidytext::reorder_within(term,\n                                                        beta, \n                                                        topic), \n                               fill = topic)) +\n  ggplot2::geom_col(show.legend = FALSE) +\n  ggplot2::facet_wrap(vars(topic), scales = \"free_y\") +\n  ggplot2::scale_x_continuous(expand = c(0, 0)) +\n  tidytext::scale_y_reordered() +\n  ggplot2::labs(x = base::expression(beta), y = NULL)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n## `Gamma Matrix`\n\n[Gamma Matricies](https://en.wikipedia.org/wiki/Gamma_matrices) \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsong_topics <- tidytext::tidy(topic_model,\n                              matrix = \"gamma\",\n                              document_names = base::rownames(lyrics_sparse)\n)\nsong_topics\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 124 × 3\n   document                   topic    gamma\n   <chr>                      <int>    <dbl>\n 1 2 Become 1                     1 0.932   \n 2 Denying                        1 0.00154 \n 3 Do It                          1 0.996   \n 4 Get Down With Me               1 0.300   \n 5 Goodbye                        1 0.000971\n 6 Holler                         1 0.00155 \n 7 If U Can't Dance               1 0.000896\n 8 If You Wanna Have Some Fun     1 0.0171  \n 9 Last Time Lover                1 0.140   \n10 Let Love Lead the Way          1 0.00178 \n# … with 114 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsong_topics %>%\n  dplyr::mutate(\n    song_name = fct_reorder(document, gamma),\n    topic = base::factor(topic)\n  ) %>%\n  ggplot2::ggplot(ggplot2::aes(gamma, topic, fill = topic)) +\n  ggplot2::geom_col(show.legend = FALSE) +\n  ggplot2::facet_wrap(vars(song_name), ncol = 4) +\n  ggplot2::scale_x_continuous(expand = c(0, 0)) +\n  ggplot2::labs(x = base::expression(gamma), y = \"Topic\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n# `8. Estimate Regression`\n\n\n::: {.cell}\n\n```{.r .cell-code}\neffects <-\n  stm::estimateEffect(\n    1:4 ~ album_name,\n    topic_model,\n    tidy_lyrics %>% distinct(song_name, album_name) %>% dplyr::arrange(song_name)\n  )\nbase::summary(effects)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nstm::estimateEffect(formula = 1:4 ~ album_name, stmobj = topic_model, \n    metadata = tidy_lyrics %>% distinct(song_name, album_name) %>% \n        dplyr::arrange(song_name))\n\n\nTopic 1:\n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)\n(Intercept)           0.14061    0.12301   1.143    0.263\nalbum_nameSpice       0.09258    0.17701   0.523    0.605\nalbum_nameSpiceworld  0.15105    0.17327   0.872    0.391\n\n\nTopic 2:\n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)\n(Intercept)            0.1471     0.1327   1.109    0.277\nalbum_nameSpice        0.1327     0.1887   0.703    0.488\nalbum_nameSpiceworld   0.1472     0.1851   0.795    0.433\n\n\nTopic 3:\n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)  \n(Intercept)           0.29480    0.12114   2.434   0.0216 *\nalbum_nameSpice       0.07952    0.17174   0.463   0.6470  \nalbum_nameSpiceworld -0.28112    0.16919  -1.662   0.1078  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTopic 4:\n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)   \n(Intercept)           0.41760    0.13938   2.996  0.00567 **\nalbum_nameSpice      -0.30293    0.19793  -1.531  0.13711   \nalbum_nameSpiceworld -0.01948    0.19352  -0.101  0.92053   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}