---
title: "Statistics 451: Applied Statistics for Engineers and Scientists - Homework 1"
author: "Randi Bolt"
date: "2021-06-28"
categories: [Statistics]
toc: true
---

The problems on this page are from Probability & Statistics for Engineering & Sciences 9th Edition by Jay L. Devore - Duxbury Publisher, and the work is mine.

![](../../00_img/concreate-beams-flex-strength.png)
```{r}

```

```{r, message=F, echo=F}
library(dplyr)
library(ggplot2)
```

## `1.10` Consider the strength data for beams.

### `a.` Construct a stem-and leaf display of the data. What appears to be a representative strength value? Do the observations appear to be highly concentrated about the representative value or rather spread out?

```{r}
beam <- c(5.9, 7.2, 7.3, 6.3, 8.1, 6.8, 7.0, 7.6, 6.8, 6.5, 7.0, 6.3, 7.9, 9.0,
         8.2, 8.7, 7.8, 9.7, 7.4, 7.7, 9.7, 7.8, 7.7, 11.6, 11.3, 11.8, 10.7)
stem(beam)
```

A representative strength value would be 7.7, as more observations are concentrated around this value than any other.

### `b.` Does the display appear to be reasonably symmetric about a representative value, or would you describe its shape in some other way?

```{r, echo=F}
hist(beam, 
     col = topo.colors(7), 
     ylim = c(0,10), 
     xlab= "Flexural Strength (in MegaPascal)",
     main = "Flexural Strength of Concreate Beams")
abline(v=mean(beam), col="orange", lwd = 6)
abline(v=median(beam), col="red", lwd = 8)
```

No, I would argue that the data has a slight positive skewed to the right. I say this because the higher frequency values (in blues) seem to be to the left of the representative value (indicated by the red line), which is to the left of the mean (indicated by the orange line).

### `c.` Do there appear to be any outlying strength values?

Yes there seems to be a small density of values outlying around 11.

### `d.` What proportion of strength observations in this sample exceed 10 MPa?

```{r, echo=F}
proportion <- mean(as.integer(beam > 10))
print(paste(round(proportion*100,2), "%"))
```

An unlikely 14.81% of values exceed 10 MPa.

## `1.12` The accompanying specific gravity values for various wood types used in construction appeared in the article "Bolted Connection Design Values Based on European Yield Model" (J. of Structural Engr., 1993: 2169-2186):

```{r}
wood.g <- c(.31, .35, .36, .36, .37, .38, .40, .40, .40,
            .41, .41, .42, .42, .42, .42, .42, .43, .44,
            .45, .46, .46, .47, .48, .48, .48, .51, .54,
            .54, .55, .58, .62, .66, .66, .67, .68, .75)
```

### Construct a stem-and-leaf display using repeated stems (see the previous exercise), and comment on any interesting features of the display.

```{r, echo=F}
stem(wood.g, scale = 0.1)
stem(wood.g, scale = 0.5)
stem(wood.g)
```

Looking at the three stem-and-leaf displays there are a few interesting features about the gravity for various wood types used in construction data that stands out. Dropping the last digit in the data, the first stem-and-leaf display shows us that there's an even number of values that are \>0.5 and 0.5that appear most dense around 0.4. The second and third stem-and-leaf displays show us that these values are most dense about 0.42, with a small blip around 6.6 and obvious outlier for value 0.75.

## `1.16` The article cited in Example 1.2 also gave the accompanying strengths observations for cylinders:

```{r}
cylinders <- c(6.1, 5.8, 7.8, 7.1, 7.2, 9.2, 6.6, 8.3, 7.0, 8.3,
           7.8, 8.1, 7.4, 8.5, 8.9, 9.8, 9.7, 14.1, 12.6, 11.2)
```

### `a.` Construct a comparative stem-and-leaf display (see the previous exercise) of the beam and cylinder data and then answer the questions in parts (b)-(d) of Exercise 10 for the observations on cylinders.

```{r, echo=F}
stem(cylinders, scale = 2)
```

-   Does the display appear to be reasonably symmetric about a representative value, or would you describe its shape in some other way?

```{r, echo=F}
# find mode 
sort(table(cylinders))
mode <- ((8.3-7.8)/2)+7.8
mean(cylinders)
median(cylinders)
# hist(cylinders, 
#      col = topo.colors(7), 
#      ylim = c(0,6),
#      xlim = c(0, 15),
#      xlab= "Flexural Strength (in MegaPascal)",
#      main = "Flexural Strength of Concrete Cylinders",
#      breaks = c(4,5,6,7,8,9,10,11,12,13,14,15))
# abline(v=mean(cylinders), col="orange", lwd = 6)
# abline(v=median(cylinders), col="red", lwd = 8)
# abline(v=mode, col="yellow", lwd = 6)
```

This data of cylinders also appears to have a slight positive skew, shown by mean (orange line) to the right of the median (red line) and mode (yellow line). However the mean is a lot closer to the median and mode in this than in the previous graph because there appear to bee less extreme observations.

-   Do there appear to be any outlying strength values?

14.1 appears to be an outlying strength value, as well as 11.2 and 12.6. Without these three values the mean and median are almost identical, shown below in cylinders.clean.

```{r, echo=F}
cylinders.clean <- c(6.1, 5.8, 7.8, 7.1, 7.2, 9.2, 6.6, 8.3, 7.0, 8.3,
           7.8, 8.1, 7.4, 8.5, 8.9, 9.8, 9.7)
cylinders.clean
mean(cylinders.clean)
median(cylinders.clean)
```

-   What proportion of strength observations in this sample exceed 10 MPa?

```{r, echo=F}
proportion2 <- mean(as.integer(cylinders > 10))
print(paste(round(proportion2*100,2), "%"))
```

About 15% of the data observations exceed 10 Mpa.

### `b.` In what ways are the two sides of the display similar? Are there any obvious differences between the beam observations and the cylinder observations?

Both displays show relatively normal distributions with slight skews to the right. Similarly both the beam and cylinders have approximately 15% of the data outside the normal distribution. An obvious difference between the two is that the beam data was more skewed than the cylinder. A reason for this may be that the range of values for the beam is smaller than the range of values for cylinders, so the beam mean is more sensitive to outlying data.

## `1.34` Exposure to microbial products, especially endotoxin, may have an impact on vulnerability to allergic diseases. The article "Dust Sampling Methods for Endotoxin -- An Essential, But Underestimated Issue" (Indoor Air, 2006: 20-27) considered various issues associated with determining endotoxin concentration. The following data on concentration (EU/mg) in settled dust for one sample of urban homes and another of farm homes was kindly supplied by the authors of the cited article.

```{r}
urban <- c(6.0, 5.0, 11.0, 33.0, 4.0, 5.0, 80.0, 18.0, 35.0, 17.0, 23.0)
farm <- c(4.0, 14.0, 11.0, 9.0, 9.0, 8.0, 4.0, 20.0, 5.0, 8.9, 21.0, 9.2, 3.0, 2.0, 0.3 )
```

### `a.` Determine the sample mean for each sample. How do they compare?

```{r}
mean(urban)
mean(farm)
```

The mean endotoxin concentration is greater in urban homes than farm homes.

### `b.` Determine the sample median for each sample. How do they compare? Why is the median for the urban sample so different from the mean for that sample?

```{r}
median(urban)
median(farm)
```

The median endotoxin concentration is greater in urban homes than farm homes.

The urban sample's median is so different from the mean, because the mean is more sensitive to outliers in the data (such as 80 EU/mg) than the median is.

### `c.` Calculate the trimmed mean for each sample by deleting the smallest and largest observation. What are the corresponding trimming percentages? How do the values of these trimmed means compare to the corresponding means and medians?

To start I will sort the data to see what are the largest and smallest observations for both.

```{r}
sort(urban)
sort(farm)
```

From the sorted data I can see the lowest and highest values for urban are c(4,80), and for farm they are c(0.3,21). These values are removed from the urban.trim and farm.trim shown below.

```{r}
urban.trim <- c(6.0, 5.0, 11.0, 33.0, 5.0, 18.0, 35.0, 17.0, 23.0)
farm.trim <- c(4.0, 14.0, 11.0, 9.0, 9.0, 8.0, 4.0, 20.0, 5.0, 8.9, 9.2, 3.0, 2.0)
```

To find the corresponding trimming percentages I subtracted the sum of the subtracted values from the sums of the urban and farm data sets respectively, and then divide each by the length of each data set respectively.

```{r}
(sum(urban)-84)/length(urban)
(sum(farm)-21.3)/length(farm)
```

The two values removed from the urban dataset is about 14% of the data, slightly more then the 7.14% variation of the farm data set.

Now to look at the trimmed means.

```{r}
mean(urban.trim)
mean(farm.trim)
```

The trimmed mean of the urban data is closer to the median of the urban data, whereas the trimmed mean for the farm data is farther away from the mean and median of the untrimmed data. After this analysis it would seem that trimming the first data set may be appropriate, whereas trimming the second may lead to misleading data. Looking at the stem-and-leaf displays are helpful in visualizing distributions and outliers.

```{r}
stem(urban, scale = 2)
stem(farm, scale = .5)
```

## `1.48` Exercise 34 presented the following data on endotoxin concentration in settled dust both for a sample of urban homes and for a sample of farm homes:

```{r}
urban
farm
```

### `a.` Determine the value of the sample standard deviation for each sample, interpret these values, and then contrast variability in the two samples.

```{r}
sd(urban)
sd(farm)
```

Another way we could find the standard deviation given the hint and the following equation given in class :

\[s\^2=\frac{1}{n-1}\sum\_{i=1}\^{n}(x_i - x)\^2\] \[=\frac{1}{n-1}\[\sum\_{i=1}^{n}x_i^2 - \frac{(\sum_{i=1}^{n}x_i)^2}{n}\]\]

```{r}
# hint
sigma_x_i.u <- 237.0
sigma_x_i.f <- 128.4
sigma_x_i_2.u <- 10079
sigma_x_i_2.f <- 1617.94
n.u <- length(urban)
n.f <- length(farm)
constant.u <- 1/(n.u-1)
constant.f <- 1/(n.f-1)
sv.u <- constant.u*(sigma_x_i_2.u - (sigma_x_i.u)^2/n.u)
sv.f <- constant.f*(sigma_x_i_2.f - (sigma_x_i.f)^2/n.f)
sqrt(sv.u)
sqrt(sv.f)
```

### `b.` Compute the fourth spread for each sample and compare. Do the fourth spreads convey the same message about variability that the standard deviations do? Explain.

The quickest way to do this in r is with quantile().

```{r}
quantile(urban)
quantile(farm)
```

Explanation : coming soon

Another way to find the forth spread is by first computing the upper fourth and lower fourth . To do that I first sorted the data, and then split it in half. Notice that because n for both data sets is odd, I figure out the middle value that is included in both, before I create the new data sets.

```{r}
# sort 
sorted.u <- sort(urban)
sorted.f <- sort(farm)
sorted.u
sorted.f
# find included value 
include.u <- as.integer(n.u/2)+1
include.f <- as.integer(n.f/2)+1
sorted.u[include.u]
sorted.f[include.f]
# upper and lower forth 
urban.lower <- c(4,  5,  5,  6, 11, 17)
urban.upper <- c(17, 18, 23, 33, 35, 80)
farm.lower <- c(0.3,  2.0,  3.0,  4.0,  4.0,  5.0,  8.0,  8.9)
farm.upper <- c(8.9,  9.0,  9.0,  9.2, 11.0, 14.0, 20.0, 21.0)
```

Now that the data is sorted, the middle values of 17 and 8.9 have been found, and the data has been split into two chunks I can compute the minimum,lower forth median, median, upper forth median, and the largest value.

```{r}
min(urban)
median(urban.lower)
median(urban)
median(urban.upper)
max(urban)
min(farm)
median(farm.lower)
median(farm)
median(farm.upper)
max(farm)
```

-   The authors of the cited article also provided endotoxin concentrations in dust bag dust:

```{r}
urban.bag <- c(34.0, 49.0, 13.0, 33.0, 24.0, 24.0, 35.0, 104.0, 34.0, 40.0, 38.0, 1.0)
farm.bag <- c(2.0, 64.0, 6.0, 17.0, 35.0, 11.0, 17.0, 13.0, 5.0, 27.0, 23.0,
              28.0, 10.0, 13.0, 0.2)
quantile(urban.bag)
quantile(farm.bag)
```

Construct a comparative boxplot (as did the cited paper) and compare and contrast the four samples.

```{r}
par(mfrow = c(1,2))
boxplot(urban)
boxplot(urban.bag)
par(mfrow = c(1,2))
boxplot(farm)
boxplot(farm.bag)
```

## `1.51` The article "A Thin-Film Oxygen Uptake Test for the Evaluation of Automotive Crankcase Lubricants" (Lubric. Engr., 1984: 75-83) reported the following data on oxidation-induction time (min) for various commercial oils:

```{r}
oxi.induct.time.min <- c(87, 103, 130, 160, 180, 195, 132, 145, 211, 105, 145,
                         153, 152, 138, 87, 99, 93, 119, 129)
```

### `a.` Calculate the sample variance and the standard deviation.

```{r}
oxi.var <- var(oxi.induct.time.min)
oxi.sd <- sd(oxi.induct.time.min)
oxi.var
oxi.sd
```

### `b.` If the observations were re-expressed in hours, what would be the resulting values of the sample variance and sample standard deviation? Answer without actually performing the re-expression.

The standard deviation has the same units as the data values (minutes) so in hours the standard deviation would be 35.56/60 (or a little over half an hour) whereas the variance is the standard deviation squared, so the values would be converted 1264.766/60\^2.

```{r}
oxi.var/60^2
oxi.sd/60
# verification 
oxi.induct.time.hour <- oxi.induct.time.min/60
var(oxi.induct.time.hour)
sd(oxi.induct.time.hour) 
```

## `1.60` Observations on burst strength (lb/in2) were obtained both for test nozzle welds ("Proper Procedures Are the Key to Welding Radioactive Waste Canisters," Welding J., Auud. 1997: 61-67)

```{r}
Test <-c(7200, 6100, 7300, 7300, 8000, 7400,
         7300, 7300, 8000, 6700, 8300)         
Cannister <- c(5250, 5625, 5900, 5900, 5700, 6050,
               5800, 6000, 5875, 6100, 5850, 6600)
```

### `a.` Construct a comparative boxplot and comment on interesting features (the cited article did not include such a picture, but the authors commented that they had looked at one).

```{r}
par(mfrow = c(1,2))
boxplot(Test, ylim = c(5000, 8500), main = "Test")
boxplot(Cannister, ylim = c(5000, 8500), main = "Cannister")
```

```{r}
mean(Test)-mean(Cannister)
mean(Test)
mean(Cannister)
sd(Test)
sd(Cannister)
```
